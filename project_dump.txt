
========== Файл: a.py ==========

#!/usr/bin/env python3
import os
import sys

# --- Настройки ---
TARGET_EXTENSIONS = {'.py', '.css', '.html', '.ts', '.tsx', '.java', ".json", "prompt", ".txt", ".log"}  # Расширения для поиска
IGNORE_DIRS = {'.venv', 'venv', '.git', 'node_modules', '__pycache__'}  # Папки для игнорирования
OUTPUT_FILENAME = 'project_dump.txt'  # Имя файла для вывода
# --- Конец Настроек ---

def scan_and_dump_project(start_dir, output_file):
    """
    Сканирует директории, начиная от start_dir, ищет файлы с нужными расширениями,
    игнорируя указанные папки, и записывает их относительные пути и содержимое
    в output_file.
    """
    abs_start_dir = os.path.abspath(start_dir)
    print(f"Начинаем сканирование из директории: {abs_start_dir}")
    print(f"Файлы будут сохранены в: {output_file}")
    print(f"Игнорируемые директории: {', '.join(IGNORE_DIRS)}")
    print(f"Искомые расширения: {', '.join(TARGET_EXTENSIONS)}")
    print("-" * 30)

    found_files_count = 0
    processed_files_count = 0

    try:
        with open(output_file, 'w', encoding='utf-8') as outfile:
            # os.walk рекурсивно обходит директории
            for dirpath, dirnames, filenames in os.walk(abs_start_dir, topdown=True):
                # --- Исключение ненужных директорий ---
                # Модифицируем dirnames ПЕРЕД тем, как os.walk пойдет вглубь.
                # Это самый эффективный способ пропустить ненужные ветки.
                dirnames[:] = [d for d in dirnames if d not in IGNORE_DIRS]
                # --------------------------------------

                # print(f"Сканируем: {dirpath}") # Раскомментируйте для детального лога

                for filename in filenames:
                    found_files_count += 1
                    # Проверяем расширение файла
                    _, ext = os.path.splitext(filename)
                    if ext.lower() in TARGET_EXTENSIONS:
                        processed_files_count += 1
                        full_path = os.path.join(dirpath, filename)
                        # Получаем относительный путь от стартовой директории
                        relative_path = os.path.relpath(full_path, abs_start_dir)

                        print(f"  -> Добавляем файл: {relative_path}")

                        # Записываем заголовок с путем
                        outfile.write(f"\n{'=' * 10} Файл: {relative_path} {'=' * 10}\n\n")

                        try:
                            # Читаем содержимое файла
                            with open(full_path, 'r', encoding='utf-8', errors='ignore') as infile:
                                content = infile.read()
                            outfile.write(content)
                            outfile.write("\n") # Добавляем пустую строку для разделения

                        except Exception as e:
                            error_msg = f"  *** Ошибка чтения файла {relative_path}: {e} ***\n"
                            print(error_msg)
                            outfile.write(error_msg)

    except IOError as e:
        print(f"Ошибка записи в файл {output_file}: {e}")
        sys.exit(1) # Выход с кодом ошибки
    except Exception as e:
        print(f"Произошла непредвиденная ошибка: {e}")
        sys.exit(1)

    print("-" * 30)
    print(f"Сканирование завершено.")
    print(f"Найдено файлов всего: {found_files_count}")
    print(f"Обработано (соответствующие расширения): {processed_files_count}")
    print(f"Результат сохранен в файл: {OUTPUT_FILENAME}")

if __name__ == "__main__":
    # Определяем директорию, где находится сам скрипт
    script_location = os.path.dirname(os.path.abspath(__file__))
    output_filepath = os.path.join(script_location, OUTPUT_FILENAME)

    scan_and_dump_project(script_location, output_filepath)

========== Файл: bot_lifecycle.py ==========

# ./Agent/bot_lifecycle.py

import logging
import inspect
import json
import os  # <<< Добавили импорт os
import asyncio # <<< Добавили импорт asyncio
from typing import Dict, Any, Callable, Optional, List
from pathlib import Path  # <<< Добавили импорт Path
from aiogram import Dispatcher  # <<< Добавили импорт Dispatcher
import google.generativeai as genai

logger = logging.getLogger(__name__)

# --- Основные зависимости ---
# Импортируем Bot и Dispatcher из загрузчика
try:
    from bot_loader import dp, bot
except ImportError:
    logging.critical("Failed to import dp, bot from bot_loader in bot_lifecycle.")
    raise

# Импортируем настройки (теперь только сам объект settings)
try:
    from config import settings
except ImportError:
    logging.critical("Failed to import settings from config in bot_lifecycle.")
    raise

# Импортируем модуль базы данных
try:
    import database
except ImportError:
    logging.critical("Failed to import database module in bot_lifecycle.")
    raise

# Импортируем модуль AI интерфейса
try:
    from ai_interface import gemini_api
except ImportError:
    logging.critical("Failed to import gemini_api from ai_interface in bot_lifecycle.")
    raise

# Импортируем доступные инструменты
logger.info("Attempting to import tools...") # Или print(...)
try:
    from tools import available_functions as all_available_tools
    logger.info("Successfully imported available_functions from tools.") # Или print(...)
    logger.info(f"Number of functions found by tools init: {len(all_available_tools)}") # Логируем размер словаря
except ImportError as e:
    logger.critical(f"CRITICAL IMPORT ERROR: Failed to import from tools: {e}", exc_info=True) # Или print(...)
    available_functions = {} # Создаем пустой словарь, чтобы бот не упал дальше
except Exception as e:
     logger.critical(f"CRITICAL UNEXPECTED ERROR during tools import: {e}", exc_info=True) # Или print(...)
     available_functions = {}

# --- Типы Google ---
try:
    # <<< ВОЗВРАЩАЕМ glm >>>
    from google.ai import generativelanguage as glm
    Content = glm.Content
    try:
        FinishReason = glm.Candidate.FinishReason
    except AttributeError: FinishReason = None
    # <<< GenerateContentResponse из types >>>
    from google.generativeai.types import GenerateContentResponse

    logger_types = logging.getLogger(__name__)
    logger_types.debug("Successfully imported Google types in bot_lifecycle")
except ImportError as e:
    logger_types = logging.getLogger(__name__)
    logger_types.warning(f"Could not import some Google types in bot_lifecycle: {e}")
    # <<< Обновляем заглушки >>>
    FinishReason, GenerateContentResponse, Content = Any, Any, Any

logger = logging.getLogger(__name__)

async def load_json_file(filepath: Optional[Path]) -> Optional[List[Dict]]: # <<< Принимаем Path
    """Вспомогательная функция для загрузки JSON."""
    if not filepath or not isinstance(filepath, Path) or not filepath.is_file(): # <<< Проверяем Path и is_file()
         logger.warning(f"JSON file path is invalid or file does not exist: {filepath}")
         return None
    try:
        # Открываем Path объект напрямую
        with open(filepath, "r", encoding="utf-8") as f:
            data = json.load(f)
        if not isinstance(data, list):
             logger.error(f"JSON content in {filepath} is not a list.")
             return None
        logger.info(f"Loaded {len(data)} items from {filepath}.")
        return data
    except (json.JSONDecodeError, OSError) as e:
        logger.error(f"Failed loading or parsing JSON file {filepath}: {e}", exc_info=True)
        return None

async def load_text_file(filepath: Optional[Path]) -> Optional[str]: # <<< Принимаем Path
    """Вспомогательная функция для загрузки текстового файла."""
    if not filepath or not isinstance(filepath, Path) or not filepath.is_file(): # <<< Проверяем Path и is_file()
         logger.warning(f"Text file path is invalid or file does not exist: {filepath}")
         return None
    try:
        # Открываем Path объект напрямую
        with open(filepath, "r", encoding="utf-8") as f:
            content = f.read()
        logger.info(f"Loaded text file {filepath} ({len(content)} chars).")
        return content
    except OSError as e:
        logger.error(f"Failed loading text file {filepath}: {e}", exc_info=True)
        return None

def get_current_api_key_index(dp: Dispatcher) -> int:
    """Получает текущий индекс ключа API из workflow_data."""
    return dp.workflow_data.get("current_api_key_index", 0)

def increment_api_key_index(dp: Dispatcher) -> int:
    """Увеличивает индекс ключа API, циклически переходя к началу."""
    keys = dp.workflow_data.get("google_api_keys", [])
    if not keys:
        return 0 # Нет ключей, индекс 0
    current_index = dp.workflow_data.get("current_api_key_index", 0)
    next_index = (current_index + 1) % len(keys)
    dp.workflow_data["current_api_key_index"] = next_index
    logger.info(f"API Key index incremented. New index: {next_index} (Key: ...{keys[next_index][-4:]})")
    return next_index


async def on_startup(dispatcher: Dispatcher):
    """Инициализация ресурсов при старте бота."""
    logger.info("Executing bot startup sequence...")

    # 0. Проверка наличия ключей API
    if not settings.google_api_keys:
         logger.critical("FATAL: No Google API keys found in settings. Cannot initialize models.")
         raise RuntimeError("Missing Google API keys in configuration.")
    logger.info(f"Found {len(settings.google_api_keys)} Google API keys.")

    # 1. Инициализация БД
    try:
        await database.init_db()
        logger.info("Database schema initialized successfully.")
        # <<< Добавляем небольшую паузу для гарантии завершения дисковых операций >>>
        await asyncio.sleep(0.1)
        logger.debug("Short sleep after DB init finished.")
    except Exception as db_init_err:
        logger.critical(f"FATAL: Database initialization failed: {db_init_err}", exc_info=True)
        raise RuntimeError("Database initialization failed") from db_init_err

    # --- 1.5 Запуск NewsService ПОСЛЕ инициализации БД ---
    try:
        from services.news_service import news_service # Импортируем здесь
        if bot is None: # Проверка наличия бота
             raise RuntimeError("Bot instance is None, cannot start NewsService.")
        # Передаем экземпляр бота в сервис новостей.
        asyncio.create_task(news_service.start(bot))
        logger.info("News service background task scheduled after DB init.")
    except ImportError:
        logger.error("Could not import news_service. News feature unavailable.")
    except Exception as news_err:
        logger.error(f"Failed to start news service: {news_err}", exc_info=True)
    # -----------------------------------------------------

    # 2. Загрузка деклараций функций и промптов (ИСПОЛЬЗУЕМ ПУТИ ИЗ settings)
    lite_declarations = None
    pro_declarations = None
    lite_prompt = None
    pro_prompt = None

    try:
        # Загружаем декларации (если пути указаны и файлы существуют)
        if settings.lite_func_decl_file:
            lite_declarations = await load_json_file(settings.lite_func_decl_file) or [] # <<< Используем путь из settings
        if settings.pro_func_decl_file:
            pro_declarations = await load_json_file(settings.pro_func_decl_file) or [] # <<< Используем путь из settings

        # Загружаем промпты (если пути указаны и файлы существуют)
        if settings.lite_prompt_file:
            lite_prompt = await load_text_file(settings.lite_prompt_file) # <<< Используем путь из settings
        if settings.pro_prompt_file:
            pro_prompt = await load_text_file(settings.pro_prompt_file) # <<< Используем путь из settings

    except Exception as load_err:
        logger.error(f"Error loading prompts/declarations: {load_err}", exc_info=True)


    # 3. Инициализация моделей Gemini (ИСПОЛЬЗУЕМ ИМЕНА И НАСТРОЙКИ ИЗ settings)
    lite_models_list: List[genai.GenerativeModel] = []
    pro_models_list: List[genai.GenerativeModel] = []

    for index, api_key in enumerate(settings.google_api_keys):
        logger.info(f"Initializing models for API key index {index} (...{api_key[-4:]})")
        try:
            # --- Важно: Конфигурируем genai ПЕРЕД созданием модели для этого ключа ---
            # Это безопасно здесь, т.к. on_startup выполняется один раз последовательно
            genai.configure(api_key=api_key)
            logger.debug(f"genai configured with API key index {index}.")

            # Инициализация Lite модели для текущего ключа
            current_lite_model = gemini_api.setup_gemini_model(
                api_key=api_key, # Передаем ключ для информации, но genai уже сконфигурирован
                function_declarations_data=lite_declarations,
                model_name=settings.lite_gemini_model_name,
                system_prompt=lite_prompt,
                generation_config=settings.lite_generation_config,
                safety_settings=settings.lite_safety_settings,
                enable_function_calling=False # У Lite нет FC
            )
            if not current_lite_model: raise ValueError(f"Lite model setup returned None for key index {index}")
            lite_models_list.append(current_lite_model)
            logger.info(f"Lite model '{settings.lite_gemini_model_name}' initialized for key index {index}.")

            # Инициализация Pro модели для текущего ключа
            current_pro_model = gemini_api.setup_gemini_model(
                api_key=api_key, # Передаем ключ для информации
                function_declarations_data=pro_declarations,
                model_name=settings.pro_gemini_model_name,
                system_prompt=pro_prompt,
                generation_config=settings.pro_generation_config,
                safety_settings=settings.pro_safety_settings,
                enable_function_calling=settings.fc_enabled
            )
            if not current_pro_model: raise ValueError(f"Pro model setup returned None for key index {index}")
            pro_models_list.append(current_pro_model)
            logger.info(f"Pro model '{settings.pro_gemini_model_name}' initialized for key index {index}.")

        except Exception as model_init_err:
            logger.critical(f"FATAL: Gemini model initialization failed for key index {index}: {model_init_err}", exc_info=True)
            # Можно либо прервать запуск, либо продолжить с теми ключами, что сработали
            # raise RuntimeError(f"Gemini model initialization failed for key index {index}") from model_init_err
            logger.warning(f"Skipping models for key index {index} due to initialization error.")

    # Проверяем, инициализировалась ли хотя бы одна пара моделей
    if not lite_models_list or not pro_models_list:
         logger.critical("FATAL: Failed to initialize at least one pair of Lite/Pro models. Check API keys and configuration.")
         raise RuntimeError("No Gemini models could be initialized.")

    # 4. Маппинг хендлеров инструментов
    logger.info(f"Mapping {len(all_available_tools)} available tool handlers...")
    # Проверка соответствия декларациям (если они были загружены)
    if pro_declarations:
         declared_pro_func_names = {decl.get('name') for decl in pro_declarations if decl.get('name')}
         missing_handlers = declared_pro_func_names - set(all_available_tools.keys())
         if missing_handlers:
             logger.warning(f"Handlers not found for PRO functions declared in JSON: {missing_handlers}")
         extra_handlers = set(all_available_tools.keys()) - declared_pro_func_names
         if extra_handlers:
             logger.warning(f"Found tool handlers that are not declared in PRO JSON: {extra_handlers}")

    # 5. Сохраняем данные в dp.workflow_data
    dispatcher.workflow_data.update({
        # Сохраняем списки
        "lite_models_list": lite_models_list,
        "pro_models_list": pro_models_list,
        # Сохраняем список ключей (может пригодиться для логирования)
        "google_api_keys": settings.google_api_keys,
        # Инициализируем индекс текущего ключа/модели
        "current_api_key_index": 0,
        # Остальные данные
        "available_pro_functions": all_available_tools,
        "max_lite_steps": settings.max_lite_fc_steps,
        "max_pro_steps": settings.max_pro_fc_steps
    })
    logger.info(f"Initialized {len(pro_models_list)} Pro models and {len(lite_models_list)} Lite models.")
    logger.info("Model lists, keys, index, tool handlers, and FC steps added to Dispatcher workflow_data.")

    # 6. Запуск фоновых задач (NewsService перенесен выше)
    # Здесь можно добавить запуск других сервисов, если они есть

    logger.info("Bot startup sequence complete!")


async def on_shutdown(dispatcher: Dispatcher):
    """Действия при остановке бота."""
    logger.info("Executing bot shutdown sequence...")

    # --- Останавливаем фоновые задачи ---
    try:
        from services.news_service import news_service # Импортируем здесь
        await news_service.stop()
        logger.info("News service stopped successfully.")
    except ImportError:
        logger.info("News service module not imported, skipping stop.")
    except Exception as e:
        logger.error(f"Error stopping News service during shutdown: {e}", exc_info=True)
    # (Добавить остановку других сервисов здесь)
    # ----------------------------------

    # Закрываем соединение с БД
    try:
        await database.close_db()
        logger.info("Database connection closed successfully.")
    except Exception as e:
        logger.error(f"Error closing database connection during shutdown: {e}", exc_info=True)

    # Очищаем workflow_data (опционально)
    dispatcher.workflow_data.clear()
    logger.info("Dispatcher workflow_data cleared.")

    # Закрываем сессию бота (aiogram обычно делает это сам при остановке)
    if bot and bot.session:
        try:
            await bot.session.close()
            logger.info("Bot session closed.")
        except Exception as e:
            logger.error(f"Error closing bot session: {e}", exc_info=True)

    logger.info("Bot shutdown sequence complete.")

========== Файл: bot_loader.py ==========

# bot_loader.py

import logging
from aiogram import Bot, Dispatcher
from aiogram.enums import ParseMode
from aiogram.client.default import DefaultBotProperties
from aiogram.fsm.storage.memory import MemoryStorage # Используем MemoryStorage по умолчанию

# Импортируем настройки из корневого config.py
try:
    from config import settings
except ImportError:
    # Заглушка на случай проблем с импортом config
    # В реальном приложении лучше убедиться, что config.py доступен
    class MockSettings:
        bot_token: str = "YOUR_BOT_TOKEN_HERE" # Замените реальным токеном или обработайте ошибку
    settings = MockSettings()
    logging.critical(
        "CRITICAL: Could not import 'settings' from config.py in bot_loader. "
        "Using mock settings. Please check your project structure and config.py."
    )
    # В продакшене здесь лучше выбрасывать исключение или выходить
    # import sys
    # sys.exit("Configuration error: Cannot load settings.")

logger = logging.getLogger(__name__)

# --- Инициализация Хранилища FSM ---
# Используем MemoryStorage, если не требуется более сложное хранилище (например, Redis).
# Для Redis:
# from aiogram.fsm.storage.redis import RedisStorage
# storage = RedisStorage.from_url('redis://localhost:6379/0')
storage = MemoryStorage()
logger.info("FSM storage initialized (MemoryStorage).")

# --- Инициализация Бота ---
# Используем parse_mode=MarkdownV2, так как утилита escape_markdown_v2 работает с ним.
# Убедитесь, что settings.bot_token действительно содержит ваш токен.
try:
    if not settings.bot_token or settings.bot_token == "YOUR_BOT_TOKEN_HERE":
         raise ValueError("Bot token is missing or is a placeholder in config/settings.")

    bot = Bot(
        token=settings.bot_token,
        default=DefaultBotProperties(
            parse_mode=ParseMode.MARKDOWN_V2
        )
    )
    logger.info("Bot instance created successfully.")
except ValueError as ve:
     logger.critical(f"Configuration error: {ve}")
     exit(1) # Выход, если токен не задан
except Exception as e:
    logger.critical(f"Failed to create Bot instance: {e}", exc_info=True)
    exit(1) # Выход из приложения, так как без бота оно не сможет работать

# --- Инициализация Диспетчера ---
# Передаем хранилище в диспетчер.
# workflow_data будет заполняться позже, в bot_lifecycle.on_startup.
try:
    dp = Dispatcher(storage=storage)
    logger.info("Dispatcher instance created successfully.")
except Exception as e:
    logger.critical(f"Failed to create Dispatcher instance: {e}", exc_info=True)
    exit(1)

# Экземпляры bot и dp теперь можно импортировать из этого модуля
# в другие части приложения (например, в bot_lifecycle, handlers),
# чтобы избежать циклических импортов.

========== Файл: config.py ==========

# config.py
import logging
import os
from pathlib import Path
# Добавляем Union для type hinting в валидаторе
from typing import Dict, List, Any, Set, Optional, Union

# Импортируем нужные декораторы и типы из Pydantic
from pydantic import field_validator, ValidationError, Field
from pydantic_settings import BaseSettings, SettingsConfigDict
from dotenv import load_dotenv

# Загружаем переменные из .env файла в окружение ОС (необязательно для Pydantic >v2, но может быть полезно)
load_dotenv()

# Определяем базовую директорию проекта (предполагаем, что config.py находится в ./Agent/)
BASE_DIR = Path(__file__).parent.resolve()
logger = logging.getLogger(__name__)

class Settings(BaseSettings):
    """
    Основные настройки приложения, загружаемые из переменных окружения и файла .env.
    """
    # Конфигурация Pydantic для загрузки из .env
    model_config = SettingsConfigDict(
        env_file=BASE_DIR.parent / '.env', # Ищем .env в родительской директории
        env_file_encoding='utf-8',
        extra='ignore'  # Игнорировать лишние переменные в .env
    )

    # --- Основные ключи и ID ---
    bot_token: str
    google_api_keys: List[str] = Field(default_factory=list)
    # Оставляем тип Set[int] для конечного результата
    admin_ids: Set[int] = set()

    # --- Добавляем Валидатор ---
    @field_validator('google_api_keys', mode='before')
    @classmethod
    def parse_google_api_keys(cls, value: Any) -> List[str]:
        """
        Парсит google_api_keys из строки (через запятую) или списка.
        Фильтрует пустые ключи.
        """
        if isinstance(value, list):
            # Фильтруем пустые строки из списка
            keys = [key.strip() for key in value if isinstance(key, str) and key.strip()]
            if not keys:
                 raise ValueError("GOOGLE_API_KEYS list is empty or contains only invalid entries.")
            return keys
        if isinstance(value, str):
            if not value.strip():
                raise ValueError("GOOGLE_API_KEYS string is empty.")
            # Разделяем по запятой и фильтруем пустые
            keys = [key.strip() for key in value.split(',') if key.strip()]
            if not keys:
                 raise ValueError("GOOGLE_API_KEYS string contains no valid keys after splitting.")
            return keys

        raise ValueError(f"Invalid type for GOOGLE_API_KEYS: {type(value)}. Expected str or list.")


    @field_validator('admin_ids', mode='before')
    @classmethod
    def parse_admin_ids(cls, value: Any) -> Set[int]:
        """
        Парсит admin_ids из строки (через запятую),
        одиночного числа или уже существующего set/list.
        """
        if isinstance(value, set):
            # Если уже set (например, значение по умолчанию)
            return value
        if isinstance(value, str):
            # Если строка, пытаемся разделить по запятой и конвертировать в int
            if not value.strip(): # Обработка пустой строки
                return set()
            try:
                # Убираем пробелы вокруг запятых, фильтруем пустые элементы после split
                return {int(admin_id.strip()) for admin_id in value.split(',') if admin_id.strip()}
            except ValueError as e:
                raise ValueError(f"Invalid integer found in ADMIN_IDS string: {e}") from e
        if isinstance(value, int):
            # Если это одно число, создаем set с ним
            return {value}
        if isinstance(value, list):
            # Если это список (менее вероятно из .env, но возможно)
             try:
                 return {int(item) for item in value}
             except ValueError as e:
                 raise ValueError(f"Invalid integer found in ADMIN_IDS list: {e}") from e

        # Если тип не подходит, выбрасываем ошибку
        raise ValueError(f"Invalid type for ADMIN_IDS: {type(value)}. Expected str, int, list or set.")

    # --- Пути ---
    db_path: str = str(BASE_DIR / "database/bot_db.sqlite") # Путь к БД по умолчанию
    env_dir_path: str = str(BASE_DIR / "env") # Путь к папке окружений по умолчанию
    prompts_dir: Path = BASE_DIR / "prompts"
    declarations_dir: Path = BASE_DIR / "declarations" # Директория для JSON-деклараций (если нужны)

    # --- Настройки AI моделей ---
    lite_gemini_model_name: str = "gemini-1.5-flash-latest"
    #pro_gemini_model_name: str = "gemini-2.0-flash-thinking-exp-01-21"
    pro_gemini_model_name: str = "gemini-2.0-flash"
    #pro_gemini_model_name: str = "gemini-1.5-flash-latest"
    #pro_gemini_model_name: str = "gemini-2.0-pro-exp"
    
    # Пути к файлам промптов
    lite_prompt_file: Path = prompts_dir / "lite_analyzer.txt" # Промпт для Lite-анализатора
    pro_prompt_file: Path = prompts_dir / "pro_assistant.txt"   # Основной промпт для Pro-модели
    deep_search_prompts_dir: Path = prompts_dir / "deep_search"

    # Пути к файлам деклараций функций (если они не встроены в код)
    # Если декларации будут генерироваться динамически или не нужны, эти пути можно убрать
    lite_func_decl_file: Optional[Path] = declarations_dir / "lite_functions.json" # Может быть None, если Lite без FC
    pro_func_decl_file: Optional[Path] = declarations_dir / "pro_functions.json"

    # Параметры генерации (можно переопределить в .env через JSON-строку)
    lite_generation_config: Dict[str, Any] = {"temperature": 0.2} # Более детерминированный для анализа
    pro_generation_config: Dict[str, Any] = {"temperature": 0.7}

    # Настройки безопасности (можно переопределить в .env через JSON-строку)
    lite_safety_settings: List[Dict[str, Any]] = [
        # Пример: BLOCK_NONE для всех категорий для Lite
        {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
        {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
        {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
        {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
    ]
    pro_safety_settings: List[Dict[str, Any]] = [
        # Пример: BLOCK_MEDIUM_AND_ABOVE для Pro (стандартные настройки)
        {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
        {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
        {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
        {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
    ]

    # Параметры Function Calling
    fc_enabled: bool = True # Глобальное включение/выключение FC
    max_lite_fc_steps: int = 1 # Максимум 1 шаг для Lite (если вообще используется)
    max_pro_fc_steps: int = 10 # Больше шагов для Pro

    # --- Настройки Бота и Интерфейса ---
    ai_timeout: int = 40 # Таймаут ожидания ответа от AI (для синхронных вызовов, если есть)
    max_message_length: int = 4000 # Макс. длина сообщения для отправки (близко к лимиту TG)
    max_history_length: int = 10 # Макс. кол-во пар сообщений (user+model) в истории для контекста

    # --- Лимиты Инструментов ---
    max_read_size_bytes: int = 150 * 1024  # 150 KB
    max_write_size_bytes: int = 500 * 1024 # 500 KB
    script_timeout_seconds: int = 45
    command_timeout_seconds: int = 75
    max_script_output_len: int = 6000
    max_command_output_len: int = 6000

    # --- Сервис Новостей ---
    rss_mapping: Dict[str, List[str]] = {
        # Добавьте сюда ваши реальные RSS URL, возможно, читая их из .env через os.getenv
        # Пример:
        "технологии": [
            os.getenv("RSS_TECH_1", "DEFAULT_TECH_URL_1"),
            os.getenv("RSS_TECH_2", "DEFAULT_TECH_URL_2")
        ],
        "наука": [
            os.getenv("RSS_SCIENCE_1", "DEFAULT_SCIENCE_URL_1")
        ],
        # ... другие категории ...
    }

    # --- Общие ---
    log_level: str = "INFO"


# Создаем экземпляр настроек
try:
    settings = Settings()
except ValidationError as e:
     # Выводим ошибки валидации (особенно важно для ключей)
     init_logger = logging.getLogger(__name__)
     init_logger.critical(f"FATAL: Configuration validation failed!")
     init_logger.critical(e)
     exit(1) # Выход, если конфиг некорректен # Теперь эта строка должна отработать корректно

# Настройка логирования
# Базовый формат, можно усложнить (добавить имя файла, номер строки и т.д.)
log_format = "%(asctime)s - %(levelname)s - %(name)s - %(message)s"
# Устанавливаем уровень логирования из настроек
logging.basicConfig(
    level=getattr(logging, settings.log_level.upper(), logging.INFO),
    format=log_format,
    # handlers=[logging.StreamHandler(), logging.FileHandler("bot.log")] # Пример вывода в файл
)
logger = logging.getLogger(__name__)

# Выводим часть настроек в лог при старте (без секретов)
logger.info("Настройки приложения загружены.")
logger.info(f"Уровень логирования: {settings.log_level}")
logger.info(f"Путь к БД: {settings.db_path}")
logger.info(f"Путь к окружениям: {settings.env_dir_path}")
# Логируем результат работы валидатора
logger.info(f"ID Администраторов: {settings.admin_ids if settings.admin_ids else 'Не заданы'}")
logger.info(f"Function Calling включен: {settings.fc_enabled}")
# logger.debug(f"Полные настройки: {settings.model_dump()}") # Для отладки (может содержать секреты!)

========== Файл: main.py ==========

# main.py

import asyncio
import logging
import os # <<< Добавлено для работы с путями >>>

# --- Загрузка основных компонентов ---
# Импортируем в первую очередь, чтобы настроить логирование и получить базовые объекты
try:
    from config import settings, logger # Импортируем настроенный логгер
    from bot_loader import bot, dp
    from bot_lifecycle import on_startup, on_shutdown
    # Импортируем сервисы для фоновых задач
    #from services.news_service import news_service
except ImportError as e:
    logging.basicConfig(level=logging.CRITICAL)
    init_logger = logging.getLogger(__name__)
    init_logger.critical(f"Failed import core components: {e}. Exiting.", exc_info=True)
    exit(1)
except Exception as e:
    logging.basicConfig(level=logging.CRITICAL)
    init_logger = logging.getLogger(__name__)
    init_logger.critical(f"Unexpected error during initial imports: {e}. Exiting.", exc_info=True)
    exit(1)

# --- Импорт и Регистрация Роутеров (Хендлеров) ---
# Порядок регистрации важен! Более специфичные роутеры должны идти раньше.
handlers_imported = False # Флаг для условной регистрации
try:
    from telegram_interface.handlers import (
        admin_commands,
        news_setup_fsm,
        user_commands,
        file_handler,       # Импортируем file_handler
        common_messages,
        error_handler       # Обработчик ошибок лучше регистрировать одним из первых
    )
    handlers_imported = True # Если импорт успешен
    logger.info("Handler modules imported successfully.")
except ImportError as e:
     logger.error(f"Failed to import handler modules: {e}. Some features will be unavailable.", exc_info=True)
except Exception as e:
     logger.error(f"Unexpected error during handler import: {e}.", exc_info=True)

# --- Регистрация роутеров (Только если импорт успешен!) ---
if handlers_imported:
    try:
        # Включаем роутер ошибок (если есть)
        if error_handler and hasattr(error_handler, 'router') and error_handler.router:
            dp.include_router(error_handler.router)
            logger.info("Error handler router registered.")
        else:
            logger.warning("Error handler router not found or invalid, skipping registration.")

        # Включаем роутеры команд и FSM
        if admin_commands and hasattr(admin_commands, 'router') and admin_commands.router:
            dp.include_router(admin_commands.router)
            logger.info("Admin commands router registered.")
        else:
            logger.warning("Admin commands router not found or invalid, skipping registration.")

        if news_setup_fsm and hasattr(news_setup_fsm, 'router') and news_setup_fsm.router:
            dp.include_router(news_setup_fsm.router)
            logger.info("News setup FSM router registered.")
        else:
            logger.warning("News setup FSM router not found or invalid, skipping registration.")

        if user_commands and hasattr(user_commands, 'router') and user_commands.router:
            dp.include_router(user_commands.router)
            logger.info("User commands router registered.")
        else:
            logger.warning("User commands router not found or invalid, skipping registration.")

        # <<< ВАЖНО: Включаем роутер файлов ЗДЕСЬ (перед common_messages) >>>
        if file_handler and hasattr(file_handler, 'router') and file_handler.router:
            dp.include_router(file_handler.router)
            logger.info("File handler router registered.") # <--- Этот лог должен появиться!
        else:
            logger.warning("File handler router not found or invalid, skipping registration.")

        # Роутер для общих сообщений (текст) регистрируем одним из последних
        if common_messages and hasattr(common_messages, 'router') and common_messages.router:
            dp.include_router(common_messages.router)
            logger.info("Common messages router registered.")
        else:
            logger.warning("Common messages router not found or invalid, skipping registration.")

        logger.info("Finished attempting to register all handlers/routers.")

    except Exception as e:
         # Эта ошибка может возникнуть, если сам вызов include_router падает
         logger.error(f"Unexpected error during handler registration process: {e}.", exc_info=True)
else:
    logger.error("Skipping all handler registration due to import errors.")

# --- Регистрация Middleware ---
try:
    # Импортируем классы Middleware
    from telegram_interface.middlewares.antiflood import AntiFloodMiddleware
    from telegram_interface.middlewares.stats_counter import StatsCounterMiddleware

    # Регистрация Middleware (outer - выполняются до фильтров и хендлеров)
    # Порядок важен: антифлуд лучше ставить раньше статистики
    dp.update.outer_middleware(AntiFloodMiddleware(rate_limit=0.7)) # Пример лимита 0.7 сек
    logger.info("AntiFloodMiddleware registered.")

    dp.update.outer_middleware(StatsCounterMiddleware())
    logger.info("StatsCounterMiddleware registered.")

    logger.info("All middlewares registered successfully.")

except ImportError as e:
     logger.warning(f"Could not import middleware: {e}. Running without custom middleware.", exc_info=True)
except Exception as e:
     logger.error(f"Unexpected error during middleware registration: {e}.", exc_info=True)


# --- Основная функция запуска ---
async def main():
    """Основная асинхронная функция запуска бота."""

    # --- Настройка логирования ---
    log_directory = "logs" # <<< Папка для логов >>>
    # <<< ИЗМЕНЕНИЕ: Логика для версионирования файлов логов >>>
    base_log_filename = "bot.log"
    log_file_path = os.path.join(log_directory, base_log_filename)
    log_counter = 1
    # Ищем следующий свободный номер файла
    while os.path.exists(log_file_path):
        log_file_path = os.path.join(log_directory, f"bot_{log_counter}.log")
        log_counter += 1
    # log_file_path теперь содержит путь к новому файлу лога
    # --- КОНЕЦ ИЗМЕНЕНИЯ ---
    # log_file_path = os.path.join(log_directory, "bot.log") # <<< Старый путь, УДАЛЕНО >>>

    # --- Создание папки logs, если не существует ---
    try:
        os.makedirs(log_directory, exist_ok=True)
    except OSError as e:
        # Используем стандартный логгер, т.к. наш еще не настроен
        print(f"CRITICAL: Could not create log directory '{log_directory}': {e}")
        # Попытка продолжить без файлового логгера

    # --- Настройка формата логов ---
    log_format = '%(asctime)s - %(levelname)s - %(name)s - %(message)s'
    log_date_format = '%Y-%m-%d %H:%M:%S'

    # --- Базовая конфигурация (вывод в консоль) ---
    logging.basicConfig(level=logging.INFO, # Устанавливаем INFO как базовый уровень
                        format=log_format,
                        datefmt=log_date_format)

    # --- Получаем корневой логгер ---
    root_logger = logging.getLogger()
    root_logger.setLevel(logging.DEBUG) # Устанавливаем DEBUG для корневого логгера

    # --- Настройка FileHandler (вывод в файл) ---
    try:
        # <<< ИЗМЕНЕНИЕ: Используем найденный log_file_path >>>
        file_handler = logging.FileHandler(log_file_path, encoding='utf-8')
        file_handler.setLevel(logging.DEBUG) # Уровень для файла - DEBUG
        file_formatter = logging.Formatter(log_format, datefmt=log_date_format)
        file_handler.setFormatter(file_formatter)
        root_logger.addHandler(file_handler)
        print(f"INFO: Logging configured. Log file: {log_file_path}") # Сообщение в консоль
    except Exception as e:
        root_logger.critical(f"CRITICAL: Failed to set up file logging to '{log_file_path}': {e}", exc_info=True)

    logger = logging.getLogger(__name__) # Получаем логгер для main.py
    logger.info("--- Bot Startup Sequence Initiated ---")

    # --- Обертываем основной код в try для обработки KeyboardInterrupt/Exception ---
    try:
        # --- Регистрация функций жизненного цикла ---
        # Важно сделать это до запуска поллинга
        dp.startup.register(on_startup)
        dp.shutdown.register(on_shutdown)
        logger.info("Startup and shutdown handlers registered.")

        # --- Запуск фоновых задач ---
        # Запускаем сервис новостей после регистрации startup/shutdown,
        # чтобы он мог корректно запуститься/остановиться.
        # Передаем экземпляр бота в сервис новостей.
        #asyncio.create_task(news_service.start(bot))
        #logger.info("News service background task scheduled.")
        # Добавьте здесь запуск других фоновых сервисов, если они есть

        # --- Удаление вебхука и пропуск старых обновлений ---
        logger.info("Attempting to delete webhook and drop pending updates...")
        try:
            await bot.delete_webhook(drop_pending_updates=True)
            logger.info("Webhook deleted and pending updates dropped successfully.")
        except Exception as e:
            # Не критично, если не удалось, но логируем как warning
            logger.warning(f"Could not delete webhook or drop pending updates: {e}")

        # --- Запуск Поллинга (вложенный try/except/finally) ---
        logger.info("Starting bot polling...")
        try:
            # allowed_updates можно настроить для оптимизации,
            # чтобы получать только нужные типы обновлений.
            # dp.resolve_used_update_types() автоматически определяет используемые типы.
            await dp.start_polling(bot, allowed_updates=dp.resolve_used_update_types())
            # Если не хотите автоопределение:
            # await dp.start_polling(bot)
        except Exception as polling_ex: # Ловим ошибки именно поллинга
            logger.critical(f"Polling failed critically: {polling_ex}", exc_info=True)
        finally:
            # Этот finally выполнится, когда поллинг остановится (штатно или из-за ошибки)
            logger.info("Polling stopped. Initiating shutdown sequence (inner finally)...")
            # Останавливаем фоновые задачи
            # await news_service.stop()
            # (Добавить остановку других сервисов)

            # Закрываем сессию бота (on_shutdown вызывается автоматически при остановке dp)
            # await bot.session.close() # Это обычно делается в on_shutdown
            logger.info("Inner shutdown sequence presumably completed via on_shutdown handler.")

        # Этот лог выполнится, если поллинг завершился штатно (не по Ctrl+C или Exception)
        logger.info("Bot polling finished normally.")

    # --- Обработка остановки (Ctrl+C) и других ошибок на уровне main ---
    except KeyboardInterrupt:
        logger.info("Bot stopped by user (KeyboardInterrupt). Handling within main.")
        # Дополнительные действия при остановке Ctrl+C, если нужно
    except Exception as main_ex:
        logger.critical(f"CRITICAL ERROR during bot lifecycle inside main: {main_ex}", exc_info=True)
    finally:
        # Этот finally выполнится ВСЕГДА при выходе из main (штатно, Ctrl+C, Exception)
        logger.info("--- Entering main() finally block --- ")
        # Важно закрыть соединение с БД в любом случае, даже если поллинг упал
        # Импортируем здесь, чтобы избежать циклического импорта, если main вызовет ошибку раньше
        try:
            from database.connection import close_db
            await close_db()
            logger.info("--- Bot Lifecycle in main() finished. DB connection closed. ---")
        except ImportError:
             logger.error("Failed to import close_db in main finally block.")
        except Exception as db_close_err:
             logger.error(f"Error closing DB connection in main finally block: {db_close_err}")


if __name__ == '__main__':
    # Настраиваем базовое логирование на случай ошибок *до* настройки в main()
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(name)s - %(message)s')
    temp_logger = logging.getLogger(__name__)
    temp_logger.info("Initializing bot application...")
    try:
        # Запускаем асинхронную функцию main
        asyncio.run(main())
    except (KeyboardInterrupt, SystemExit):
        # Корректная остановка по Ctrl+C или SystemExit до или во время запуска main
        temp_logger.info("Bot stopped by user (KeyboardInterrupt/SystemExit) at top level.")
    except Exception as e:
        # Ловим все остальные неожиданные исключения на верхнем уровне (до старта main)
        temp_logger.critical(f"Unhandled exception at main level: {e}", exc_info=True)
        exit(1) # Завершение с кодом ошибки
    finally:
        temp_logger.info("Bot application finished.")

========== Файл: project_dump.txt ==========


========== Файл: a.py ==========

#!/usr/bin/env python3
import os
import sys

# --- Настройки ---
TARGET_EXTENSIONS = {'.py', '.css', '.html', '.ts', '.tsx', '.java', ".json", "prompt", ".txt", ".log"}  # Расширения для поиска
IGNORE_DIRS = {'.venv', 'venv', '.git', 'node_modules', '__pycache__'}  # Папки для игнорирования
OUTPUT_FILENAME = 'project_dump.txt'  # Имя файла для вывода
# --- Конец Настроек ---

def scan_and_dump_project(start_dir, output_file):
    """
    Сканирует директории, начиная от start_dir, ищет файлы с нужными расширениями,
    игнорируя указанные папки, и записывает их относительные пути и содержимое
    в output_file.
    """
    abs_start_dir = os.path.abspath(start_dir)
    print(f"Начинаем сканирование из директории: {abs_start_dir}")
    print(f"Файлы будут сохранены в: {output_file}")
    print(f"Игнорируемые директории: {', '.join(IGNORE_DIRS)}")
    print(f"Искомые расширения: {', '.join(TARGET_EXTENSIONS)}")
    print("-" * 30)

    found_files_count = 0
    processed_files_count = 0

    try:
        with open(output_file, 'w', encoding='utf-8') as outfile:
            # os.walk рекурсивно обходит директории
            for dirpath, dirnames, filenames in os.walk(abs_start_dir, topdown=True):
                # --- Исключение ненужных директорий ---
                # Модифицируем dirnames ПЕРЕД тем, как os.walk пойдет вглубь.
                # Это самый эффективный способ пропустить ненужные ветки.
                dirnames[:] = [d for d in dirnames if d not in IGNORE_DIRS]
                # --------------------------------------

                # print(f"Сканируем: {dirpath}") # Раскомментируйте для детального лога

                for filename in filenames:
                    found_files_count += 1
                    # Проверяем расширение файла
                    _, ext = os.path.splitext(filename)
                    if ext.lower() in TARGET_EXTENSIONS:
                        processed_files_count += 1
                        full_path = os.path.join(dirpath, filename)
                        # Получаем относительный путь от стартовой директории
                        relative_path = os.path.relpath(full_path, abs_start_dir)

                        print(f"  -> Добавляем файл: {relative_path}")

                        # Записываем заголовок с путем
                        outfile.write(f"\n{'=' * 10} Файл: {relative_path} {'=' * 10}\n\n")

                        try:
                            # Читаем содержимое файла
                            with open(full_path, 'r', encoding='utf-8', errors='ignore') as infile:
                                content = infile.read()
                            outfile.write(content)
                            outfile.write("\n") # Добавляем пустую строку для разделения

                        except Exception as e:
                            error_msg = f"  *** Ошибка чтения файла {relative_path}: {e} ***\n"
                            print(error_msg)
                            outfile.write(error_msg)

    except IOError as e:
        print(f"Ошибка записи в файл {output_file}: {e}")
        sys.exit(1) # Выход с кодом ошибки
    except Exception as e:
        print(f"Произошла непредвиденная ошибка: {e}")
        sys.exit(1)

    print("-" * 30)
    print(f"Сканирование завершено.")
    print(f"Найдено файлов всего: {found_files_count}")
    print(f"Обработано (соответствующие расширения): {processed_files_count}")
    print(f"Результат сохранен в файл: {OUTPUT_FILENAME}")

if __name__ == "__main__":
    # Определяем директорию, где находится сам скрипт
    script_location = os.path.dirname(os.path.abspath(__file__))
    output_filepath = os.path.join(script_location, OUTPUT_FILENAME)

    scan_and_dump_project(script_location, output_filepath)

========== Файл: bot_lifecycle.py ==========

# ./Agent/bot_lifecycle.py

import logging
import inspect
import json
import os  # <<< Добавили импорт os
import asyncio # <<< Добавили импорт asyncio
from typing import Dict, Any, Callable, Optional, List
from pathlib import Path  # <<< Добавили импорт Path
from aiogram import Dispatcher  # <<< Добавили импорт Dispatcher
import google.generativeai as genai

logger = logging.getLogger(__name__)

# --- Основные зависимости ---
# Импортируем Bot и Dispatcher из загрузчика
try:
    from bot_loader import dp, bot
except ImportError:
    logging.critical("Failed to import dp, bot from bot_loader in bot_lifecycle.")
    raise

# Импортируем настройки (теперь только сам объект settings)
try:
    from config import settings
except ImportError:
    logging.critical("Failed to import settings from config in bot_lifecycle.")
    raise

# Импортируем модуль базы данных
try:
    import database
except ImportError:
    logging.critical("Failed to import database module in bot_lifecycle.")
    raise

# Импортируем модуль AI интерфейса
try:
    from ai_interface import gemini_api
except ImportError:
    logging.critical("Failed to import gemini_api from ai_interface in bot_lifecycle.")
    raise

# Импортируем доступные инструменты
logger.info("Attempting to import tools...") # Или print(...)
try:
    from tools import available_functions as all_available_tools
    logger.info("Successfully imported available_functions from tools.") # Или print(...)
    logger.info(f"Number of functions found by tools init: {len(all_available_tools)}") # Логируем размер словаря
except ImportError as e:
    logger.critical(f"CRITICAL IMPORT ERROR: Failed to import from tools: {e}", exc_info=True) # Или print(...)
    available_functions = {} # Создаем пустой словарь, чтобы бот не упал дальше
except Exception as e:
     logger.critical(f"CRITICAL UNEXPECTED ERROR during tools import: {e}", exc_info=True) # Или print(...)
     available_functions = {}

# --- Типы Google ---
try:
    # <<< ВОЗВРАЩАЕМ glm >>>
    from google.ai import generativelanguage as glm
    Content = glm.Content
    try:
        FinishReason = glm.Candidate.FinishReason
    except AttributeError: FinishReason = None
    # <<< GenerateContentResponse из types >>>
    from google.generativeai.types import GenerateContentResponse

    logger_types = logging.getLogger(__name__)
    logger_types.debug("Successfully imported Google types in bot_lifecycle")
except ImportError as e:
    logger_types = logging.getLogger(__name__)
    logger_types.warning(f"Could not import some Google types in bot_lifecycle: {e}")
    # <<< Обновляем заглушки >>>
    FinishReason, GenerateContentResponse, Content = Any, Any, Any

logger = logging.getLogger(__name__)

async def load_json_file(filepath: Optional[Path]) -> Optional[List[Dict]]: # <<< Принимаем Path
    """Вспомогательная функция для загрузки JSON."""
    if not filepath or not isinstance(filepath, Path) or not filepath.is_file(): # <<< Проверяем Path и is_file()
         logger.warning(f"JSON file path is invalid or file does not exist: {filepath}")
         return None
    try:
        # Открываем Path объект напрямую
        with open(filepath, "r", encoding="utf-8") as f:
            data = json.load(f)
        if not isinstance(data, list):
             logger.error(f"JSON content in {filepath} is not a list.")
             return None
        logger.info(f"Loaded {len(data)} items from {filepath}.")
        return data
    except (json.JSONDecodeError, OSError) as e:
        logger.error(f"Failed loading or parsing JSON file {filepath}: {e}", exc_info=True)
        return None

async def load_text_file(filepath: Optional[Path]) -> Optional[str]: # <<< Принимаем Path
    """Вспомогательная функция для загрузки текстового файла."""
    if not filepath or not isinstance(filepath, Path) or not filepath.is_file(): # <<< Проверяем Path и is_file()
         logger.warning(f"Text file path is invalid or file does not exist: {filepath}")
         return None
    try:
        # Открываем Path объект напрямую
        with open(filepath, "r", encoding="utf-8") as f:
            content = f.read()
        logger.info(f"Loaded text file {filepath} ({len(content)} chars).")
        return content
    except OSError as e:
        logger.error(f"Failed loading text file {filepath}: {e}", exc_info=True)
        return None

def get_current_api_key_index(dp: Dispatcher) -> int:
    """Получает текущий индекс ключа API из workflow_data."""
    return dp.workflow_data.get("current_api_key_index", 0)

def increment_api_key_index(dp: Dispatcher) -> int:
    """Увеличивает индекс ключа API, циклически переходя к началу."""
    keys = dp.workflow_data.get("google_api_keys", [])
    if not keys:
        return 0 # Нет ключей, индекс 0
    current_index = dp.workflow_data.get("current_api_key_index", 0)
    next_index = (current_index + 1) % len(keys)
    dp.workflow_data["current_api_key_index"] = next_index
    logger.info(f"API Key index incremented. New index: {next_index} (Key: ...{keys[next_index][-4:]})")
    return next_index


async def on_startup(dispatcher: Dispatcher):
    """Инициализация ресурсов при старте бота."""
    logger.info("Executing bot startup sequence...")

    # 0. Проверка наличия ключей API
    if not settings.google_api_keys:
         logger.critical("FATAL: No Google API keys found in settings. Cannot initialize models.")
         raise RuntimeError("Missing Google API keys in configuration.")
    logger.info(f"Found {len(settings.google_api_keys)} Google API keys.")

    # 1. Инициализация БД
    try:
        await database.init_db()
        logger.info("Database schema initialized successfully.")
        # <<< Добавляем небольшую паузу для гарантии завершения дисковых операций >>>
        await asyncio.sleep(0.1)
        logger.debug("Short sleep after DB init finished.")
    except Exception as db_init_err:
        logger.critical(f"FATAL: Database initialization failed: {db_init_err}", exc_info=True)
        raise RuntimeError("Database initialization failed") from db_init_err

    # --- 1.5 Запуск NewsService ПОСЛЕ инициализации БД ---
    try:
        from services.news_service import news_service # Импортируем здесь
        if bot is None: # Проверка наличия бота
             raise RuntimeError("Bot instance is None, cannot start NewsService.")
        # Передаем экземпляр бота в сервис новостей.
        asyncio.create_task(news_service.start(bot))
        logger.info("News service background task scheduled after DB init.")
    except ImportError:
        logger.error("Could not import news_service. News feature unavailable.")
    except Exception as news_err:
        logger.error(f"Failed to start news service: {news_err}", exc_info=True)
    # -----------------------------------------------------

    # 2. Загрузка деклараций функций и промптов (ИСПОЛЬЗУЕМ ПУТИ ИЗ settings)
    lite_declarations = None
    pro_declarations = None
    lite_prompt = None
    pro_prompt = None

    try:
        # Загружаем декларации (если пути указаны и файлы существуют)
        if settings.lite_func_decl_file:
            lite_declarations = await load_json_file(settings.lite_func_decl_file) or [] # <<< Используем путь из settings
        if settings.pro_func_decl_file:
            pro_declarations = await load_json_file(settings.pro_func_decl_file) or [] # <<< Используем путь из settings

        # Загружаем промпты (если пути указаны и файлы существуют)
        if settings.lite_prompt_file:
            lite_prompt = await load_text_file(settings.lite_prompt_file) # <<< Используем путь из settings
        if settings.pro_prompt_file:
            pro_prompt = await load_text_file(settings.pro_prompt_file) # <<< Используем путь из settings

    except Exception as load_err:
        logger.error(f"Error loading prompts/declarations: {load_err}", exc_info=True)


    # 3. Инициализация моделей Gemini (ИСПОЛЬЗУЕМ ИМЕНА И НАСТРОЙКИ ИЗ settings)
    lite_models_list: List[genai.GenerativeModel] = []
    pro_models_list: List[genai.GenerativeModel] = []

    for index, api_key in enumerate(settings.google_api_keys):
        logger.info(f"Initializing models for API key index {index} (...{api_key[-4:]})")
        try:
            # --- Важно: Конфигурируем genai ПЕРЕД созданием модели для этого ключа ---
            # Это безопасно здесь, т.к. on_startup выполняется один раз последовательно
            genai.configure(api_key=api_key)
            logger.debug(f"genai configured with API key index {index}.")

            # Инициализация Lite модели для текущего ключа
            current_lite_model = gemini_api.setup_gemini_model(
                api_key=api_key, # Передаем ключ для информации, но genai уже сконфигурирован
                function_declarations_data=lite_declarations,
                model_name=settings.lite_gemini_model_name,
                system_prompt=lite_prompt,
                generation_config=settings.lite_generation_config,
                safety_settings=settings.lite_safety_settings,
                enable_function_calling=False # У Lite нет FC
            )
            if not current_lite_model: raise ValueError(f"Lite model setup returned None for key index {index}")
            lite_models_list.append(current_lite_model)
            logger.info(f"Lite model '{settings.lite_gemini_model_name}' initialized for key index {index}.")

            # Инициализация Pro модели для текущего ключа
            current_pro_model = gemini_api.setup_gemini_model(
                api_key=api_key, # Передаем ключ для информации
                function_declarations_data=pro_declarations,
                model_name=settings.pro_gemini_model_name,
                system_prompt=pro_prompt,
                generation_config=settings.pro_generation_config,
                safety_settings=settings.pro_safety_settings,
                enable_function_calling=settings.fc_enabled
            )
            if not current_pro_model: raise ValueError(f"Pro model setup returned None for key index {index}")
            pro_models_list.append(current_pro_model)
            logger.info(f"Pro model '{settings.pro_gemini_model_name}' initialized for key index {index}.")

        except Exception as model_init_err:
            logger.critical(f"FATAL: Gemini model initialization failed for key index {index}: {model_init_err}", exc_info=True)
            # Можно либо прервать запуск, либо продолжить с теми ключами, что сработали
            # raise RuntimeError(f"Gemini model initialization failed for key index {index}") from model_init_err
            logger.warning(f"Skipping models for key index {index} due to initialization error.")

    # Проверяем, инициализировалась ли хотя бы одна пара моделей
    if not lite_models_list or not pro_models_list:
         logger.critical("FATAL: Failed to initialize at least one pair of Lite/Pro models. Check API keys and configuration.")
         raise RuntimeError("No Gemini models could be initialized.")

    # 4. Маппинг хендлеров инструментов
    logger.info(f"Mapping {len(all_available_tools)} available tool handlers...")
    # Проверка соответствия декларациям (если они были загружены)
    if pro_declarations:
         declared_pro_func_names = {decl.get('name') for decl in pro_declarations if decl.get('name')}
         missing_handlers = declared_pro_func_names - set(all_available_tools.keys())
         if missing_handlers:
             logger.warning(f"Handlers not found for PRO functions declared in JSON: {missing_handlers}")
         extra_handlers = set(all_available_tools.keys()) - declared_pro_func_names
         if extra_handlers:
             logger.warning(f"Found tool handlers that are not declared in PRO JSON: {extra_handlers}")

    # 5. Сохраняем данные в dp.workflow_data
    dispatcher.workflow_data.update({
        # Сохраняем списки
        "lite_models_list": lite_models_list,
        "pro_models_list": pro_models_list,
        # Сохраняем список ключей (может пригодиться для логирования)
        "google_api_keys": settings.google_api_keys,
        # Инициализируем индекс текущего ключа/модели
        "current_api_key_index": 0,
        # Остальные данные
        "available_pro_functions": all_available_tools,
        "max_lite_steps": settings.max_lite_fc_steps,
        "max_pro_steps": settings.max_pro_fc_steps
    })
    logger.info(f"Initialized {len(pro_models_list)} Pro models and {len(lite_models_list)} Lite models.")
    logger.info("Model lists, keys, index, tool handlers, and FC steps added to Dispatcher workflow_data.")

    # 6. Запуск фоновых задач (NewsService перенесен выше)
    # Здесь можно добавить запуск других сервисов, если они есть

    logger.info("Bot startup sequence complete!")


async def on_shutdown(dispatcher: Dispatcher):
    """Действия при остановке бота."""
    logger.info("Executing bot shutdown sequence...")

    # --- Останавливаем фоновые задачи ---
    try:
        from services.news_service import news_service # Импортируем здесь
        await news_service.stop()
        logger.info("News service stopped successfully.")
    except ImportError:
        logger.info("News service module not imported, skipping stop.")
    except Exception as e:
        logger.error(f"Error stopping News service during shutdown: {e}", exc_info=True)
    # (Добавить остановку других сервисов здесь)
    # ----------------------------------

    # Закрываем соединение с БД
    try:
        await database.close_db()
        logger.info("Database connection closed successfully.")
    except Exception as e:
        logger.error(f"Error closing database connection during shutdown: {e}", exc_info=True)

    # Очищаем workflow_data (опционально)
    dispatcher.workflow_data.clear()
    logger.info("Dispatcher workflow_data cleared.")

    # Закрываем сессию бота (aiogram обычно делает это сам при остановке)
    if bot and bot.session:
        try:
            await bot.session.close()
            logger.info("Bot session closed.")
        except Exception as e:
            logger.error(f"Error closing bot session: {e}", exc_info=True)

    logger.info("Bot shutdown sequence complete.")

========== Файл: bot_loader.py ==========

# bot_loader.py

import logging
from aiogram import Bot, Dispatcher
from aiogram.enums import ParseMode
from aiogram.client.default import DefaultBotProperties
from aiogram.fsm.storage.memory import MemoryStorage # Используем MemoryStorage по умолчанию

# Импортируем настройки из корневого config.py
try:
    from config import settings
except ImportError:
    # Заглушка на случай проблем с импортом config
    # В реальном приложении лучше убедиться, что config.py доступен
    class MockSettings:
        bot_token: str = "YOUR_BOT_TOKEN_HERE" # Замените реальным токеном или обработайте ошибку
    settings = MockSettings()
    logging.critical(
        "CRITICAL: Could not import 'settings' from config.py in bot_loader. "
        "Using mock settings. Please check your project structure and config.py."
    )
    # В продакшене здесь лучше выбрасывать исключение или выходить
    # import sys
    # sys.exit("Configuration error: Cannot load settings.")

logger = logging.getLogger(__name__)

# --- Инициализация Хранилища FSM ---
# Используем MemoryStorage, если не требуется более сложное хранилище (например, Redis).
# Для Redis:
# from aiogram.fsm.storage.redis import RedisStorage
# storage = RedisStorage.from_url('redis://localhost:6379/0')
storage = MemoryStorage()
logger.info("FSM storage initialized (MemoryStorage).")

# --- Инициализация Бота ---
# Используем parse_mode=MarkdownV2, так как утилита escape_markdown_v2 работает с ним.
# Убедитесь, что settings.bot_token действительно содержит ваш токен.
try:
    if not settings.bot_token or settings.bot_token == "YOUR_BOT_TOKEN_HERE":
         raise ValueError("Bot token is missing or is a placeholder in config/settings.")

    bot = Bot(
        token=settings.bot_token,
        default=DefaultBotProperties(
            parse_mode=ParseMode.MARKDOWN_V2
        )
    )
    logger.info("Bot instance created successfully.")
except ValueError as ve:
     logger.critical(f"Configuration error: {ve}")
     exit(1) # Выход, если токен не задан
except Exception as e:
    logger.critical(f"Failed to create Bot instance: {e}", exc_info=True)
    exit(1) # Выход из приложения, так как без бота оно не сможет работать

# --- Инициализация Диспетчера ---
# Передаем хранилище в диспетчер.
# workflow_data будет заполняться позже, в bot_lifecycle.on_startup.
try:
    dp = Dispatcher(storage=storage)
    logger.info("Dispatcher instance created successfully.")
except Exception as e:
    logger.critical(f"Failed to create Dispatcher instance: {e}", exc_info=True)
    exit(1)

# Экземпляры bot и dp теперь можно импортировать из этого модуля
# в другие части приложения (например, в bot_lifecycle, handlers),
# чтобы избежать циклических импортов.

========== Файл: config.py ==========

# config.py
import logging
import os
from pathlib import Path
# Добавляем Union для type hinting в валидаторе
from typing import Dict, List, Any, Set, Optional, Union

# Импортируем нужные декораторы и типы из Pydantic
from pydantic import field_validator, ValidationError, Field
from pydantic_settings import BaseSettings, SettingsConfigDict
from dotenv import load_dotenv

# Загружаем переменные из .env файла в окружение ОС (необязательно для Pydantic >v2, но может быть полезно)
load_dotenv()

# Определяем базовую директорию проекта (предполагаем, что config.py находится в ./Agent/)
BASE_DIR = Path(__file__).parent.resolve()
logger = logging.getLogger(__name__)

class Settings(BaseSettings):
    """
    Основные настройки приложения, загружаемые из переменных окружения и файла .env.
    """
    # Конфигурация Pydantic для загрузки из .env
    model_config = SettingsConfigDict(
        env_file=BASE_DIR.parent / '.env', # Ищем .env в родительской директории
        env_file_encoding='utf-8',
        extra='ignore'  # Игнорировать лишние переменные в .env
    )

    # --- Основные ключи и ID ---
    bot_token: str
    google_api_keys: List[str] = Field(default_factory=list)
    # Оставляем тип Set[int] для конечного результата
    admin_ids: Set[int] = set()

    # --- Добавляем Валидатор ---
    @field_validator('google_api_keys', mode='before')
    @classmethod
    def parse_google_api_keys(cls, value: Any) -> List[str]:
        """
        Парсит google_api_keys из строки (через запятую) или списка.
        Фильтрует пустые ключи.
        """
        if isinstance(value, list):
            # Фильтруем пустые строки из списка
            keys = [key.strip() for key in value if isinstance(key, str) and key.strip()]
            if not keys:
                 raise ValueError("GOOGLE_API_KEYS list is empty or contains only invalid entries.")
            return keys
        if isinstance(value, str):
            if not value.strip():
                raise ValueError("GOOGLE_API_KEYS string is empty.")
            # Разделяем по запятой и фильтруем пустые
            keys = [key.strip() for key in value.split(',') if key.strip()]
            if not keys:
                 raise ValueError("GOOGLE_API_KEYS string contains no valid keys after splitting.")
            return keys

        raise ValueError(f"Invalid type for GOOGLE_API_KEYS: {type(value)}. Expected str or list.")


    @field_validator('admin_ids', mode='before')
    @classmethod
    def parse_admin_ids(cls, value: Any) -> Set[int]:
        """
        Парсит admin_ids из строки (через запятую),
        одиночного числа или уже существующего set/list.
        """
        if isinstance(value, set):
            # Если уже set (например, значение по умолчанию)
            return value
        if isinstance(value, str):
            # Если строка, пытаемся разделить по запятой и конвертировать в int
            if not value.strip(): # Обработка пустой строки
                return set()
            try:
                # Убираем пробелы вокруг запятых, фильтруем пустые элементы после split
                return {int(admin_id.strip()) for admin_id in value.split(',') if admin_id.strip()}
            except ValueError as e:
                raise ValueError(f"Invalid integer found in ADMIN_IDS string: {e}") from e
        if isinstance(value, int):
            # Если это одно число, создаем set с ним
            return {value}
        if isinstance(value, list):
            # Если это список (менее вероятно из .env, но возможно)
             try:
                 return {int(item) for item in value}
             except ValueError as e:
                 raise ValueError(f"Invalid integer found in ADMIN_IDS list: {e}") from e

        # Если тип не подходит, выбрасываем ошибку
        raise ValueError(f"Invalid type for ADMIN_IDS: {type(value)}. Expected str, int, list or set.")

    # --- Пути ---
    db_path: str = str(BASE_DIR / "database/bot_db.sqlite") # Путь к БД по умолчанию
    env_dir_path: str = str(BASE_DIR / "env") # Путь к папке окружений по умолчанию
    prompts_dir: Path = BASE_DIR / "prompts"
    declarations_dir: Path = BASE_DIR / "declarations" # Директория для JSON-деклараций (если нужны)

    # --- Настройки AI моделей ---
    lite_gemini_model_name: str = "gemini-1.5-flash-latest"
    #pro_gemini_model_name: str = "gemini-2.0-flash-thinking-exp-01-21"
    pro_gemini_model_name: str = "gemini-2.0-flash"
    #pro_gemini_model_name: str = "gemini-1.5-flash-latest"
    #pro_gemini_model_name: str = "gemini-2.0-pro-exp"
    
    # Пути к файлам промптов
    lite_prompt_file: Path = prompts_dir / "lite_analyzer.txt" # Промпт для Lite-анализатора
    pro_prompt_file: Path = prompts_dir / "pro_assistant.txt"   # Основной промпт для Pro-модели
    deep_search_prompts_dir: Path = prompts_dir / "deep_search"

    # Пути к файлам деклараций функций (если они не встроены в код)
    # Если декларации будут генерироваться динамически или не нужны, эти пути можно убрать
    lite_func_decl_file: Optional[Path] = declarations_dir / "lite_functions.json" # Может быть None, если Lite без FC
    pro_func_decl_file: Optional[Path] = declarations_dir / "pro_functions.json"

    # Параметры генерации (можно переопределить в .env через JSON-строку)
    lite_generation_config: Dict[str, Any] = {"temperature": 0.2} # Более детерминированный для анализа
    pro_generation_config: Dict[str, Any] = {"temperature": 0.7}

    # Настройки безопасности (можно переопределить в .env через JSON-строку)
    lite_safety_settings: List[Dict[str, Any]] = [
        # Пример: BLOCK_NONE для всех категорий для Lite
        {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
        {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
        {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
        {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
    ]
    pro_safety_settings: List[Dict[str, Any]] = [
        # Пример: BLOCK_MEDIUM_AND_ABOVE для Pro (стандартные настройки)
        {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
        {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
        {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
        {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
    ]

    # Параметры Function Calling
    fc_enabled: bool = True # Глобальное включение/выключение FC
    max_lite_fc_steps: int = 1 # Максимум 1 шаг для Lite (если вообще используется)
    max_pro_fc_steps: int = 10 # Больше шагов для Pro

    # --- Настройки Бота и Интерфейса ---
    ai_timeout: int = 40 # Таймаут ожидания ответа от AI (для синхронных вызовов, если есть)
    max_message_length: int = 4000 # Макс. длина сообщения для отправки (близко к лимиту TG)
    max_history_length: int = 10 # Макс. кол-во пар сообщений (user+model) в истории для контекста

    # --- Лимиты Инструментов ---
    max_read_size_bytes: int = 150 * 1024  # 150 KB
    max_write_size_bytes: int = 500 * 1024 # 500 KB
    script_timeout_seconds: int = 45
    command_timeout_seconds: int = 75
    max_script_output_len: int = 6000
    max_command_output_len: int = 6000

    # --- Сервис Новостей ---
    rss_mapping: Dict[str, List[str]] = {
        # Добавьте сюда ваши реальные RSS URL, возможно, читая их из .env через os.getenv
        # Пример:
        "технологии": [
            os.getenv("RSS_TECH_1", "DEFAULT_TECH_URL_1"),
            os.getenv("RSS_TECH_2", "DEFAULT_TECH_URL_2")
        ],
        "наука": [
            os.getenv("RSS_SCIENCE_1", "DEFAULT_SCIENCE_URL_1")
        ],
        # ... другие категории ...
    }

    # --- Общие ---
    log_level: str = "INFO"


# Создаем экземпляр настроек
try:
    settings = Settings()
except ValidationError as e:
     # Выводим ошибки валидации (особенно важно для ключей)
     init_logger = logging.getLogger(__name__)
     init_logger.critical(f"FATAL: Configuration validation failed!")
     init_logger.critical(e)
     exit(1) # Выход, если конфиг некорректен # Теперь эта строка должна отработать корректно

# Настройка логирования
# Базовый формат, можно усложнить (добавить имя файла, номер строки и т.д.)
log_format = "%(asctime)s - %(levelname)s - %(name)s - %(message)s"
# Устанавливаем уровень логирования из настроек
logging.basicConfig(
    level=getattr(logging, settings.log_level.upper(), logging.INFO),
    format=log_format,
    # handlers=[logging.StreamHandler(), logging.FileHandler("bot.log")] # Пример вывода в файл
)
logger = logging.getLogger(__name__)

# Выводим часть настроек в лог при старте (без секретов)
logger.info("Настройки приложения загружены.")
logger.info(f"Уровень логирования: {settings.log_level}")
logger.info(f"Путь к БД: {settings.db_path}")
logger.info(f"Путь к окружениям: {settings.env_dir_path}")
# Логируем результат работы валидатора
logger.info(f"ID Администраторов: {settings.admin_ids if settings.admin_ids else 'Не заданы'}")
logger.info(f"Function Calling включен: {settings.fc_enabled}")
# logger.debug(f"Полные настройки: {settings.model_dump()}") # Для отладки (может содержать секреты!)

========== Файл: main.py ==========

# main.py

import asyncio
import logging
import os # <<< Добавлено для работы с путями >>>

# --- Загрузка основных компонентов ---
# Импортируем в первую очередь, чтобы настроить логирование и получить базовые объекты
try:
    from config import settings, logger # Импортируем настроенный логгер
    from bot_loader import bot, dp
    from bot_lifecycle import on_startup, on_shutdown
    # Импортируем сервисы для фоновых задач
    #from services.news_service import news_service
except ImportError as e:
    logging.basicConfig(level=logging.CRITICAL)
    init_logger = logging.getLogger(__name__)
    init_logger.critical(f"Failed import core components: {e}. Exiting.", exc_info=True)
    exit(1)
except Exception as e:
    logging.basicConfig(level=logging.CRITICAL)
    init_logger = logging.getLogger(__name__)
    init_logger.critical(f"Unexpected error during initial imports: {e}. Exiting.", exc_info=True)
    exit(1)

# --- Импорт и Регистрация Роутеров (Хендлеров) ---
# Порядок регистрации важен! Более специфичные роутеры должны идти раньше.
handlers_imported = False # Флаг для условной регистрации
try:
    from telegram_interface.handlers import (
        admin_commands,
        news_setup_fsm,
        user_commands,
        file_handler,       # Импортируем file_handler
        common_messages,
        error_handler       # Обработчик ошибок лучше регистрировать одним из первых
    )
    handlers_imported = True # Если импорт успешен
    logger.info("Handler modules imported successfully.")
except ImportError as e:
     logger.error(f"Failed to import handler modules: {e}. Some features will be unavailable.", exc_info=True)
except Exception as e:
     logger.error(f"Unexpected error during handler import: {e}.", exc_info=True)

# --- Регистрация роутеров (Только если импорт успешен!) ---
if handlers_imported:
    try:
        # Включаем роутер ошибок (если есть)
        if error_handler and hasattr(error_handler, 'router') and error_handler.router:
            dp.include_router(error_handler.router)
            logger.info("Error handler router registered.")
        else:
            logger.warning("Error handler router not found or invalid, skipping registration.")

        # Включаем роутеры команд и FSM
        if admin_commands and hasattr(admin_commands, 'router') and admin_commands.router:
            dp.include_router(admin_commands.router)
            logger.info("Admin commands router registered.")
        else:
            logger.warning("Admin commands router not found or invalid, skipping registration.")

        if news_setup_fsm and hasattr(news_setup_fsm, 'router') and news_setup_fsm.router:
            dp.include_router(news_setup_fsm.router)
            logger.info("News setup FSM router registered.")
        else:
            logger.warning("News setup FSM router not found or invalid, skipping registration.")

        if user_commands and hasattr(user_commands, 'router') and user_commands.router:
            dp.include_router(user_commands.router)
            logger.info("User commands router registered.")
        else:
            logger.warning("User commands router not found or invalid, skipping registration.")

        # <<< ВАЖНО: Включаем роутер файлов ЗДЕСЬ (перед common_messages) >>>
        if file_handler and hasattr(file_handler, 'router') and file_handler.router:
            dp.include_router(file_handler.router)
            logger.info("File handler router registered.") # <--- Этот лог должен появиться!
        else:
            logger.warning("File handler router not found or invalid, skipping registration.")

        # Роутер для общих сообщений (текст) регистрируем одним из последних
        if common_messages and hasattr(common_messages, 'router') and common_messages.router:
            dp.include_router(common_messages.router)
            logger.info("Common messages router registered.")
        else:
            logger.warning("Common messages router not found or invalid, skipping registration.")

        logger.info("Finished attempting to register all handlers/routers.")

    except Exception as e:
         # Эта ошибка может возникнуть, если сам вызов include_router падает
         logger.error(f"Unexpected error during handler registration process: {e}.", exc_info=True)
else:
    logger.error("Skipping all handler registration due to import errors.")

# --- Регистрация Middleware ---
try:
    # Импортируем классы Middleware
    from telegram_interface.middlewares.antiflood import AntiFloodMiddleware
    from telegram_interface.middlewares.stats_counter import StatsCounterMiddleware

    # Регистрация Middleware (outer - выполняются до фильтров и хендлеров)
    # Порядок важен: антифлуд лучше ставить раньше статистики
    dp.update.outer_middleware(AntiFloodMiddleware(rate_limit=0.7)) # Пример лимита 0.7 сек
    logger.info("AntiFloodMiddleware registered.")

    dp.update.outer_middleware(StatsCounterMiddleware())
    logger.info("StatsCounterMiddleware registered.")

    logger.info("All middlewares registered successfully.")

except ImportError as e:
     logger.warning(f"Could not import middleware: {e}. Running without custom middleware.", exc_info=True)
except Exception as e:
     logger.error(f"Unexpected error during middleware registration: {e}.", exc_info=True)


# --- Основная функция запуска ---
async def main():
    """Основная асинхронная функция запуска бота."""

    # --- Настройка логирования ---
    log_directory = "logs" # <<< Папка для логов >>>
    # <<< ИЗМЕНЕНИЕ: Логика для версионирования файлов логов >>>
    base_log_filename = "bot.log"
    log_file_path = os.path.join(log_directory, base_log_filename)
    log_counter = 1
    # Ищем следующий свободный номер файла
    while os.path.exists(log_file_path):
        log_file_path = os.path.join(log_directory, f"bot_{log_counter}.log")
        log_counter += 1
    # log_file_path теперь содержит путь к новому файлу лога
    # --- КОНЕЦ ИЗМЕНЕНИЯ ---
    # log_file_path = os.path.join(log_directory, "bot.log") # <<< Старый путь, УДАЛЕНО >>>

    # --- Создание папки logs, если не существует ---
    try:
        os.makedirs(log_directory, exist_ok=True)
    except OSError as e:
        # Используем стандартный логгер, т.к. наш еще не настроен
        print(f"CRITICAL: Could not create log directory '{log_directory}': {e}")
        # Попытка продолжить без файлового логгера

    # --- Настройка формата логов ---
    log_format = '%(asctime)s - %(levelname)s - %(name)s - %(message)s'
    log_date_format = '%Y-%m-%d %H:%M:%S'

    # --- Базовая конфигурация (вывод в консоль) ---
    logging.basicConfig(level=logging.INFO, # Устанавливаем INFO как базовый уровень
                        format=log_format,
                        datefmt=log_date_format)

    # --- Получаем корневой логгер ---
    root_logger = logging.getLogger()
    root_logger.setLevel(logging.DEBUG) # Устанавливаем DEBUG для корневого логгера

    # --- Настройка FileHandler (вывод в файл) ---
    try:
        # <<< ИЗМЕНЕНИЕ: Используем найденный log_file_path >>>
        file_handler = logging.FileHandler(log_file_path, encoding='utf-8')
        file_handler.setLevel(logging.DEBUG) # Уровень для файла - DEBUG
        file_formatter = logging.Formatter(log_format, datefmt=log_date_format)
        file_handler.setFormatter(file_formatter)
        root_logger.addHandler(file_handler)
        print(f"INFO: Logging configured. Log file: {log_file_path}") # Сообщение в консоль
    except Exception as e:
        root_logger.critical(f"CRITICAL: Failed to set up file logging to '{log_file_path}': {e}", exc_info=True)

    logger = logging.getLogger(__name__) # Получаем логгер для main.py
    logger.info("--- Bot Startup Sequence Initiated ---")

    # --- Обертываем основной код в try для обработки KeyboardInterrupt/Exception ---
    try:
        # --- Регистрация функций жизненного цикла ---
        # Важно сделать это до запуска поллинга
        dp.startup.register(on_startup)
        dp.shutdown.register(on_shutdown)
        logger.info("Startup and shutdown handlers registered.")

        # --- Запуск фоновых задач ---
        # Запускаем сервис новостей после регистрации startup/shutdown,
        # чтобы он мог корректно запуститься/остановиться.
        # Передаем экземпляр бота в сервис новостей.
        #asyncio.create_task(news_service.start(bot))
        #logger.info("News service background task scheduled.")
        # Добавьте здесь запуск других фоновых сервисов, если они есть

        # --- Удаление вебхука и пропуск старых обновлений ---
        logger.info("Attempting to delete webhook and drop pending updates...")
        try:
            await bot.delete_webhook(drop_pending_updates=True)
            logger.info("Webhook deleted and pending updates dropped successfully.")
        except Exception as e:
            # Не критично, если не удалось, но логируем как warning
            logger.warning(f"Could not delete webhook or drop pending updates: {e}")

        # --- Запуск Поллинга (вложенный try/except/finally) ---
        logger.info("Starting bot polling...")
        try:
            # allowed_updates можно настроить для оптимизации,
            # чтобы получать только нужные типы обновлений.
            # dp.resolve_used_update_types() автоматически определяет используемые типы.
            await dp.start_polling(bot, allowed_updates=dp.resolve_used_update_types())
            # Если не хотите автоопределение:
            # await dp.start_polling(bot)
        except Exception as polling_ex: # Ловим ошибки именно поллинга
            logger.critical(f"Polling failed critically: {polling_ex}", exc_info=True)
        finally:
            # Этот finally выполнится, когда поллинг остановится (штатно или из-за ошибки)
            logger.info("Polling stopped. Initiating shutdown sequence (inner finally)...")
            # Останавливаем фоновые задачи
            # await news_service.stop()
            # (Добавить остановку других сервисов)

            # Закрываем сессию бота (on_shutdown вызывается автоматически при остановке dp)
            # await bot.session.close() # Это обычно делается в on_shutdown
            logger.info("Inner shutdown sequence presumably completed via on_shutdown handler.")

        # Этот лог выполнится, если поллинг завершился штатно (не по Ctrl+C или Exception)
        logger.info("Bot polling finished normally.")

    # --- Обработка остановки (Ctrl+C) и других ошибок на уровне main ---
    except KeyboardInterrupt:
        logger.info("Bot stopped by user (KeyboardInterrupt). Handling within main.")
        # Дополнительные действия при остановке Ctrl+C, если нужно
    except Exception as main_ex:
        logger.critical(f"CRITICAL ERROR during bot lifecycle inside main: {main_ex}", exc_info=True)
    finally:
        # Этот finally выполнится ВСЕГДА при выходе из main (штатно, Ctrl+C, Exception)
        logger.info("--- Entering main() finally block --- ")
        # Важно закрыть соединение с БД в любом случае, даже если поллинг упал
        # Импортируем здесь, чтобы избежать циклического импорта, если main вызовет ошибку раньше
        try:
            from database.connection import close_db
            await close_db()
            logger.info("--- Bot Lifecycle in main() finished. DB connection closed. ---")
        except ImportError:
             logger.error("Failed to import close_db in main finally block.")
        except Exception as db_close_err:
             logger.error(f"Error closing DB connection in main finally block: {db_close_err}")


if __name__ == '__main__':
    # Настраиваем базовое логирование на случай ошибок *до* настройки в main()
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(name)s - %(message)s')
    temp_logger = logging.getLogger(__name__)
    temp_logger.info("Initializing bot application...")
    try:
        # Запускаем асинхронную функцию main
        asyncio.run(main())
    except (KeyboardInterrupt, SystemExit):
        # Корректная остановка по Ctrl+C или SystemExit до или во время запуска main
        temp_logger.info("Bot stopped by user (KeyboardInterrupt/SystemExit) at top level.")
    except Exception as e:
        # Ловим все остальные неожиданные исключения на верхнем уровне (до старта main)
        temp_logger.critical(f"Unhandled exception at main level: {e}", exc_info=True)
        exit(1) # Завершение с кодом ошибки
    finally:
        temp_logger.info("Bot application finished.")

========== Файл: requirements.txt ==========

# Agent Project Requirements

# --- Core Framework ---
aiogram>=3.4.0 # Используем актуальную версию aiogram (на момент создания)
pydantic>=2.0.0
pydantic-settings>=2.0.0 # Для удобной загрузки .env в Pydantic

# --- AI Interface ---
google-generativeai>=0.5.0 # Актуальная версия Gemini API
google-api-python-client # Зависимость для google-generativeai
google-auth # Зависимость для google-generativeai
protobuf # Зависимость для google-generativeai

# --- Database ---
aiosqlite>=0.17.0 # Асинхронный драйвер SQLite
# sqlalchemy>=2.0.0 # Раскомментировать, если будете использовать SQLAlchemy ORM
# alembic>=1.10.0 # Раскомментировать для миграций с SQLAlchemy
# psycopg2-binary # Раскомментировать, если будете использовать PostgreSQL

# --- Tools & Services Dependencies ---
aiohttp>=3.9.0 # Асинхронные HTTP запросы (для аватаров, парсинга чартов, RSS)
aiofiles>=23.0.0 # Асинхронные операции с файлами
beautifulsoup4>=4.11.0 # Парсинг HTML (для чартов, RSS)
lxml>=4.9.0 # Быстрый парсер для BeautifulSoup (опционально, но рекомендуется)
requests>=2.30.0 # Синхронные HTTP запросы (может требоваться для некоторых старых частей парсеров)
jsonpath-ng>=1.5.3
feedparser>=6.0.0 # Парсинг RSS лент
duckduckgo-search>=5.0.0 # Для инструмента веб-поиска

# --- Environment & Utilities ---
python-dotenv>=1.0.0 # Загрузка .env файлов

# --- Development & Optional ---
# pytest # Для запуска тестов
# pytest-asyncio # Для асинхронных тестов
# flake8 # Линтер
# mypy # Статический анализатор типов
# pre-commit # Для git hooks

========== Файл: ai_interface\fc_processing.py ==========

import asyncio
import inspect
import logging
import json # Для логирования
from typing import Dict, Any, List, Optional, Tuple, Callable

# --- Локальные импорты из новой структуры ---
try:
    # Импортируем модуль gemini_api целиком для доступа к send_message_to_gemini
    from . import gemini_api
    from utils.helpers import escape_markdown_v2 # Утилита экранирования
    # <<< ДОБАВЛЕНО: Импорт database >>>
    from utils.converters import _convert_value_for_json
    import database
except ImportError:
     logging.critical("CRITICAL: Failed to import dependencies (gemini_api, utils.helpers, database) in fc_processing.", exc_info=True)
     gemini_api = None # type: ignore
     database = None # type: ignore
     def escape_markdown_v2(text: str) -> str: return text # Заглушка

# --- Типы Google ---
try:
    # <<< ВОЗВРАЩАЕМ glm >>>
    from google.ai import generativelanguage as glm
    Part = glm.Part
    FunctionResponse = glm.FunctionResponse
    FunctionCall = glm.FunctionCall
    Content = glm.Content # Определяем Content через glm
    try:
        FinishReason = glm.Candidate.FinishReason
    except AttributeError: FinishReason = None

    # <<< GenerateContentResponse из types >>>
    from google.generativeai.types import GenerateContentResponse

    logger = logging.getLogger(__name__)
    logger.debug("Successfully imported Google types in fc_processing")
except ImportError as e:
    logger = logging.getLogger(__name__)
    logger.critical(f"CRITICAL: Failed to import Google types in fc_processing: {e}", exc_info=True)
    # <<< Обновляем заглушки >>>
    Part, Content, FunctionResponse, FunctionCall, FinishReason, GenerateContentResponse = Any, Any, Any, Any, Any, Any

logger = logging.getLogger(__name__)

async def execute_function_call(
        handler_func: Callable,
        args: Dict[str, Any], # Аргументы, предложенные моделью Gemini
        chat_id_for_handlers: Optional[int] = None, # ID чата, откуда пришел запрос
        user_id_for_handlers: Optional[int] = None  # ID пользователя, отправившего запрос
) -> Any:
    """
    Асинхронно выполняет хендлер инструмента (синхронный или асинхронный),
    передавая ему аргументы. Приоритет отдается аргументам, предложенным
    моделью Gemini (в словаре `args`). Если модель не предложила аргумент,
    а функция его ожидает (например, 'chat_id' или 'user_id'), то используются
    значения `chat_id_for_handlers` или `user_id_for_handlers`.

    Args:
        handler_func: Асинхронная или синхронная функция-обработчик инструмента.
        args: Словарь аргументов, полученный от модели Gemini.
        chat_id_for_handlers: ID чата для передачи в хендлер (если модель не передала).
        user_id_for_handlers: ID пользователя (отправителя) для передачи в хендлер (если модель не передала).

    Returns:
        Результат выполнения хендлера или словарь с ошибкой.
    """
    handler_sig = inspect.signature(handler_func)
    # Начинаем с аргументов, предоставленных моделью AI
    final_args = args.copy()

    # --- ИСПРАВЛЕННАЯ ЛОГИКА ВНЕДРЕНИЯ ID ---

    # 1. Обработка chat_id:
    #    Внедряем ID чата отправителя, ТОЛЬКО если функция его ожидает
    #    И если он НЕ был предоставлен самой моделью в args.
    if 'chat_id' in handler_sig.parameters and 'chat_id' not in args:
        if chat_id_for_handlers is not None:
            final_args['chat_id'] = chat_id_for_handlers
            logger.debug(f"Injecting sender chat_id ({chat_id_for_handlers}) into args for {handler_func.__name__}")
        else:
            # Логируем, только если chat_id был обязательным параметром без значения по умолчанию
            param_obj = handler_sig.parameters['chat_id']
            if param_obj.default is inspect.Parameter.empty:
                logger.warning(f"Handler '{handler_func.__name__}' expects mandatory 'chat_id', but it was not provided by AI or sender context.")

    # 2. Обработка user_id:
    #    Аналогично, внедряем ID пользователя-отправителя, ТОЛЬКО если
    #    функция ожидает 'user_id', и модель НЕ предоставила его в args.
    #    ВАЖНО: Если инструмент должен работать с ID ДРУГОГО пользователя,
    #    модель ДОЛЖНА передать этот ID в аргументе 'user_id' (или 'target_user_id').
    #    Эта логика гарантирует, что ID от модели имеет приоритет.
    if 'user_id' in handler_sig.parameters and 'user_id' not in args:
         if user_id_for_handlers is not None:
            final_args['user_id'] = user_id_for_handlers
            logger.debug(f"Injecting sender user_id ({user_id_for_handlers}) as 'user_id' into args for {handler_func.__name__}")
         else:
            param_obj = handler_sig.parameters['user_id']
            if param_obj.default is inspect.Parameter.empty:
                 logger.warning(f"Handler '{handler_func.__name__}' expects mandatory 'user_id', but it was not provided by AI or sender context.")

    # --- КОНЕЦ ИСПРАВЛЕННОЙ ЛОГИКИ ---

    # 3. Фильтрация аргументов:
    #    Оставляем только те аргументы из final_args (уже с возможными
    #    добавлениями chat_id/user_id отправителя), которые действительно
    #    принимает функция-хендлер.
    filtered_args = {k: v for k, v in final_args.items() if k in handler_sig.parameters}

    # 4. Проверка обязательных аргументов:
    #    Убеждаемся, что все параметры функции, у которых нет значения
    #    по умолчанию, присутствуют в `filtered_args`.
    missing_args = [
        p_name for p_name, p_obj in handler_sig.parameters.items()
        if p_obj.default is inspect.Parameter.empty and p_name not in filtered_args
    ]
    if missing_args:
        err_msg = f"Missing required arguments for '{handler_func.__name__}': {', '.join(missing_args)}. Provided args from AI: {list(args.keys())}, Final filtered args: {list(filtered_args.keys())}"
        logger.error(err_msg)
        return {"status": "error", "message": err_msg} # Возвращаем ошибку

    # Логируем финальные аргументы перед вызовом
    logger.debug(f"Executing handler '{handler_func.__name__}' with final args: {filtered_args}")

    # 5. Выполнение хендлера:
    try:
        if asyncio.iscoroutinefunction(handler_func):
            # Если хендлер асинхронный, просто await его
            return await handler_func(**filtered_args)
        else:
            # Если хендлер синхронный, запускаем его в executor'е
            loop = asyncio.get_running_loop()
            from functools import partial
            # functools.partial нужен, чтобы передать аргументы в функцию,
            # которая будет вызвана в другом потоке/процессе executor'а.
            func_call = partial(handler_func, **filtered_args)
            return await loop.run_in_executor(None, func_call)
    except Exception as exec_err:
        # Ловим любые ошибки во время выполнения самого хендлера
        err_msg = f"Handler execution failed for function '{handler_func.__name__}': {exec_err}"
        logger.error(f"Error executing handler '{handler_func.__name__}' with args {filtered_args}: {exec_err}", exc_info=True)
        # Возвращаем словарь с ошибкой, чтобы Gemini знал о проблеме
        return {"status": "error", "message": err_msg}


async def process_gemini_fc_cycle(
    model_instance: Any, # Экземпляр genai.GenerativeModel
    chat_session: Any,   # Экземпляр genai.ChatSession
    available_functions_map: Dict[str, Callable],
    max_steps: int,
    original_chat_id: Optional[int] = None,
    original_user_id: Optional[int] = None,
) -> Tuple[Optional[List[Content]], Optional[str], Optional[str], Optional[Dict]]:
    """
    Обрабатывает цикл Function Calling для ответа Gemini.
    Отправляет ответы на все Function Calls одним запросом к API.
    Возвращает: (final_history, last_successful_fc_name, last_sent_text, last_successful_fc_result)
    """
    # Проверка импорта типов Google
    if not all([Part, Content, FunctionResponse, FunctionCall, GenerateContentResponse]):
         logger.critical("Missing Google types! Cannot process Function Calling.")
         # <<< ИСПРАВЛЕНИЕ ValueError: Возвращаем 4 значения >>>
         return getattr(chat_session, 'history', None), None, None, None

    # <<< ИНИЦИАЛИЗАЦИЯ: Гарантируем инициализацию всех возвращаемых значений >>>
    last_successful_fc_name: Optional[str] = None
    last_sent_text: Optional[str] = None
    last_successful_fc_result: Optional[Dict] = None
    step = 0
    current_response: Optional[GenerateContentResponse] = None
    final_history: Optional[List[Content]] = getattr(chat_session, 'history', None)

    # Получаем последний ответ из истории сессии (инициализация current_response)
    try:
        if not hasattr(chat_session, 'history') or not chat_session.history:
             logger.warning("Chat session history is empty or missing before FC cycle.")
             # <<< ИСПРАВЛЕНИЕ ValueError: Возвращаем 4 значения >>>
             return final_history, None, None, None # Используем инициализированный final_history

        last_content = chat_session.history[-1]
        if not isinstance(last_content, Content):
             logger.error(f"Last history item is not Content object: {type(last_content)}")
             # <<< ИСПРАВЛЕНИЕ ValueError: Возвращаем 4 значения >>>
             return final_history, None, None, None
        if last_content.role != 'model':
             logger.debug("Last message in history is not from model, no FC cycle needed.")
             # <<< ИСПРАВЛЕНИЕ ValueError: Возвращаем 4 значения >>>
             return final_history, None, None, None

        # Создаем Mock-ответ для входа в цикл (первый шаг)
        class MockResponse:
            def __init__(self, content: Content):
                class MockCandidate:
                    def __init__(self, content: Content):
                        self.content = content
                        self.safety_ratings = []
                        self.finish_reason = FinishReason.STOP if hasattr(FinishReason, 'STOP') else 1
                self.candidates = [MockCandidate(content)] if content else []
        current_response = MockResponse(last_content)

    except Exception as e:
         logger.error(f"Failed to get last response from session history: {e}", exc_info=True)
         # <<< ИСПРАВЛЕНИЕ ValueError: Возвращаем 4 значения >>>
         return final_history, None, None, None

    # Основной цикл обработки FC
    while current_response and step < max_steps:
        step += 1
        model_name_str = getattr(model_instance, '_model_name', 'Unknown Model') # Попробуем достать имя модели
        logger.info(f"--- FC Analysis ({model_name_str} Step {step}/{max_steps}) Chat: {original_chat_id} ---")

        # Извлекаем части из ответа
        try:
            if not current_response.candidates:
                logger.info(f"No candidates in response for step {step}. Ending FC cycle.")
                break # Выход из цикла while
            candidate = current_response.candidates[0]
            # Проверка на блокировку контента
            if hasattr(candidate, 'finish_reason') and candidate.finish_reason not in (FinishReason.STOP, FinishReason.MAX_TOKENS, FinishReason.FINISH_REASON_UNSPECIFIED, 1, 0): # 1=STOP, 0=UNSPECIFIED (примерные значения)
                 logger.warning(f"Model response stopped with reason: {candidate.finish_reason}. Ending FC cycle. Safety: {getattr(candidate, 'safety_ratings', 'N/A')}")
                 break # Выход из цикла while
            if not candidate.content or not candidate.content.parts:
                finish_reason = getattr(candidate, 'finish_reason', 'N/A')
                logger.info(f"No content/parts in candidate (Finish reason: {finish_reason}). Ending FC cycle.")
                break # Выход из цикла while
            parts = candidate.content.parts
        except Exception as e:
            logger.warning(f"Response structure error accessing parts: {e}.")
            break # Выход из цикла while

        # Собираем валидные Function Calls для обработки
        function_calls_to_process: List[FunctionCall] = []
        for part in parts:
            # --- Обработка FunctionCall ---
            if isinstance(part, Part) and hasattr(part, 'function_call') and part.function_call is not None:
                fc = part.function_call
                fc_name = getattr(fc, 'name', None) # Безопасно получаем имя
                # Проверяем, что имя функции существует и НЕ ПУСТОЕ
                if isinstance(fc, FunctionCall) and fc_name: # Проверяем, что имя не пустое
                    function_calls_to_process.append(fc)
                    logger.debug(f"Found valid FC to process: {fc_name}")
                elif isinstance(fc, FunctionCall): # Если это FunctionCall, но имя пустое
                    logger.debug(f"Ignoring FunctionCall with empty name found in model response part: {fc}")
                else: # Если это не FunctionCall или имя None (маловероятно)
                    logger.error(f"MODEL ERROR: Found invalid/malformed FunctionCall object in model response part. IGNORING this FC. Object: {fc}")

            # --- Обработка FunctionResponse (Логирование аномалии) ---
            # Логируем, если вдруг модель вернула FunctionResponse
            if isinstance(part, Part) and hasattr(part, 'function_response') and part.function_response is not None:
                 fr = part.function_response
                 fr_name = getattr(fr, 'name', None)
                 if isinstance(fr, FunctionResponse) and fr_name: # Если имя есть и не пустое
                     logger.warning(f"MODEL WARNING: Found function_response with name '{fr_name}' in MODEL response parts (should not happen). IGNORING this FR.")
                 else: # Если имя пустое или отсутствует
                     logger.debug(f"Ignoring FunctionResponse with empty/missing name found in model response part: {fr}")

        # Если нет FC для обработки, выходим из цикла
        if not function_calls_to_process:
            logger.info("No valid Function Calls found in this step. Ending FC cycle.")
            break # Выход из цикла while

        logger.info(f"Found {len(function_calls_to_process)} valid FCs by {model_name_str} to process.")

        # Готовим и запускаем задачи выполнения хендлеров
        response_parts_for_gemini: List[Part] = [] # Список ответов для Gemini
        # <<< ИЗМЕНЕНО: Храним (task, original_args) >>>
        interrupt_fc_cycle = False

        for fc_index, fc in enumerate(function_calls_to_process):
            function_name = fc.name
            original_args_for_log: Optional[Dict] = None
            args: Dict[str, Any] = {}
            handler_result: Any = None
            execution_error: Optional[Exception] = None
            log_status = 'error' # Статус по умолчанию для логирования

            # 1. Парсинг аргументов (как и раньше)
            if hasattr(fc, 'args') and fc.args is not None:
                try:
                    args = _convert_value_for_json(fc.args) # Используем импортированную функцию
                    if not isinstance(args, dict): raise TypeError("Args not dict")
                    original_args_for_log = args
                except (TypeError, ValueError) as e:
                    logger.error(f"Cannot convert/parse args for FC '{function_name}': {e}")
                    # Формируем ответ об ошибке для Gemini
                    response_payload = {"error": f"Failed to parse arguments: {e}"}
                    response_part = Part(function_response=FunctionResponse(name=function_name, response=response_payload))
                    response_parts_for_gemini.append(response_part)
                    # Логируем ошибку в БД
                    if database:
                         try:
                              error_args_log = {"raw_args": str(getattr(fc, 'args', 'MISSING')), "parsing_error": str(e)}
                              asyncio.create_task(database.add_tool_execution_log(
                                   chat_id=original_chat_id, user_id=original_user_id, tool_name=function_name,
                                   tool_args=error_args_log, status='error', result_message=f"Argument parsing failed: {e}"
                              )) # Логируем асинхронно
                         except Exception as log_err: logger.error(f"DB log error (arg parse fail): {log_err}")
                    continue # Переходим к следующему FC в пачке
            else:
                original_args_for_log = {}

            logger.info(f"Executing FC {fc_index + 1}/{len(function_calls_to_process)} sequentially: {function_name}({args}) for chat {original_chat_id}")

            # 2. Поиск и выполнение хендлера
            if function_name in available_functions_map:
                handler = available_functions_map[function_name]
                try:
                    handler_result = await execute_function_call(
                        handler_func=handler,
                        args=args,
                        chat_id_for_handlers=original_chat_id,
                        user_id_for_handlers=original_user_id
                    )
                except Exception as exec_err:
                     execution_error = exec_err # Сохраняем ошибку выполнения
                     # handler_result остается None
            else:
                logger.error(f"Function handler '{function_name}' not found.")
                handler_result = {"status": "error", "message": f"Function '{function_name}' is not implemented or available."}
                log_status = 'not_found' # Уточняем статус для лога

            # 3. Обработка результата и логирование
            log_return_code = None
            log_result_message = None
            log_stdout = None
            log_stderr = None
            response_content_for_fr = None
            full_result_json_str = None

            if execution_error:
                 log_status = 'error'
                 log_result_message = f"Execution failed: {execution_error}"
                 response_content_for_fr = {"error": log_result_message}
            elif isinstance(handler_result, dict):
                 log_stdout = handler_result.get('stdout')
                 log_stderr = handler_result.get('stderr')
                 log_return_code = handler_result.get('returncode')
                 if 'status' in handler_result and handler_result['status'] in {'success', 'error', 'not_found', 'warning', 'timeout'}:
                     log_status = handler_result['status']
                     log_result_message = handler_result.get('message', handler_result.get('error')) if log_status == 'error' else handler_result.get('message')
                 elif 'error' in handler_result:
                     log_status = 'error'; log_result_message = handler_result['error']
                 else:
                     log_status = 'success'; log_result_message = handler_result.get('message')

                 response_content_for_fr = handler_result

                 if log_status == 'success':
                    last_successful_fc_name = function_name
                    last_successful_fc_result = handler_result
                    if function_name == 'send_telegram_message':
                         last_sent_text = original_args_for_log.get('text')
                         logger.info(f"Recorded sent text via send_telegram_message: '{last_sent_text[:50]}...'")
                         response_content_for_fr = {"status": "success", "message": "Message queued for sending."} # Упрощаем ответ для Gemini
            else: # Неожиданный тип результата
                 log_status = 'success' # Предполагаем успех
                 log_result_message = f"Handler returned non-dict/non-exception: {type(handler_result)} - {str(handler_result)[:100]}..."
                 logger.warning(f"Handler '{function_name}' returned unexpected result type: {type(handler_result)}")
                 response_content_for_fr = {"result_value": str(handler_result)} # Оборачиваем в словарь

            # Логирование в БД (асинхронно)
            if database:
                try:
                     full_result_json_str = json.dumps(handler_result, ensure_ascii=False, default=str)
                except Exception as json_full_err:
                     logger.error(f"Failed serialize full_result tool log '{function_name}': {json_full_err}")
                     full_result_json_str = json.dumps({"error": f"Full result serialization failed: {json_full_err}"})
                asyncio.create_task(database.add_tool_execution_log(
                    chat_id=original_chat_id, user_id=original_user_id, tool_name=function_name, tool_args=original_args_for_log,
                    status=log_status, return_code=log_return_code, result_message=log_result_message,
                    stdout=log_stdout, stderr=log_stderr, full_result=full_result_json_str, trigger_message_id=None
                )) # Логируем асинхронно

            # 4. Подготовка FunctionResponse для Gemini
            response_payload_for_gemini = {}
            try:
                response_payload_for_gemini = _convert_value_for_json(response_content_for_fr)
                if not isinstance(response_payload_for_gemini, dict):
                    response_payload_for_gemini = {"value": response_payload_for_gemini}
            except Exception as conversion_err:
                 logger.error(f"Explicit conversion tool result failed '{function_name}': {conversion_err}")
                 response_payload_for_gemini = {"error": f"Tool result conversion failed: {conversion_err}"}

            # Добавляем результат в список для отправки в API
            response_part = Part(function_response=FunctionResponse(name=function_name, response=response_payload_for_gemini))
            response_parts_for_gemini.append(response_part)

            # 5. Проверка на блокирующий вызов
            is_blocking = False
            # Пример: считаем блокирующим вызов send_telegram_message, если текст заканчивается на "?"
            if function_name == 'send_telegram_message':
                # Получаем значение аргумента, по умолчанию False
                requires_response = args.get('requires_user_response', False)
                # Убедимся, что значение булево (модель может вернуть строку 'true'/'false')
                if isinstance(requires_response, str):
                    requires_response = requires_response.lower() == 'true'

                if requires_response is True: # Явная проверка на True
                    logger.info(f"Blocking FC detected ({function_name} with requires_user_response=True). Interrupting batch after this call.")
                    is_blocking = True

            # Если вызов блокирующий, прерываем обработку ОСТАЛЬНЫХ FC из этой пачки
            if is_blocking:
                 interrupt_fc_cycle = True # Устанавливаем флаг для внешнего цикла
                 break # Прерываем цикл for fc in function_calls_to_process

        # --- КОНЕЦ внутреннего цикла for fc in function_calls_to_process ---

        # Если цикл был прерван блокирующим вызовом, выходим из основного цикла while
        if interrupt_fc_cycle:
             logger.info("Exiting FC cycle early due to blocking call. Sending executed responses back.")
             # Отправляем те ответы, что успели собрать ДО блокирующего вызова
             if response_parts_for_gemini:
                  logger.info(f"Sending {len(response_parts_for_gemini)} function responses (before block) back to Gemini for chat {original_chat_id}.")
                  try:
                      content_with_responses = Content(role="function", parts=response_parts_for_gemini)
                      loop = asyncio.get_running_loop()
                      # Важно: Этот вызов НЕ обновляет current_response для СЛЕДУЮЩЕЙ итерации,
                      # так как мы прерываем цикл while. Его результат нам не нужен.
                      await loop.run_in_executor(
                           None, gemini_api.send_message_to_gemini,
                           model_instance, chat_session, content_with_responses
                      )
                      final_history = getattr(chat_session, 'history', None) # Сохраняем историю до прерывания
                  except Exception as api_err:
                       logger.error(f"Error sending partial function responses to Gemini API before blocking exit: {api_err}", exc_info=True)
                       # Не прерываем здесь, просто логируем ошибку отправки
             else:
                  logger.warning("Blocking call detected, but no responses to send back (e.g., error occurred before block).")
             break # <-- ВЫХОДИМ ИЗ ОСНОВНОГО ЦИКЛА WHILE

        # Если все FC в пачке обработаны БЕЗ прерывания
        # Отправляем собранные ответы Gemini и получаем следующий ответ модели
        if not response_parts_for_gemini:
             logger.warning("No response parts generated for Gemini in this step, though FCs were present. Ending cycle.")
             break

        logger.info(f"Sending {len(response_parts_for_gemini)} function responses back to Gemini for chat {original_chat_id}.")
        if gemini_api is None:
            logger.critical("gemini_api module unavailable.")
            break

        try:
            content_with_responses = Content(role="function", parts=response_parts_for_gemini)
            loop = asyncio.get_running_loop()
            current_response = await loop.run_in_executor( # Этот вызов важен для следующей итерации
                 None, gemini_api.send_message_to_gemini,
                 model_instance, chat_session, content_with_responses
            )
            logger.debug(f"Received next response from Gemini after sending FRs for chat {original_chat_id}")
            final_history = getattr(chat_session, 'history', None) # Обновляем историю
            # response_parts_for_gemini очистится в начале следующей итерации while (перенесли инициализацию)

        except Exception as api_err:
             logger.error(f"Error sending function responses to Gemini API: {api_err}", exc_info=True)
             current_response = None # Прерываем цикл while при ошибке API
             break

    # Цикл завершен (по шагам, отсутствию FC, ошибке или прерыванию)
    # --->>> КОНЕЦ ИЗМЕНЕНИЙ <<<---
    logger.info(f"FC processing cycle finished after {step} step(s) for chat {original_chat_id}.")
    return final_history, last_successful_fc_name, last_sent_text, last_successful_fc_result


========== Файл: ai_interface\gemini_api.py ==========

import google.generativeai as genai
import logging
from typing import Optional, Dict, List, Any, Union, Sequence

logger = logging.getLogger(__name__)

# --- ИМПОРТ ТИПОВ ИЗ google.ai.generativelanguage ---
try:
    from google.ai import generativelanguage as glm
    # <<< ВОЗВРАЩАЕМ ИМПОРТЫ glm >>>
    Part = glm.Part
    FunctionResponse = glm.FunctionResponse
    FunctionDeclaration = glm.FunctionDeclaration
    Tool = glm.Tool
    Schema = glm.Schema
    Type = glm.Type
    try:
        FinishReason = glm.Candidate.FinishReason
        logger_types = logging.getLogger(__name__)
        logger_types.debug("Imported FinishReason from glm.Candidate")
    except AttributeError:
        logger_types = logging.getLogger(__name__)
        logger_types.warning("Could not import FinishReason from glm.Candidate. String comparison fallback needed.")
        FinishReason = None # Тип будет None

    # <<< ИМПОРТИРУЕМ GenerationConfig ОТДЕЛЬНО ИЗ types >>>
    from google.generativeai.types import ContentDict, GenerateContentResponse, GenerationConfig
    # <<< УБИРАЕМ Content отсюда, он будет через glm >>>
    # from google.generativeai import Content # НЕПРАВИЛЬНО

    logger_types = logging.getLogger(__name__)
    logger_types.debug("Successfully imported types from google.ai.generativelanguage and google.generativeai.types")

except ImportError as e:
    logger_types = logging.getLogger(__name__)
    logger_types.critical("CRITICAL: Failed to import required Google AI types. Functionality will be impaired.", exc_info=True)
    # Определяем заглушки Any
    Part, FunctionResponse, FunctionDeclaration, Tool, Schema, Type, FinishReason = Any, Any, Any, Any, Any, Any, Any
    ContentDict, GenerateContentResponse, GenerationConfig = Any, Any, Any
    # Content будет Any из-за структуры ниже
    Content = Any # Добавляем заглушку для Content

# <<< УБЕДИМСЯ, ЧТО Content тоже доступен (через glm) >>>
try:
    Content = glm.Content # Определяем Content через glm
    logger_types.debug("Defined Content via glm.Content")
except NameError: # Если glm не импортировался
    pass # Content останется Any
except AttributeError: # Если в glm нет Content
     logger_types.warning("Could not define Content via glm.Content")
     Content = Any
# Предполагаем, что settings импортируются там, где вызываются эти функции,
# или передаются как аргументы. Не импортируем settings напрямую здесь.
# from config import settings (Не рекомендуется здесь)

# --- Настройка модели ---
def setup_gemini_model(
    api_key: str,
    model_name: str,
    system_prompt: Optional[str] = None,
    function_declarations_data: Optional[List[Dict[str, Any]]] = None,
    generation_config: Optional[Dict[str, Any]] = None,
    safety_settings: Optional[List[Dict[str, Any]]] = None,
    enable_function_calling: bool = True
) -> Optional[genai.GenerativeModel]:
    """
    Настраивает и возвращает модель Gemini с инструментами, системным промптом,
    конфигурацией генерации и настройками безопасности.

    Args:
        api_key: API ключ Google AI.
        model_name: Имя модели Gemini (например, 'gemini-1.5-pro-latest').
        system_prompt: Текст системного промпта (может быть None).
        function_declarations_data: Список словарей с декларациями функций (может быть None).
        generation_config: Словарь с параметрами генерации (temperature, top_p, etc.).
        safety_settings: Список словарей с настройками безопасности.
        enable_function_calling: Включить ли Function Calling.

    Returns:
        Инициализированный объект genai.GenerativeModel или None при ошибке.
    """
    # Проверка импорта базовых типов
    if not all([genai, Tool, FunctionDeclaration, Schema, Type, GenerationConfig]):
        logger.critical(f"Cannot setup model '{model_name}': Missing essential Google AI types.")
        return None

    try:
        genai.configure(api_key=api_key)
        tools_list = None

        # Создание инструментов (Function Calling)
        if function_declarations_data and enable_function_calling:
            logger.info(f"Creating Tool configuration for model '{model_name}'...")
            declarations = []
            for func_decl_dict in function_declarations_data:
                if not isinstance(func_decl_dict, dict) or 'name' not in func_decl_dict or 'description' not in func_decl_dict:
                    logger.warning(f"Skipping incomplete function declaration: {func_decl_dict}")
                    continue
                try:
                    param_schema = None
                    parameters_dict = func_decl_dict.get('parameters', {})
                    properties_dict = parameters_dict.get('properties', {}) if isinstance(parameters_dict, dict) else {}
                    required_params_list = parameters_dict.get('required', []) if isinstance(parameters_dict, dict) else []

                    if isinstance(properties_dict, dict) and properties_dict:
                        param_properties = {}
                        for param_name, param_details in properties_dict.items():
                            if not isinstance(param_details, dict):
                                logger.warning(f"Parameter details for '{param_name}' in '{func_decl_dict['name']}' is not a dict. Skipping param.")
                                continue
                            param_type_str = param_details.get('type', 'STRING').upper()
                            schema_type_enum = getattr(Type, param_type_str, Type.STRING)
                            if schema_type_enum == Type.STRING and param_type_str != 'STRING':
                                logger.warning(f"Unknown type '{param_type_str}' for param '{param_name}'. Defaulting to STRING.")

                            param_properties[param_name] = Schema(type=schema_type_enum, description=param_details.get('description', ''))

                        # Валидация required параметров
                        valid_required = [p for p in required_params_list if isinstance(p, str) and p in param_properties]
                        if len(valid_required) != len(required_params_list):
                             invalid_req = set(required_params_list) - set(valid_required)
                             logger.warning(f"Required params {invalid_req} not found in properties for '{func_decl_dict['name']}'. Ignoring them in 'required'.")

                        param_schema = Schema(type=Type.OBJECT, properties=param_properties, required=valid_required)

                    declarations.append(FunctionDeclaration(name=func_decl_dict['name'], description=func_decl_dict['description'], parameters=param_schema))
                except Exception as e:
                    logger.error(f"Error creating FunctionDeclaration for '{func_decl_dict.get('name', 'UNKNOWN')}': {e}", exc_info=True)

            if declarations:
                tool_object = Tool(function_declarations=declarations)
                tools_list = [tool_object]
                logger.info(f"Tool object created for '{model_name}' with {len(declarations)} declarations.")
            else:
                logger.warning(f"No valid function declarations created for '{model_name}'. Function Calling might be unavailable.")
        elif not enable_function_calling:
            logger.info(f"Function Calling disabled for model '{model_name}'. No tools created.")
        else:
            logger.info(f"No function declaration data provided for '{model_name}'. No tools created.")

        # Формируем аргументы для инициализации модели
        init_args = {"model_name": model_name}
        if generation_config and isinstance(generation_config, dict):
            try:
                init_args["generation_config"] = GenerationConfig(**generation_config)
                logger.debug(f"Applying generation config for '{model_name}': {generation_config}")
            except Exception as conf_err:
                 logger.error(f"Failed to apply generation_config for '{model_name}': {conf_err}. Config: {generation_config}")
        if safety_settings and isinstance(safety_settings, list):
            init_args["safety_settings"] = safety_settings
            logger.debug(f"Applying safety settings for '{model_name}': {safety_settings}")
        if tools_list:
            init_args["tools"] = tools_list
        if system_prompt and isinstance(system_prompt, str) and system_prompt.strip():
            init_args["system_instruction"] = system_prompt
            logger.info(f"Applying system instruction for '{model_name}'.")

        # Инициализация модели
        model = genai.GenerativeModel(**init_args)
        logger.info(f"Gemini model '{model_name}' initialized successfully.")
        return model

    except Exception as e:
        logger.critical(f"Failed to initialize Gemini model '{model_name}': {e}", exc_info=True)
        return None


# --- Отправка сообщения (синхронная, для использования в executor) ---
def send_message_to_gemini(
    model: genai.GenerativeModel,
    chat_session: genai.ChatSession,
    user_message: Union[str, Part, List[Part], ContentDict, List[ContentDict]]
) -> Optional[GenerateContentResponse]:
    """
    Отправляет сообщение в чат-сессию Gemini.
    Эта функция синхронная и предназначена для вызова через loop.run_in_executor.

    Args:
        model: Экземпляр genai.GenerativeModel (формально не используется send_message сессии, но оставлен для контекста).
        chat_session: Активная сессия чата genai.ChatSession.
        user_message: Сообщение для отправки (строка, Part, список Part или ContentDict).

    Returns:
        Ответ от модели (GenerateContentResponse) или None при ошибке.
    """
    if not chat_session:
        logger.error("Cannot send message: chat_session is None.")
        return None
    if not user_message:
         logger.warning("Attempted to send an empty message to Gemini.")
         # Можно вернуть ошибку или пустой ответ в зависимости от желаемого поведения
         return None # Или создать пустой фейковый ответ

    try:
        # Тип user_message уже должен быть подготовлен вызывающей функцией
        response = chat_session.send_message(user_message) # Синхронный вызов

        if response is None:
            logger.error("Gemini API returned None response.")
            return None

        # Детальное логирование ответа
        try:
            parts_repr = []
            finish_reason_val = 'N/A'
            safety_ratings_repr = 'N/A'
            if hasattr(response, 'candidates') and response.candidates:
                candidate = response.candidates[0]
                finish_reason_val = getattr(candidate, 'finish_reason', 'N/A')
                safety_ratings_repr = str(getattr(candidate, 'safety_ratings', []))
                if hasattr(candidate, 'content') and candidate.content and hasattr(candidate.content, 'parts'):
                    for i, part in enumerate(candidate.content.parts):
                        part_info = f"Part {i}: Type={type(part).__name__}"
                        if hasattr(part, 'text') and part.text is not None: part_info += f", Text='{part.text[:80]}...'"
                        if hasattr(part, 'function_call') and part.function_call is not None: part_info += f", FunctionCall(Name='{getattr(part.function_call, 'name', 'N/A')}')"
                        if hasattr(part, 'function_response') and part.function_response is not None: part_info += f", FunctionResponse(Name='{getattr(part.function_response, 'name', 'N/A')}')"
                        parts_repr.append(part_info)
            elif hasattr(response, 'prompt_feedback') and response.prompt_feedback:
                 feedback = response.prompt_feedback
                 finish_reason_val = getattr(feedback, 'block_reason', 'UNKNOWN_BLOCK')
                 safety_ratings_repr = str(getattr(feedback, 'safety_ratings', []))

            logger.info(f"Raw Gemini Response: Parts=[{'; '.join(parts_repr)}], FinishReason: {finish_reason_val}, Safety: {safety_ratings_repr}")
        except Exception as log_ex:
            logger.error(f"Error during detailed response logging: {log_ex}", exc_info=True)

        return response

    except Exception as e:
        logger.error(f"Error sending message to Gemini: {e}", exc_info=True)
        # Возвращаем None или перевыбрасываем исключение, чтобы вызывающий код мог его обработать (например, для retry)
        raise # Перевыбрасываем, чтобы run_gemini_interaction мог поймать ResourceExhausted


# --- Генерация описания изображения (асинхронная) ---
async def generate_image_description(
    api_key: str, # Добавляем API ключ как аргумент
    image_bytes: bytes,
    prompt: str,
    model_name: str = "gemini-1.5-pro-latest" # Используем модель с vision capabilities
) -> Optional[str]:
    """
    Генерирует текстовое описание для изображения, используя Gemini Vision.

    Args:
        api_key: API ключ Google AI.
        image_bytes: Изображение в виде байтов.
        prompt: Промпт для модели (например, "Опиши это изображение").
        model_name: Имя модели Gemini с поддержкой Vision (по умолчанию 'gemini-1.5-pro-latest').

    Returns:
        Сгенерированное описание или None в случае ошибки.
    """
    logger.info(f"Generating image description using model '{model_name}'...")
    if not image_bytes:
        logger.error("Cannot generate description: image_bytes is empty.")
        return None
    if not api_key:
         logger.error("Cannot generate description: Google API Key is missing.")
         return None

    try:
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel(model_name)

        # Определяем mime_type (упрощенно, можно добавить более надежное определение)
        # Библиотека google-generativeai может определить тип сама, если передать bytes
        image_part = {"mime_type": "image/jpeg", "data": image_bytes} # TODO: Определять mime_type надежнее

        # Вызов generate_content_async
        response = await model.generate_content_async([prompt, image_part])

        if response and response.text:
            description = response.text.strip()
            logger.info(f"Image description generated successfully (length: {len(description)}).")
            return description
        elif response and response.prompt_feedback and response.prompt_feedback.block_reason:
            reason = response.prompt_feedback.block_reason
            logger.error(f"Image description request blocked. Reason: {reason}")
            return f"[Описание заблокировано: {reason}]"
        else:
            logger.error("Image description generation returned empty or invalid response.")
            return None

    except Exception as e:
        logger.error(f"Error generating image description: {e}", exc_info=True)
        return None

========== Файл: ai_interface\llm_models.py ==========



========== Файл: ai_interface\__init__.py ==========



========== Файл: core_agent\agent_processor.py ==========

# core_agent/agent_processor.py

import logging
import json
import re # Импорт для регулярных выражений (проверка упоминаний)
from typing import Optional, Dict, Any, List, Callable

# --- Aiogram и зависимости ---
from aiogram import types, Bot, Dispatcher # <<< Добавлен Dispatcher
from aiogram.enums import ChatType as aiogram_ChatType
# --- Локальные импорты ядра ---
from .history_manager import prepare_history, save_history
from .ai_interaction import process_request
from .result_parser import extract_text
# --- Импорт парсера ответа Lite-модели ---
from .response_parsers import parse_lite_llm_response # Используем новое имя файла
# --- Импорт утилит и глобальных объектов ---
from utils.helpers import escape_markdown_v2
from bot_loader import dp, bot as bot_instance # Импортируем dp и бот
# --- Импорт функций управления индексом (если используется для Lite) ---
# Если Lite не требует ротации ключей, этот импорт не нужен здесь
from bot_lifecycle import get_current_api_key_index # <<< Импортируем для выбора Lite модели

# --- Импорт БД и CRUD операций ---
import database
from database.crud_ops.profiles import upsert_user_profile

# (Опционально, если работаете с объектами Content напрямую)
# from google.ai import generativelanguage as glm
# Content = glm.Content

logger_ap = logging.getLogger(__name__)
logger_ap.info("--- Loading agent_processor.py ---")

# --- Кэш информации о боте ---
BOT_INFO_CACHE: Dict[str, Any] = {"info": None, "username_lower": None}

async def _get_bot_info(bot_to_use: Bot) -> Optional[types.User]:
    """Получает и кэширует информацию о боте."""
    global BOT_INFO_CACHE
    if BOT_INFO_CACHE["info"] is None and bot_to_use:
        try:
            bot_user = await bot_to_use.get_me()
            BOT_INFO_CACHE["info"] = bot_user
            BOT_INFO_CACHE["username_lower"] = bot_user.username.lower() if bot_user.username else None
            logger_ap.info(f"Bot info cached in agent_processor: ID={bot_user.id}, Username=@{bot_user.username}")
        except Exception as e:
            logger_ap.error(f"Failed to get bot info via API in agent_processor: {e}")
            BOT_INFO_CACHE["info"] = None
            BOT_INFO_CACHE["username_lower"] = None
    return BOT_INFO_CACHE["info"]

# --- Вспомогательная функция для вызова Pro-модели ---
async def _execute_pro_model_logic(
    message: types.Message,
    # <<< ИЗМЕНЕНИЕ: Принимаем СПИСКИ моделей >>>
    # pro_model: Any, # Удалено
    pro_models_list: List[Any],
    lite_models_list: List[Any], # Опционально, если нужно передавать дальше
    available_pro_functions: Dict[str, Callable],
    max_pro_steps: int,
    # <<< ДОБАВЛЕНО: dispatcher >>>
    dispatcher: Dispatcher
) -> Optional[str]:
    """
    Выполняет стандартную логику обработки Pro моделью, используя списки моделей
    и передавая dispatcher для управления ключами API.
    """
    chat_id=message.chat.id
    user_id=message.from_user.id if message.from_user else 0
    chat_type=message.chat.type
    user_input=message.text or ""
    add_user_context = True # По умолчанию добавляем контекст

    logger_ap.debug(f"Executing Pro model logic for chat {chat_id} using multi-key setup.")

    try:
        # --- Подготовка истории (остается без изменений) ---
        initial_history_obj_list, original_db_len = await prepare_history(
            chat_id=chat_id,
            user_id=user_id,
            chat_type=chat_type,
            add_notes=add_user_context
        )
        # Убедимся, что initial_history_obj_list - это список Content объектов
        if not isinstance(initial_history_obj_list, list):
             logger_ap.error(f"prepare_history did not return a list for chat {chat_id}. Type: {type(initial_history_obj_list)}")
             return escape_markdown_v2("Ошибка подготовки истории диалога.")

        # --- Взаимодействие с Pro AI ---
        # <<< ИЗМЕНЕНИЕ: Передаем dispatcher вместо model_instance >>>
        final_history_obj_list, interaction_error_msg, last_func_name, last_sent_text, last_func_result = await process_request(
            # model_instance=... # Удалено
            initial_history=initial_history_obj_list, # Передаем список Content объектов
            user_input=user_input,
            available_functions=available_pro_functions,
            max_steps=max_pro_steps,
            chat_id=chat_id,
            user_id=user_id,
            chat_type=chat_type,
            dispatcher=dispatcher # Передаем dispatcher
        )

        # --- Обработка результата Pro AI (остается без изменений) ---
        error_message_for_user: Optional[str] = None
        final_response_text_escaped: Optional[str] = None

        if interaction_error_msg:
            logger_ap.error(f"Core Agent (Pro): AI interaction failed for chat {chat_id}: {interaction_error_msg}")
            # Экранируем сообщение об ошибке от process_request
            error_message_for_user = f"Произошла ошибка при обработке: {escape_markdown_v2(interaction_error_msg)}"
        elif final_history_obj_list:
            final_response_text_raw = extract_text(final_history_obj_list)

            if last_func_name == 'send_telegram_message' and final_response_text_raw:
                logger_ap.info(f"Suppressing final text output because last successful action was send_telegram_message. Chat: {chat_id}")
                final_response_text_raw = None

            if final_response_text_raw:
                logger_ap.info(f"Core Agent (Pro): Final text (len={len(final_response_text_raw)}) will be sent for chat {chat_id}.")
                final_response_text_escaped = escape_markdown_v2(final_response_text_raw)
            else:
                reason = "Model generated no text" if last_func_name != 'send_telegram_message' else "Text suppressed after send_telegram_message"
                log_level = logging.INFO if last_func_name or last_sent_text else logging.WARNING # Учитываем last_sent_text
                logger_ap.log(log_level, f"Core Agent (Pro): No final text to send for chat {chat_id}. Reason: {reason}. (Last func: {last_func_name})")

            # --- Сохранение истории Pro (остается без изменений) ---
            if save_history:
                await save_history(
                      chat_id=chat_id,
                      final_history_obj_list=final_history_obj_list,
                      original_db_history_len=original_db_len,
                      current_user_id=user_id,
                      last_sent_message_text=last_sent_text # <<< ДОБАВЛЕНО ОБРАТНО
                )
            else:
                 logger_ap.error(f"Cannot save Pro history for chat {chat_id}: save_history function is not available.")
        else:
            logger_ap.error(f"Core Agent (Pro): AI interaction returned None history without error msg for chat {chat_id}")
            error_message_for_user = escape_markdown_v2("Модель AI не вернула корректный результат.")

        # --- Возврат результата Pro ---
        if error_message_for_user:
            # Сообщение об ошибке уже должно быть экранировано
            return error_message_for_user
        elif final_response_text_escaped:
            return final_response_text_escaped
        else:
            return None # Ни ошибки, ни текста

    except Exception as pro_err:
        logger_ap.error(f"Unexpected error during Pro model execution logic: {pro_err}", exc_info=True)
        return escape_markdown_v2("Произошла внутренняя ошибка при обработке вашего запроса.")


# --- Основная функция обработчика ---
async def handle_user_request(
    message: types.Message,
    force_pro_model: bool = False
) -> Optional[str]:
    """
    Основная точка входа для обработки входящего запроса пользователя.
    Управляет выбором модели (Lite/Pro) и делегирует выполнение.
    """
    chat_id = message.chat.id
    user = message.from_user
    user_id = user.id if user else 0
    chat_type = message.chat.type
    user_input = message.text or ""

    if user_id == 0:
         logger_ap.warning(f"Handling request in chat {chat_id} without user_id. Input ignored.")
         return None

    logger_ap.info(f"Core Agent: Handling request from user={user_id} in chat={chat_id} (type={chat_type}, force_pro={force_pro_model})")

    # --- Сохранение сообщения и профиля пользователя СРАЗУ (остается без изменений) ---
    if user and user_input:
        # ... (код сохранения в БД остается) ...
        try:
            await upsert_user_profile(
                user_id=user_id,
                username=user.username,
                first_name=user.first_name,
                last_name=user.last_name
            )
            user_parts_list = [{'text': user_input}]
            try:
                from utils.converters import _serialize_parts
                user_parts_json = _serialize_parts(user_parts_list)
                if database and hasattr(database, 'add_message_to_history'):
                     await database.add_message_to_history(
                         chat_id=chat_id,
                         role='user',
                         parts=user_parts_json,
                         user_id=user_id
                     )
                else:
                    logger_ap.error("Cannot save user message: Database module or add_message_to_history function unavailable.")
            except Exception as serialize_err:
                logger_ap.error(f"Agent Processor: Failed to serialize or save user message for {user_id}: {serialize_err}", exc_info=True)
            logger_ap.info(f"Agent Processor: Saved initial user message and updated profile for user {user_id}.")
        except Exception as initial_save_err:
            logger_ap.error(f"Agent Processor: Failed to save initial user message/profile for user {user_id}: {initial_save_err}", exc_info=True)

    # --- Получение моделей и настроек ---
    # <<< ИЗМЕНЕНИЕ: Получаем СПИСКИ моделей >>>
    lite_models_list = dp.workflow_data.get("lite_models_list", [])
    pro_models_list = dp.workflow_data.get("pro_models_list", [])
    available_pro_functions = dp.workflow_data.get("available_pro_functions", {})
    max_pro_steps = dp.workflow_data.get("max_pro_steps", 10)

    # Проверка наличия Pro моделей (критично)
    if not pro_models_list: # <--- Проверяем список
        logger_ap.critical(f"Core Agent: Pro model list not found or empty in workflow_data for chat {chat_id}")
        return escape_markdown_v2("⚠️ Ошибка: Основная модель AI недоступна.")
    if not bot_instance: # (остается)
        logger_ap.critical(f"Core Agent: Bot instance unavailable.")
        return escape_markdown_v2("⚠️ Ошибка: Экземпляр бота недоступен.")

    # --- ОПРЕДЕЛЕНИЕ ПУТИ ОБРАБОТКИ (логика остается, но проверка Lite изменена) ---
    call_pro_directly = False
    call_lite_filter = False
    pro_reason = ""

    if force_pro_model:
        call_pro_directly = True
        pro_reason = "Forced by flag"
    elif chat_type == aiogram_ChatType.PRIVATE:
        call_pro_directly = True
        pro_reason = "Private chat"
    elif chat_type in {aiogram_ChatType.GROUP, aiogram_ChatType.SUPERGROUP}:
        bot_info = await _get_bot_info(bot_instance)
        is_reply_to_bot = False
        is_mention = False
        if bot_info and bot_info.id:
            if (message.reply_to_message
                    and message.reply_to_message.from_user
                    and message.reply_to_message.from_user.id == bot_info.id):
                is_reply_to_bot = True
            if BOT_INFO_CACHE["username_lower"]:
                mention_pattern = rf"(^|\s)@{re.escape(BOT_INFO_CACHE['username_lower'])}(?![a-zA-Z0-9_])"
                if re.search(mention_pattern, user_input, re.IGNORECASE):
                    is_mention = True

        if is_reply_to_bot or is_mention:
            call_pro_directly = True
            pro_reason = "Reply/Mention in group"
        else:
            # <<< ИЗМЕНЕНИЕ: Проверяем список Lite моделей >>>
            if lite_models_list:
                call_lite_filter = True
                logger_ap.info(f"Lite filter will be used for group message (user {user_id} chat {chat_id}).")
            else:
                call_pro_directly = True
                pro_reason = "Lite filter unavailable (no models)"
                logger_ap.warning(f"Lite models unavailable for group chat {chat_id}, falling back to Pro.")
    else:
        call_pro_directly = True
        pro_reason = f"Unhandled chat type: {chat_type}"
        logger_ap.warning(pro_reason + ". Proceeding with Pro model.")

    # --- ЛОГИКА ВЫЗОВОВ ---
    actions_from_lite: Optional[List[Dict]] = None
    trigger_pro_after_lite = False

    # --- 1. Вызов Lite-фильтра (если решили) ---
    if call_lite_filter:
        try:
            # <<< НОВОЕ: Выбор Lite модели по индексу >>>
            # Используем тот же индекс, что и для Pro, предполагая синхронную ротацию
            # или что Lite не делает вызовы к API, требующие отдельной ротации.
            current_lite_index = get_current_api_key_index(dp)
            if current_lite_index >= len(lite_models_list):
                logger_ap.warning(f"Lite index {current_lite_index} out of bounds, resetting to 0.")
                current_lite_index = 0
            lite_model_instance = lite_models_list[current_lite_index]
            logger_ap.debug(f"Using Lite model index {current_lite_index} for filter.")

            lite_input = f"user_id: {user_id}\nchat_id: {chat_id}\nuser_input: {user_input}"
            lite_response = await lite_model_instance.generate_content_async(lite_input)

            # --- Обработка ответа Lite (остается без изменений) ---
            parse_result = parse_lite_llm_response(lite_response.text)

            if isinstance(parse_result, str) and parse_result == "NO_ACTION_NEEDED":
                logger_ap.info(f"Lite filter determined NO_ACTION_NEEDED (user {user_id} chat {chat_id}).")
                return None
            elif isinstance(parse_result, list):
                actions_from_lite = parse_result
                logger_ap.info(f"Lite filter returned {len(actions_from_lite)} actions.")
                if any(action.get("function_name") == "trigger_pro_model_processing" for action in actions_from_lite):
                    trigger_pro_after_lite = True
                    pro_reason = "Lite filter requested Pro"
            elif isinstance(parse_result, dict) and "error" in parse_result:
                logger_ap.error(f"Lite filter parsing failed: {parse_result.get('message')}. Falling back to Pro.")
                call_pro_directly = True
                pro_reason = "Lite filter parsing error"
            else:
                 logger_ap.error(f"Unexpected result from parse_lite_llm_response. Falling back to Pro.")
                 call_pro_directly = True
                 pro_reason = "Lite filter unexpected result"

            # !!! ВАЖНО: НЕ инкрементируем API ключ после вызова Lite, т.к. он
            # вероятно не делает вызовы к API Gemini или не требует ротации.
            # Ротация ключа происходит внутри process_request для Pro модели.

        except IndexError: # Если lite_models_list пуст, несмотря на проверку выше
             logger_ap.error(f"Lite filter failed: Model list is empty.")
             call_pro_directly = True
             pro_reason = "Lite model list empty"
        except Exception as lite_err:
            logger_ap.error(f"Error calling/processing Lite model API: {lite_err}", exc_info=True)
            call_pro_directly = True
            pro_reason = "Lite API/processing error"

    # --- 2. Выполнение действий из Lite (remember_user_info) (остается без изменений) ---
    if actions_from_lite is not None:
        remember_action_found = False
        pro_action_found = False
        for action in actions_from_lite:
            func_name = action.get("function_name")
            args = action.get("arguments", {})
            if func_name == "remember_user_info":
                 remember_action_found = True
                 # ... (код вызова database.upsert_user_note) ...
                 if database and hasattr(database, 'upsert_user_note') and 'user_id' in args and 'info_category' in args and 'info_value' in args:
                     try:
                         await database.upsert_user_note(
                             user_id=args['user_id'], # Используем ID из аргументов Lite
                             info_category=args['info_category'],
                             value=args['info_value']
                             # merge_lists по умолчанию True
                         )
                         logger_ap.info(f"Lite filter executed: remember_user_info for user {args.get('user_id')}")
                     except Exception as db_err:
                         logger_ap.error(f"DB error during remember_user_info from Lite: {db_err}", exc_info=True)
                 elif not database or not hasattr(database, 'upsert_user_note'):
                      logger_ap.error("Cannot execute remember_user_info: DB module or upsert_user_note unavailable.")
                 else:
                      logger_ap.error("remember_user_info requested with missing args from Lite.")
            elif func_name == "trigger_pro_model_processing":
                 pro_action_found = True

        if remember_action_found and not pro_action_found and not trigger_pro_after_lite:
            logger_ap.info(f"Finished processing: Lite triggered only 'remember'. No Pro call needed (user {user_id} chat {chat_id}).")
            return None

    # --- 3. Вызов Pro-модели (если нужно) ---
    if call_pro_directly or trigger_pro_after_lite:
        if not pro_reason: pro_reason = "Fallback or Unknown"
        logger_ap.info(f"Proceeding with Pro model for user {user_id} chat {chat_id} (Reason: {pro_reason}).")
        try:
            # <<< ИЗМЕНЕНИЕ: Передаем списки моделей и dispatcher >>>
            return await _execute_pro_model_logic(
                message=message,
                pro_models_list=pro_models_list,
                lite_models_list=lite_models_list, # Передаем для полноты
                available_pro_functions=available_pro_functions,
                max_pro_steps=max_pro_steps,
                dispatcher=dp # Передаем dispatcher (импортирован как dp)
            )
        except Exception as pro_exec_err:
             logger_ap.error(f"Core Agent: Unhandled exception during _execute_pro_model_logic call for chat {chat_id}: {pro_exec_err}", exc_info=True)
             return escape_markdown_v2("Произошла внутренняя ошибка при обработке вашего запроса основной моделью.")

    # --- 4. Завершение (если не вызвали Pro и не вышли раньше) ---
    logger_ap.info(f"Finishing request for user {user_id} chat {chat_id} (no direct Pro call, Lite filter decided no further action/Pro needed).")
    return None

logger_ap.info("--- agent_processor.py loaded successfully. ---")

========== Файл: core_agent\ai_interaction.py ==========

# core_agent/ai_interaction.py

import asyncio
import logging
import json
from typing import Dict, Any, List, Optional, Tuple, Callable

# --- Локальные импорты ---
try:
    # Модули для взаимодействия с AI и обработки FC
    import google.api_core.exceptions
    from ai_interface import gemini_api, fc_processing
    # <<< Импортируем функции управления индексом >>>
    from bot_lifecycle import get_current_api_key_index, increment_api_key_index
    # <<< Импортируем Dispatcher для доступа к workflow_data >>>
    from aiogram import Dispatcher
except ImportError:
    logging.critical("CRITICAL: Failed to import dependencies (ai_interface, bot_lifecycle, aiogram) in ai_interaction.", exc_info=True)
    gemini_api = None # type: ignore
    fc_processing = None # type: ignore
    Dispatcher = Any # type: ignore
    # Заглушки для функций управления индексом
    def get_current_api_key_index(*args, **kwargs) -> int: return 0
    def increment_api_key_index(*args, **kwargs) -> int: return 0
    # Заглушка для process_gemini_fc_cycle, чтобы код не падал
    async def mock_fc_cycle(*args, **kwargs): return None, None, None, None # Возвращает 4 значения
    if fc_processing: fc_processing.process_gemini_fc_cycle = mock_fc_cycle


# --- Типы Google и зависимости ---
try:
    import google.api_core.exceptions
    # <<< Прямой импорт Content из google.ai >>>
    from google.ai.generativelanguage import Content
    # <<< Импорт GenerateContentResponse из google.generativeai.types >>>
    from google.generativeai.types import GenerateContentResponse
    # Тип ChatType для аннотации (опционально, можно использовать Any)
    from aiogram.enums import ChatType
except ImportError:
    logging.warning("Could not import specific Google/Aiogram types in ai_interaction.")
    Content = Any
    GenerateContentResponse = Any
    ChatType = Any
    google = Any # Заглушка для exceptions

logger = logging.getLogger(__name__)

async def process_request(
    # <<< УДАЛЕНО: model_instance больше не передается напрямую >>>
    # model_instance: Any,
    initial_history: List[Content],
    user_input: str,
    available_functions: Dict[str, Callable],
    max_steps: int,
    chat_id: int,
    user_id: int,
    chat_type: ChatType, # Используем импортированный тип или Any
    # <<< ДОБАВЛЕНО: Передаем dispatcher для доступа к workflow_data >>>
    dispatcher: Dispatcher
) -> Tuple[Optional[List[Content]], Optional[str], Optional[str], Optional[str], Optional[Dict]]:
    """
    Запускает сессию Gemini, отправляет сообщение, обрабатывает FC
    и обрабатывает ошибки квоты (429) с ПЕРЕКЛЮЧЕНИЕМ КЛЮЧЕЙ/МОДЕЛЕЙ и повторными попытками.

    Args:
        initial_history: Начальная история чата (список объектов Content).
        user_input: Текст сообщения пользователя.
        available_functions: Словарь доступных функций.
        max_steps: Максимальное количество шагов FC.
        chat_id: ID чата.
        user_id: ID пользователя.
        chat_type: Тип чата.
        dispatcher: Экземпляр Dispatcher для доступа к workflow_data.

    Returns:
        - final_history_obj_list: Финальная история (список объектов Content) или None при ошибке.
        - error_message: Сообщение об ошибке, если она произошла.
        - last_called_func_name: Имя последней *успешно* вызванной функции.
        - last_sent_text: Текст последнего сообщения, отправленного через send_telegram_message (или None).
        - last_func_result: Результат (словарь) последнего успешного вызова (или None).
    """
    # --- Инициализация возвращаемых значений ---
    final_history_obj_list: Optional[List[Content]] = None
    last_called_func_name: Optional[str] = None
    error_message: Optional[str] = None
    last_sent_text: Optional[str] = None
    last_func_result: Optional[Dict] = None

    logger.info(f"Running Gemini interaction for chat={chat_id}, user={user_id}, chat_type={chat_type}")

    # --- Проверки на старте ---
    if not gemini_api or not fc_processing:
         error_message = "Internal configuration error: AI interface modules not loaded."
         logger.critical(error_message)
         return None, error_message, None, None, None
    if dispatcher is None:
         error_message = "Internal configuration error: Dispatcher instance not provided."
         logger.critical(error_message)
         return None, error_message, None, None, None

    # <<< НОВОЕ: Получаем СПИСКИ моделей из workflow_data >>>
    pro_models_list = dispatcher.workflow_data.get("pro_models_list")
    api_keys_list = dispatcher.workflow_data.get("google_api_keys", []) # Получаем ключи для логирования

    # Проверяем наличие и непустоту списка моделей
    if not pro_models_list or not isinstance(pro_models_list, list) or len(pro_models_list) == 0:
         error_message = "AI Pro model list is not available or empty in workflow_data."
         logger.critical(f"{error_message} Chat: {chat_id}")
         return None, error_message, None, None, None

    num_keys = len(pro_models_list)
    logger.debug(f"Found {num_keys} Pro models (API keys) to use.")

    # --- НАСТРОЙКИ RETRY/ПЕРЕКЛЮЧЕНИЯ ---
    MAX_KEY_SWITCH_RETRIES = num_keys # Попробуем каждый ключ по одному разу
    INITIAL_RETRY_DELAY_SECONDS = 2 # Задержка ПЕРЕД повторной попыткой с НОВЫМ ключом

    # --- Инициализация переменных для цикла ---
    model_instance: Optional[Any] = None # Модель текущей попытки
    chat_session: Optional[Any] = None   # Сессия текущей попытки
    current_response: Optional[GenerateContentResponse] = None # Ответ текущей попытки
    retries = 0                          # Счетчик попыток (переключений ключей)
    initial_key_index = get_current_api_key_index(dispatcher) # Запоминаем стартовый индекс
    current_key_index = initial_key_index   # Индекс для текущей попытки

    # --- Основной цикл выбора ключа и попытки API вызова ---
    while retries < MAX_KEY_SWITCH_RETRIES: # Изменено условие цикла
        # 1. Выбираем модель для текущей попытки
        try:
            model_instance = pro_models_list[current_key_index]
            current_key_snippet = f"...{api_keys_list[current_key_index][-4:]}" if current_key_index < len(api_keys_list) else "???"
            logger.info(f"Attempt {retries + 1}/{MAX_KEY_SWITCH_RETRIES}. Using API key index {current_key_index} ({current_key_snippet}) for chat {chat_id}")
        except IndexError:
             # Этого не должно произойти при правильной логике % num_keys, но добавим защиту
             logger.error(f"Logic Error: Invalid API key index {current_key_index} attempted (list size {num_keys}). Resetting to 0.")
             current_key_index = 0
             if num_keys > 0: model_instance = pro_models_list[0]
             else: # Если список моделей внезапно стал пустым
                 error_message = "AI Pro model list became empty during processing."
                 logger.critical(error_message)
                 return None, error_message, None, None, None
        except Exception as model_select_err:
             error_message = f"Failed to select model for key index {current_key_index}: {model_select_err}"
             logger.critical(error_message, exc_info=True)
             # Инкрементируем индекс перед выходом, чтобы след. запрос начал с другого ключа
             increment_api_key_index(dispatcher)
             return None, error_message, None, None, None

        # 2. Создаем сессию для ВЫБРАННОЙ модели
        try:
             chat_session = model_instance.start_chat(history=initial_history)
             if not chat_session: raise ValueError("model.start_chat returned None")
             logger.debug(f"Chat session started successfully for key index {current_key_index}.")
        except Exception as session_err:
             error_message = f"Failed to start chat session for key index {current_key_index}: {session_err}"
             logger.error(f"{error_message} Chat: {chat_id}", exc_info=True)
             # Ошибка сессии - переходим к следующему ключу
             retries += 1
             current_key_index = (initial_key_index + retries) % num_keys # Переключаем индекс
             logger.warning(f"Session error. Will try next key index {current_key_index} after delay.")
             await asyncio.sleep(INITIAL_RETRY_DELAY_SECONDS) # Задержка перед след. ключом
             continue # Переходим к следующей итерации цикла while

        # 3. Пытаемся выполнить API вызов с текущей моделью/сессией
        try:
             loop = asyncio.get_running_loop()
             logger.debug(f"Attempting Gemini API call with key index {current_key_index} for chat {chat_id}")

             # --- Вызов синхронной функции в executor'е ---
             current_response = await loop.run_in_executor(
                 None, # Используем executor по умолчанию
                 gemini_api.send_message_to_gemini, # Имя синхронной функции
                 model_instance, # 1-й аргумент (model)
                 chat_session,   # 2-й аргумент (chat_session)
                 user_input      # 3-й аргумент (user_message)
             )

             # --- Логирование ответа (можно добавить детализацию, как было раньше) ---
             if current_response:
                  logger.debug(f"Raw Gemini Response object (key index {current_key_index}) for chat {chat_id}: {current_response!r}")
                  # ... (можно добавить код для логирования parts, text, function_call и т.д.) ...
             else:
                  # Случай, когда send_message_to_gemini вернула None без исключения
                  logger.error(f"Gemini API call with key index {current_key_index} returned None response.")
                  # Можно либо пробовать следующий ключ, либо вернуть ошибку
                  # Давайте попробуем следующий ключ
                  raise google.api_core.exceptions.Unknown("API returned None response") # Имитируем ошибку для перехода


             # --- Успех! Выходим из цикла retry ---
             logger.info(f"API call successful with key index {current_key_index} for chat {chat_id}")
             # !!! ВАЖНО: Сдвигаем ГЛОБАЛЬНЫЙ индекс для СЛЕДУЮЩЕГО запроса к боту !!!
             increment_api_key_index(dispatcher)
             break # <--- Выход из цикла while

        # --- Ловим ошибку квоты (429) ---
        except google.api_core.exceptions.ResourceExhausted as quota_error:
             logger.warning(f"Quota exceeded (429) on key index {current_key_index} for chat {chat_id}.")
             retries += 1
             if retries < MAX_KEY_SWITCH_RETRIES: # Если еще есть ключи для пробы
                 next_try_key_index = (initial_key_index + retries) % num_keys
                 logger.warning(f"Switching to next key index {next_try_key_index}. Retrying in {INITIAL_RETRY_DELAY_SECONDS}s... (Attempt {retries + 1}/{MAX_KEY_SWITCH_RETRIES})")
                 current_key_index = next_try_key_index # Устанавливаем индекс для следующей итерации
                 await asyncio.sleep(INITIAL_RETRY_DELAY_SECONDS) # Задержка перед след. попыткой
                 chat_session = None # Сбрасываем сессию, т.к. будем использовать другую модель
                 continue # Переходим к следующей итерации цикла while
             else: # Исчерпаны все ключи
                  error_message = f"Quota limit exceeded after trying all {num_keys} API keys."
                  logger.error(f"{error_message} Chat: {chat_id}. Last error on index {current_key_index}: {quota_error}")
                  # Инкрементируем индекс перед выходом
                  increment_api_key_index(dispatcher)
                  return None, error_message, None, None, None

        # --- Ловим другие ошибки API ---
        except Exception as api_call_error:
             # Ловим остальные ошибки, включая имитированную "API returned None response"
             error_message = f"API call failed on key index {current_key_index}: {api_call_error}"
             logger.error(f"{error_message} Chat: {chat_id}", exc_info=isinstance(api_call_error, google.api_core.exceptions.Unknown)) # Не логируем полный трейсбек для имитированной ошибки
             # При других ошибках НЕ переключаем ключ автоматически в этом же запросе,
             # но инкрементируем глобальный индекс для СЛЕДУЮЩЕГО запроса.
             increment_api_key_index(dispatcher)
             return None, error_message, None, None, None
    # --- КОНЕЦ ЦИКЛА while retries < MAX_KEY_SWITCH_RETRIES ---

    # --- Проверки после цикла ---
    if current_response is None:
        # Сюда можно попасть, если все ключи дали ошибку СЕССИИ (не API)
        if not error_message: error_message = "Failed to get response from AI model after trying all keys (possibly session errors)."
        logger.error(f"{error_message} Chat: {chat_id}")
        # Инкрементируем индекс перед выходом
        increment_api_key_index(dispatcher)
        return None, error_message, None, None, None
    if chat_session is None:
         # Этого не должно произойти, если current_response не None, но проверим
         error_message = "Internal logic error: Successful response but no valid chat session."
         logger.critical(f"{error_message} Chat: {chat_id}")
         # Инкрементируем индекс перед выходом
         increment_api_key_index(dispatcher)
         return None, error_message, None, None, None
    if model_instance is None:
         # Тоже маловероятно
         error_message = "Internal logic error: Successful response but no valid model instance."
         logger.critical(f"{error_message} Chat: {chat_id}")
         # Инкрементируем индекс перед выходом
         increment_api_key_index(dispatcher)
         return None, error_message, None, None, None


    # Проверка импорта типа Content (на всякий случай)
    if Content is None or not callable(fc_processing.process_gemini_fc_cycle):
        error_message = "Internal configuration error: AI type system or FC processor failed."
        logger.critical(error_message)
        # Инкрементируем индекс перед выходом
        increment_api_key_index(dispatcher)
        return None, error_message, None, None, None

    # --- Запускаем цикл обработки Function Calling ---
    # Используем model_instance и chat_session, полученные на ПОСЛЕДНЕЙ УСПЕШНОЙ итерации
    try:
        final_history_obj_list, last_called_func_name, last_sent_text, last_func_result = await fc_processing.process_gemini_fc_cycle(
            model_instance=model_instance, # Успешная модель
            chat_session=chat_session,     # Успешная сессия
            available_functions_map=available_functions,
            max_steps=max_steps,
            original_chat_id=chat_id,
            original_user_id=user_id
        )
    except Exception as fc_error:
        error_message = f"Error during Function Calling processing: {fc_error}"
        logger.error(f"{error_message} Chat: {chat_id}", exc_info=True)
        # Неясно, нужно ли инкрементировать индекс здесь, т.к. основной вызов API прошел.
        # Пока не будем инкрементировать повторно.
        # final_history_obj_list будет None в этом случае по логике process_gemini_fc_cycle
        return getattr(chat_session, 'history', None), error_message, None, None, None # Возвращаем историю до ошибки FC

    # --- Обработка результата FC цикла ---
    # final_history_obj_list может быть None, если сам цикл FC упал критически (обработано выше)
    if final_history_obj_list is None:
         # Эта ветка достигается, если process_gemini_fc_cycle вернул (None, ...)
         if not error_message: # Если ошибка не была установлена внутри fc_cycle
              error_message = "AI model processing (Function Calling) cycle failed."
         logger.error(f"{error_message} Chat: {chat_id}")
         # Возвращаем имя последней функции, если оно было установлено до ошибки
         # Историю берем из chat_session, т.к. final_history_obj_list тут None
         return getattr(chat_session, 'history', None), error_message, last_called_func_name, last_sent_text, last_func_result
    elif not final_history_obj_list:
         # Случай, когда fc_cycle вернул ([], ...) - пустой список
         error_message = "AI model processing cycle resulted in empty history (unexpected)."
         logger.warning(f"{error_message} Chat: {chat_id}")
         return None, error_message, last_called_func_name, last_sent_text, last_func_result

    # Если все прошло успешно (API вызов + FC цикл)
    return final_history_obj_list, error_message, last_called_func_name, last_sent_text, last_func_result


========== Файл: core_agent\history_manager.py ==========

# core_agent/history_manager.py

import logging
import json
import re
# <<< ДОБАВЛЕНЫ ИМПОРТЫ ВЕРСИОНИРОВАНИЯ >>>
import sys # Для проверки версии Python
# <<< КОНЕЦ ДОБАВЛЕНЫ ИМПОРТЫ >>>
from typing import List, Dict, Any, Optional, Tuple, Union # Добавили Union

# --- Google Types ---
# Импортируем типы Google. Ошибка импорта здесь критична для работы с моделью.
# Если Python < 3.9, ast.unparse не будет доступен, что повлияет на инструменты, но не на базовый import
try:
    # Используем более специфичный импорт, если знаем, где находится RepeatedComposite
    # или полагаемся на то, что он доступен после импорта glm
    # https://github.com/googleapis/python-api-core/blob/main/google/api_core/protobuf_helpers.py
    # или прямо из google.protobuf.internal.containers (как в оригинале)
    # Проверим версию protobuf, если нужно

    # Попробуем импортировать нужный класс напрямую
    # Оставляем старый импорт, так как он используется в заглушке
    from google.protobuf.internal.containers import RepeatedComposite as GoogleRepeatedComposite
    # Проверяем, что импорт удался, прежде чем присваивать переменной
    RepeatedComposite = GoogleRepeatedComposite
    logger_types = logging.getLogger(__name__)
    logger_types.debug("Successfully imported RepeatedComposite from google.protobuf.internal.containers.")
except ImportError as e:
    logger_types = logging.getLogger(__name__)
    # Логируем критическую ошибку импорта RepeatedComposite
    logger_types.critical(f"CRITICAL: Failed to import RepeatedComposite from google.protobuf.internal.containers: {e}", exc_info=True)
    RepeatedComposite = Any # Определяем как Any, если импорт не удался


try:
    # Импортируем основные типы Google AI после попытки импорта RepeatedComposite
    from google.ai import generativelanguage as glm
    Content = glm.Content
    Part = glm.Part
    FunctionResponse = glm.FunctionResponse
    FunctionCall = glm.FunctionCall
    logger_types.debug("Successfully imported Google AI core types (glm).")
except ImportError as e:
    logger_types.warning(f"Could not import Google AI core types (glm): {e}. Setting core types to Any.", exc_info=True)
    Content = Any # Fallback
    Part = Any # Fallback
    FunctionResponse = Any # Fallback
    FunctionCall = Any # Fallback


# --- Database Module ---
# Импортируем модуль базы данных. Ошибка здесь критична для хранения истории.
# Этот импорт зависит от корректной настройки БД и драйвера (aiosqlite)
try:
    import database
    logger_db = logging.getLogger(__name__)
    logger_db.debug("Successfully imported database module.")
except ImportError as e:
    logger_db = logging.getLogger(__name__)
    logger_db.critical(f"CRITICAL: Failed to import database module in history_manager: {e}", exc_info=True)
    database = None # type: ignore
    logging.warning("Database module unavailable. History functionality will be disabled.")


# --- Utility Functions ---
# Импортируем вспомогательные функции из локальных модулей.
# Эти импорты зависят от того, что utils.helpers и utils.converters
# были успешно загружены на более ранних этапах импорта Python.
# Их успешная загрузка, в свою очередь, может зависеть от импорта Google Types
# внутри них (как мы видели в utils.converters.py).
try:
    # escape_markdown_v2 и remove_markdown
    from utils.helpers import escape_markdown_v2, remove_markdown
    # Функции конвертации
    from utils.converters import _deserialize_parts, reconstruct_content_object, _convert_part_to_dict, _convert_value_for_json
    logger_utils = logging.getLogger(__name__)
    logger_utils.debug("Successfully imported utility functions.")
except ImportError as e:
    logger_utils = logging.getLogger(__name__)
    # Это предупреждение, но мы будем проверять availability этих функций перед использованием
    logger_utils.warning(f"Could not import utility functions or converters in history_manager: {e}.", exc_info=True)
    # Определяем заглушки, чтобы остальной код мог запуститься
    def escape_markdown_v2(text: Optional[str]) -> str: return text or "" # type: ignore
    def remove_markdown(text: Optional[str]) -> str: return text or "" # type: ignore
    def _deserialize_parts(parts_json: Optional[str]) -> List[Dict[str, Any]]: return [] # type: ignore
    def reconstruct_content_object(role: str, parts_list: List[Dict[str, Any]]) -> Optional[Any]: return None # type: ignore
    def _convert_part_to_dict(part: Any) -> Optional[Dict[str, Any]]: return None # type: ignore
    def _convert_value_for_json(value: Any) -> Any: return str(value) # type: ignore # Грубая заглушка
    logging.warning("Using mock utility functions in history_manager due to import errors.")

# Проверяем, что импорт Content и Part удался, для использования в type hints и коде
if Content is Any or Part is Any:
     logging.warning("Google AI core types (Content, Part) are not available. History functionality will be limited.")


logger = logging.getLogger(__name__) # Получаем основной логгер для этого модуля

# Константа для обрезки вывода логов в истории
MAX_LOG_CONTEXT_LEN = 200
MAX_FULL_RESULT_PREVIEW = 500

# --- Функция подготовки истории ---
async def prepare_history(
    chat_id: int,
    user_id: int, # ID ТЕКУЩЕГО пользователя (для заметок и профиля)
    chat_type: Any, # Тип чата для определения, нужны ли префиксы (Any для совместимости с заглушкой)
    add_notes: bool = True, # Флаг, добавлять ли контекст пользователя
    add_recent_logs: bool = True, # Флаг, добавлять ли недавние логи выполнения
    recent_logs_limit: int = 8 # Количество недавних логов для добавления
) -> Tuple[List[Any], int]: # List[Any] т.к. Content может быть заглушкой
    """
    Получает историю из БД, заметки/профиль пользователя, недавние логи выполнения,
    форматирует историю для модели (префиксы).
    *** УДАЛЕНА некорректная логика фильтрации последнего текстового сообщения модели. ***

    Возвращает:
        - final_history_for_api: Список объектов Content (или их заглушек) для model.start_chat().
        - original_db_len: Исходная длина истории из БД (для расчета новых сообщений).
    """
    logger.debug(f"Preparing history for chat={chat_id}, current_user={user_id}, chat_type={chat_type}, add_notes={add_notes}, add_logs={add_recent_logs}, log_limit={recent_logs_limit}")

    # Проверка доступности БД и необходимых утилит/типов перед началом работы
    # Проверяем database и ключевые функции конвертации
    if database is None or _deserialize_parts is None or reconstruct_content_object is None or escape_markdown_v2 is None:
         logger.critical("Database module or essential utility functions/types unavailable. Cannot prepare history.")
         # Логи из предыдущих запусков показывают, что database и конвертеры могут быть None
         # due to the RepeatedComposite error.
         # Если эта ошибка возникла, возвращаем пустую историю и 0 записей.
         return [], 0 # Возвращаем пустую историю и 0 записей


    # 1. Получение данных из БД
    history_from_db: List[Dict[str, Any]] = []
    user_profile: Optional[Dict[str, Any]] = None
    user_notes: Dict[str, Any] = {}
    recent_logs: List[Dict[str, Any]] = []
    original_db_len: int = 0 # Инициализируем
    try:
        # Получаем историю в виде словарей (как она хранится в БД)
        # Проверяем наличие функций перед вызовом на всякий случай
        if hasattr(database, 'get_chat_history'):
             history_from_db = await database.get_chat_history(chat_id) # Ожидаем List[Dict]
             original_db_len = len(history_from_db) # <<< ЗАПОМИНАЕМ ОРИГИНАЛЬНУЮ ДЛИНУ ЗДЕСЬ
        else: logger.warning("Database.get_chat_history unavailable.")

        if add_notes:
            if hasattr(database, 'get_user_profile'): user_profile = await database.get_user_profile(user_id)
            else: logger.warning("Database.get_user_profile unavailable.")
            if hasattr(database, 'get_user_notes'): user_notes = await database.get_user_notes(user_id, parse_json=True)
            else: logger.warning("Database.get_user_notes unavailable.")
        if add_recent_logs and recent_logs_limit > 0:
            if hasattr(database, 'get_recent_tool_executions'): recent_logs = await database.get_recent_tool_executions(chat_id, limit=recent_logs_limit)
            else: logger.warning("Database.get_recent_tool_executions unavailable.")

    except Exception as db_err:
        logger.error(f"DB error during history/profile/notes/logs fetch for chat={chat_id}, user={user_id}: {db_err}", exc_info=True)
        # original_db_len остается 0, если была ошибка
        # Возвращаем пустую историю, чтобы бот не упал
        return [], 0


    # --- УДАЛЕНА логика фильтрации последнего текстового сообщения ---
    # Это была попытка обойти проблему, теперь она не нужна.


    # 2. Формирование истории для модели (список объектов Content)
    # Используем List[Any], так как Content может быть заглушкой
    prepared_history_objects: List[Any] = []

    # --- Добавляем блок RAG (недавние логи) ---
    # Проверяем доступность escape_markdown_v2 перед использованием
    if add_recent_logs and recent_logs and escape_markdown_v2:
        logs_str_parts = [escape_markdown_v2("~~~Недавние Выполненные Действия~~~")]
        added_log_count = 0
        # Используем reversed, чтобы последние логи были ближе к концу контекста
        for log_entry in reversed(recent_logs):
            tool_name = log_entry.get('tool_name', 'unknown_tool')
            # Не добавляем логи инструментов коммуникации или инструментов,
            # которые могут зацикливать контекст или создают слишком много шума.
            # send_telegram_message, Developer_Feedback уже обрабатываются отдельно.
            # Пропускаем логи поиска, если они уже включены в Deep Search output (например, в future версиях)
            if tool_name in {'send_telegram_message', 'Developer_Feedback', '_perform_web_search_async'}:
                logger.debug(f"History Prep: Skipping log entry for tool '{tool_name}' (filtered).")
                continue

            log_line_parts = []
            # Безопасно получаем время и обрезаем миллисекунды
            ts = escape_markdown_v2(str(log_entry.get('timestamp', 'N/A')).split('.')[0])
            status = escape_markdown_v2(str(log_entry.get('status', 'unknown')))
            msg = log_entry.get('result_message')
            stdout = log_entry.get('stdout')
            stderr = log_entry.get('stderr')
            full_result_json_str = log_entry.get('full_result_json') # Уже строка JSON или None

            log_line_parts.append(f"- [{ts}] **{escape_markdown_v2(tool_name)}** (Статус: **{status}**)")

            # Добавляем сообщение результата, если оно есть и не дублируется в full_result_json
            if msg:
                try:
                    # Проверяем, содержится ли msg в full_result_json_str
                    if full_result_json_str and isinstance(full_result_json_str, str) and msg in full_result_json_str:
                         pass # Пропускаем msg, если он часть полного результата
                    else:
                        truncated_msg = (msg[:MAX_LOG_CONTEXT_LEN] + '...') if len(msg) > MAX_LOG_CONTEXT_LEN else msg
                        log_line_parts.append(f"  - Результат: `{escape_markdown_v2(truncated_msg)}`")
                except Exception as check_msg_err:
                    logger.warning(f"History Prep: Error checking if msg is in full_result_json for '{tool_name}': {check_msg_err}")
                    # В случае ошибки проверки, добавим msg
                    truncated_msg = (msg[:MAX_LOG_CONTEXT_LEN] + '...') if len(msg) > MAX_LOG_CONTEXT_LEN else msg
                    log_line_parts.append(f"  - Результат: `{escape_markdown_v2(truncated_msg)}`")


            if full_result_json_str:
                try:
                    # Пытаемся распарсить и красиво отформатировать JSON
                    # Важно: даже если парсинг тут упадет, full_result_json_str все еще строка и может быть отправлена как raw
                    parsed_result = json.loads(full_result_json_str)
                    # Форматируем с отступами для лучшей читаемости (но больше токенов)
                    formatted_result = json.dumps(parsed_result, indent=2, ensure_ascii=False, default=str) # default=str на всякий случай
                    # Обрезаем, если слишком длинный
                    if len(formatted_result) > MAX_FULL_RESULT_PREVIEW:
                        result_preview = formatted_result[:MAX_FULL_RESULT_PREVIEW] + "\n... [Full Result Truncated]"
                    else:
                        result_preview = formatted_result

                    log_line_parts.append(f"  - Полный Результат (JSON):\n```json\n{escape_markdown_v2(result_preview)}\n```")
                except json.JSONDecodeError:
                    # Если это не JSON, добавляем как текст (обрезанный)
                    preview = (full_result_json_str[:MAX_FULL_RESULT_PREVIEW] + '...[Truncated]') if len(full_result_json_str) > MAX_FULL_RESULT_PREVIEW else full_result_json_str
                    log_line_parts.append(f"  - Полный Результат (Raw):\n```\n{escape_markdown_v2(preview)}\n```")
                except Exception as format_err:
                     logger.warning(f"History Prep: Error formatting full_result_json: {format_err}")
                     # В случае ошибки форматирования, добавим raw строку
                     preview = (str(full_result_json_str)[:MAX_FULL_RESULT_PREVIEW] + '...[Truncated]') if len(str(full_result_json_str)) > MAX_FULL_RESULT_PREVIEW else str(full_result_json_str)
                     log_line_parts.append(f"  - Полный Результат (Error):\n```\n{escape_markdown_v2(preview)}\n```")


            if stdout and (not full_result_json_str or (isinstance(full_result_json_str, str) and stdout not in full_result_json_str)):
                truncated_stdout = (stdout[:MAX_LOG_CONTEXT_LEN] + '... (обрезано)') if len(stdout) > MAX_LOG_CONTEXT_LEN else stdout
                log_line_parts.append(f"  - Вывод (stdout):\n```\n{escape_markdown_v2(truncated_stdout)}\n```")
            if stderr and (not full_result_json_str or (isinstance(full_result_json_str, str) and stderr not in full_result_json_str)):
                truncated_stderr = (stderr[:MAX_LOG_CONTEXT_LEN] + '... (обрезано)') if len(stderr) > MAX_LOG_CONTEXT_LEN else stderr
                log_line_parts.append(f"  - Ошибки (stderr):\n```\n{escape_markdown_v2(truncated_stderr)}\n```")

            # Добавляем пустую строку для разделения логов
            logs_str_parts.append("\n".join(log_line_parts))
            added_log_count += 1

        # Добавляем блок логов, только если есть что добавить
        if added_log_count > 0:
            full_logs_str = "\n\n".join(logs_str_parts)
            try:
                # Создаем Content объект для блока логов
                # Проверяем, что необходимые типы доступны
                if Content is not Any and Part is not Any:
                    logs_content = Content(role="model", parts=[Part(text=full_logs_str)])
                    prepared_history_objects.append(logs_content)
                    logger.info(f"Added {added_log_count} recent non-communication tool execution logs to history context for chat {chat_id}.")
                else:
                    logger.warning("History Prep: Skipping adding log content due to missing Google AI types.")
            except Exception as logs_content_err:
                 logger.error(f"Failed to create Content object for recent logs: {logs_content_err}", exc_info=True)
    elif add_recent_logs:
        logger.warning("History Prep: Skipping adding recent logs context: escape_markdown_v2 unavailable.")


    # --- Добавляем контекст пользователя (профиль + заметки) ---
    # Проверяем доступность всех необходимых компонентов перед добавлением контекста пользователя
    if add_notes and database is not None and hasattr(database, 'get_user_profile') and hasattr(database, 'get_user_notes') and escape_markdown_v2 is not None:
        user_data_str_parts = []
        context_added = False
        try:
            user_profile = await database.get_user_profile(user_id)
            user_notes = await database.get_user_notes(user_id, parse_json=True)

            if user_profile:
                profile_parts = [f"*Ваш Профиль (User ID: {user_id}):*"] # user_id здесь - ID текущего пользователя
                if user_profile.get('first_name'): profile_parts.append(f"- Имя: {escape_markdown_v2(str(user_profile['first_name']))}")
                if user_profile.get('username'): profile_parts.append(f"- Username: @{escape_markdown_v2(str(user_profile['username']))}")
                if user_profile.get("avatar_description"): profile_parts.append(f"- Аватар: {escape_markdown_v2(str(user_profile['avatar_description']))}")
                user_data_str_parts.append("\n".join(profile_parts))
                context_added = True
            if user_notes:
                notes_str_list = []
                # Используем сортировку по ключам для консистентности
                for cat in sorted(user_notes.keys()):
                     val = user_notes[cat]
                     try:
                          # Если значение является dict или list, сериализуем его красиво
                          if isinstance(val, (dict, list)):
                               val_str = json.dumps(val, ensure_ascii=False, indent=2, default=str) # default=str на всякий случай
                               notes_str_list.append(f"- **{escape_markdown_v2(cat)}** (JSON):\n```json\n{escape_markdown_v2(val_str)}\n```")
                          else:
                               # Иначе, просто конвертируем в строку и экранируем
                               notes_str_list.append(f"- **{escape_markdown_v2(cat)}**: {escape_markdown_v2(str(val))}")
                     except Exception as format_err:
                          logger.warning(f"Error formatting note value for cat '{cat}': {format_err}. Using str().")
                          # В случае ошибки форматирования, просто используем str() и экранируем
                          notes_str_list.append(f"- **{escape_markdown_v2(cat)}**: {escape_markdown_v2(str(val))}")
                if notes_str_list:
                     notes_section = "*Ваши Заметки:*\n" + "\n".join(notes_str_list)
                     user_data_str_parts.append(notes_section)
                     context_added = True

        except Exception as db_notes_err:
             logger.error(f"Error fetching user notes/profile from DB for user {user_id}: {db_notes_err}", exc_info=True)
             # Не прерываем, просто не добавляем контекст

        if context_added:
             full_context_str = escape_markdown_v2("~~~Контекст Текущего Пользователя~~~") + "\n" + "\n\n".join(user_data_str_parts)
             try:
                 # Создаем Content объект для блока контекста
                 # Проверяем, что необходимые типы доступны
                 if Content is not Any and Part is not Any:
                     context_content = Content(role="model", parts=[Part(text=full_context_str)])
                     prepared_history_objects.append(context_content)
                     logger.info(f"Added combined profile/notes context for current user {user_id} in chat {chat_id}.")
                 else:
                      logger.warning("History Prep: Skipping adding user context content due to missing Google AI types.")
             except Exception as context_err:
                 logger.error(f"Failed to create Content object for user context: {context_err}", exc_info=True)
    elif add_notes:
        logger.warning("History Prep: Skipping adding user notes/profile context: Database module or necessary functions unavailable.")


    # --- Добавляем историю сообщений из БД (ИЗ ПОЛНОГО СПИСКА) ---
    processed_db_entries_count = 0
    # ИСПОЛЬЗУЕМ history_from_db БЕЗ ФИЛЬТРАЦИИ
    # Проверяем, что reconstruct_content_object и _deserialize_parts доступны
    if reconstruct_content_object and _deserialize_parts and Content is not Any and Part is not Any:
        for entry in history_from_db:
            role = entry.get("role")
            parts_json_str = entry.get("parts_json") # Получаем строку JSON
            db_user_id = entry.get("user_id") # ID пользователя из БД

            if not role or parts_json_str is None or not isinstance(parts_json_str, str):
                logger.warning(f"History Prep: Skipping DB entry with missing/invalid role or parts_json: {entry}")
                continue

            # НЕ пропускаем 'function' роли здесь. Они нужны модели для FC цикла.

            # Десериализуем JSON строку в список словарей
            parts_list_of_dicts = _deserialize_parts(parts_json_str)

            # Пытаемся реконструировать объект Content из словарей
            reconstructed_content = reconstruct_content_object(role, parts_list_of_dicts)

            # Добавляем реконструированный объект
            # Проверяем, что объект Content успешно создан и имеет правильную роль
            if reconstructed_content and getattr(reconstructed_content, 'role', None) == role:
                 # Добавляем префикс пользователя (если нужно)
                 # Добавляем префикс ТОЛЬКО К СООБЩЕНИЯМ ПОЛЬЗОВАТЕЛЕЙ, если чат не личный
                 # Проверяем, что escape_markdown_v2 доступен перед использованием
                 if role == 'user' and db_user_id is not None and chat_type != ChatType.PRIVATE and escape_markdown_v2 is not None:
                     try:
                         # Ищем текстовую часть для добавления префикса и модифицируем ее
                         # Убедимся, что glm и glm.Part доступны, если используем их.
                         if all([glm, glm.Part]):
                             new_parts_for_user_entry = []
                             prefix_added = False
                             # Итерируемся по частям, чтобы найти текстовую
                             for original_part in reconstructed_content.parts:
                                  # Проверяем тип Part и наличие текста
                                  if isinstance(original_part, glm.Part) and hasattr(original_part, 'text') and isinstance(original_part.text, str):
                                      # Создаем новую Part с префиксом
                                      prefixed_text = f"User {db_user_id}: {original_part.text}"
                                      # Создаем новую Part, так как Part из glm могут быть immutable
                                      new_parts_for_user_entry.append(glm.Part(text=prefixed_text))
                                      prefix_added = True
                                  elif isinstance(original_part, glm.Part):
                                      # Сохраняем другие типы частей (FC, FR) без изменений
                                      new_parts_for_user_entry.append(original_part)
                                  # Игнорируем другие типы в parts (если они там оказались)

                             # Если удалось добавить префикс хотя бы к одной текстовой части, заменяем parts у reconstructed_content
                             if prefix_added:
                                  # Создаем новый Content объект с модифицированными частями
                                  reconstructed_content = glm.Content(role='user', parts=new_parts_for_user_entry)
                                  logger.debug(f"Added user prefix for chat {chat_id}, user {db_user_id}.")
                             else:
                                logger.debug(f"History Prep: Could not add user prefix for chat {chat_id}, user {db_user_id}: No text part found in reconstructed Content.")

                         elif Content and Part: # Fallback с заглушками Part/Content
                              # Логика с заглушками будет проще, но менее надежной
                              # Пропустим добавление префикса в этом случае
                              logger.warning("History Prep: Skipping user prefix due to missing Google types.")
                         else:
                             logger.warning("History Prep: Skipping user prefix due to missing Google or fallback types.")


                     except Exception as prefix_err:
                         logger.error(f"Error adding user prefix to reconstructed content: {prefix_err}", exc_info=True)
                         # Продолжаем, даже если не удалось добавить префикс

                 # Добавляем обработанный (возможно, с префиксом) Content объект
                 prepared_history_objects.append(reconstructed_content)
                 processed_db_entries_count += 1

            else:
                logger.warning(f"History Prep: Skipped DB entry for role '{role}' because reconstruction failed or returned None/wrong role.")
                # Можно добавить запись-заглушку об ошибке в историю, чтобы модель видела, что был пропуск
                # Проверяем, что Content и Part доступны перед созданием заглушки
                if Content is not Any and Part is not Any:
                    error_content = Content(role="model", parts=[Part(text=f"Internal Error: Failed to reconstruct history entry for role '{role}'.")])
                    prepared_history_objects.append(error_content)
                    logger.warning(f"History Prep: Added error placeholder for role '{role}'.")


        logger.debug(f"History Prep: Finished processing {processed_db_entries_count} entries from DB history. Prepared {len(prepared_history_objects)} Content objects.")
    else:
        logger.critical("History Prep: Skipping DB history processing: _deserialize_parts, reconstruct_content_object, or Google AI types unavailable.")


    final_history_for_api = prepared_history_objects
    # Добавим лог, чтобы видеть, что передается
    logger.debug(f"Final history prepared for API call. Length: {len(final_history_for_api)}")
    # Возвращаем подготовленную историю и исходную длину из БД
    return final_history_for_api, original_db_len

# --- Функция сохранения истории ---
async def save_history(
    chat_id: int,
    final_history_obj_list: Optional[List[Any]], # List[Any] т.к. Content может быть заглушкой
    original_db_history_len: int,
    current_user_id: int,
    last_sent_message_text: Optional[str] = None # Принято для совместимости, сейчас не используется
):
    """
    Сохраняет НОВЫЕ сообщения из final_history в БД chat_history.
    НЕ сохраняет 'user' и 'function' сообщения.
    *** Исправлено: СОХРАНЯЕТ текстовые части 'model' сообщений, даже если они содержат FunctionCall/Response. ***
    Использует original_db_history_len для определения новых сообщений.

    Args:
        chat_id (int): ID чата.
        final_history_obj_list (Optional[List[Content]]): Полный список истории Content объектов
            после взаимодействия с моделью, или None при ошибке.
        original_db_history_len (int): Количество сообщений, которые были *загружены из БД*
            перед этим взаимодействием.
        current_user_id (int): ID пользователя, отправившего последнее сообщение в этом цикле.
        last_sent_message_text (Optional[str]): Текст ПОСЛЕДНЕГО сообщения пользователя,
            которое было отправлено модели в ЭТОМ цикле (сейчас не используется, но принято для совместимости).
    """
    # Проверка доступности БД и необходимых утилит/типов перед началом работы
    if database is None or _convert_part_to_dict is None or _convert_value_for_json is None or Content is Any: # Проверяем, что Content не заглушка
         logger.critical(f"Database module or essential utility functions/types unavailable. Cannot save history for chat {chat_id}.")
         return

    if not final_history_obj_list:
        logger.debug(f"Save History: Received empty or None final_history_obj_list for chat {chat_id}. Nothing to save.")
        return

    # Рассчитываем количество новых элементов
    num_new_items = len(final_history_obj_list) - original_db_history_len

    if num_new_items <= 0:
        logger.debug(f"Save History: No new entries detected in final_history compared to initial history for chat {chat_id} (original_db_len={original_db_history_len}, final_len={len(final_history_obj_list)}). Nothing to save.")
        return

    # Берем только новые элементы в конце списка
    new_history_entries_content = final_history_obj_list[-num_new_items:]

    logger.info(f"Save History: Preparing to save {len(new_history_entries_content)} new entries (detected delta) for chat {chat_id}.")

    save_count = 0
    # Проверяем наличие функции добавления в историю перед циклом
    if not hasattr(database, 'add_message_to_history'):
         logger.critical("Database.add_message_to_history function unavailable. Cannot save history.")
         return

    # Проверяем, доступен ли RepeatedComposite для проверки типа Parts
    is_repeated_composite = lambda obj: isinstance(obj, RepeatedComposite) if RepeatedComposite is not Any else False


    for entry_content in new_history_entries_content:
        # Проверка, что это Content объект (на всякий случай)
        if not isinstance(entry_content, (glm.Content if glm else Content)):
             logger.warning(f"Save History: Skipping non-Content item in new entries list: {type(entry_content)}")
             continue

        role = getattr(entry_content, 'role', None)
        parts_obj_list = getattr(entry_content, 'parts', None) # Получаем список частей

        # Проверяем, что parts_obj_list является списком, кортежем или RepeatedComposite
        if not role or parts_obj_list is None or not isinstance(parts_obj_list, (list, tuple, RepeatedComposite)):
            logger.warning(f"Save History: Skipping invalid Content entry (missing role or parts): {entry_content}")
            continue

        # Пропускаем 'function' и 'user' роли - они сохраняются в других местах или не должны быть в истории чата для модели.
        if role == 'function':
            logger.debug(f"Save History: Skipping role 'function' entry, not saving to chat_history.")
            continue
        if role == 'user':
            logger.debug(f"Save History: Skipping role 'user' entry, should be saved on send.")
            continue


        # --- Обрабатываем только 'model' роль для сохранения ---
        if role == 'model':
            parts_list_of_dicts: List[Dict[str, Any]] = []
            # Переменная has_function_call больше не используется для логики фильтрации

            try:
                # Шаг 1: Конвертируем объекты Part в словари Python
                # Используем _convert_part_to_dict, которая должна обрабатывать все типы Part (text, function_call, function_response)
                # Она возвращает None для пустых или некорректных частей.
                # Проверяем, доступен ли _convert_part_to_dict
                if _convert_part_to_dict is not None:
                     for part_obj in parts_obj_list:
                         converted_part_dict = _convert_part_to_dict(part_obj)
                         if converted_part_dict is not None:
                             parts_list_of_dicts.append(converted_part_dict)
                         else:
                              logger.debug(f"Save History: Skipping part conversion result (None) for role '{role}'. Part object type: {type(part_obj)}")
                else:
                     logger.critical("Save History: _convert_part_to_dict unavailable. Cannot convert parts for saving.")
                     # Пропускаем сохранение этой записи
                     continue

                # <<< ИСПРАВЛЕНО: Удалена логика условной фильтрации >>>
                # Теперь parts_list_of_dicts содержит все части (текст, FC, FR), которые удалось сконвертировать.
                filtered_parts_for_db = parts_list_of_dicts

                logger.debug(f"Save History: Converted {len(parts_obj_list)} original parts to {len(filtered_parts_for_db)} serializable parts for role '{role}'.")


                # Шаг 2: Сериализуем список словарей в JSON строку
                parts_json_str = "[]" # Значение по умолчанию
                # Сериализуем, только если список не пустой (после конвертации)
                # Проверяем, доступен ли _convert_value_for_json перед использованием в default
                if filtered_parts_for_db:
                    try:
                        parts_json_str = json.dumps(filtered_parts_for_db, ensure_ascii=False, default=(_convert_value_for_json if _convert_value_for_json else str)) # Используем str как fallback для default
                        logger.debug(f"Save History (model): Serialized parts for DB (size: {len(parts_json_str)}): {parts_json_str[:200]}...")
                    except Exception as serialize_err:
                        logger.error(f"Save History (model): Failed to serialize parts list to JSON: {serialize_err}. Saving empty list.", exc_info=True)
                        parts_json_str = "[]" # Fallback

                # Если после сериализации получился пустой список JSON '[]', возможно, сообщение не содержало ничего полезного
                # Пропускаем сохранение, если JSON пустой, чтобы не засорять историю
                if parts_json_str == "[]":
                    logger.debug(f"Save History (model): Skipping save for chat {chat_id}, role '{role}' because serialized parts resulted in empty JSON '[]'.")
                    continue

                # Шаг 3: Сохраняем в БД
                try:
                    # Вызываем add_message_to_history с уже готовой JSON строкой
                    # Проверяем наличие функции перед вызовом
                    if hasattr(database, 'add_message_to_history'):
                         await database.add_message_to_history(
                             chat_id=chat_id,
                             user_id=current_user_id, # Сохраняем ID пользователя, который инициировал диалог
                             role=role,
                             parts=parts_json_str # Передаем СТРОКУ JSON
                         )
                         logger.info(f"Save History: Successfully saved 'model' entry (incl. text, FC, FR) to chat_history for chat {chat_id}. JSON size: {len(parts_json_str)}.")
                         save_count += 1
                    else:
                         logger.critical("Save History: Database.add_message_to_history function unavailable during save loop.")


                # Обработка ошибок базы данных (остается прежней)
                except TypeError as te:
                     logger.critical(f"Save History: TYPE ERROR calling add_message_to_history for 'model' entry (chat {chat_id}): {te}. Check arguments! Passed parts type: {type(parts_json_str)}, value: {parts_json_str[:100]}...", exc_info=True)
                except AttributeError as ae:
                     logger.critical(f"Save History: ATTRIBUTE ERROR calling DB function for 'model' entry (chat {chat_id}): {ae}. CHECK FUNCTION NAME! Expected 'add_message_to_history'. Parts JSON: {parts_json_str}", exc_info=True)
                except Exception as db_save_err:
                    logger.error(f"Save History: DB Error calling add_message_to_history for 'model' entry (chat {chat_id}): {db_save_err}", exc_info=True)

            except Exception as e: # Ловим любые ошибки на этапе конвертации/сериализации для этой записи
                logger.error(f"Save History: Error processing parts for role '{role}': {e}. Skipping entry.", exc_info=True)
                continue
        else:
            # Если роль не 'user', 'function' и не 'model' (неожиданно)
            logger.warning(f"Save History: Encountered unexpected role '{role}' during save loop. Skipping.")

    logger.info(f"Save History: Finished saving new entries for chat {chat_id}. Saved {save_count} new messages.")

# --- НЕ ОЧИЩАЕМ FC/FR из ИСТОРИИ после сохранения ---
# Это больше не нужно, т.к. мы сохраняем их в БД, и prepare_history
# реконструирует их обратно в Content объекты для API.

========== Файл: core_agent\response_parsers.py ==========

# core_agent/response_parsers.py
import json
import logging
import re
from typing import List, Dict, Tuple, Optional, Any, Union

logger = logging.getLogger(__name__)

LiteParseResult = Union[List[Dict[str, Any]], Dict[str, Any], str]

def parse_lite_llm_response(text_response: Optional[str]) -> LiteParseResult:
    """
    Парсит, очищает и валидирует JSON-ответ от Lite LLM.
    Возвращает список действий, "NO_ACTION_NEEDED" или словарь ошибки.
    """
    if not text_response:
        logger.info("Lite LLM returned empty text response. Interpreting as NO_ACTION_NEEDED.")
        return "NO_ACTION_NEEDED"

    cleaned_text = text_response.strip()
    original_cleaned_text = cleaned_text
    is_cleaned = False
    logger.debug(f"Parsing Lite LLM response. Initial text: '{text_response[:100]}...'")

    if cleaned_text.startswith("```") and cleaned_text.endswith("```"):
        cleaned_text = cleaned_text[3:-3].strip()
        is_cleaned = True
        first_line_end = cleaned_text.find('\n')
        if first_line_end != -1:
            first_line = cleaned_text[:first_line_end].strip()
            if first_line.lower() == "json":
                 cleaned_text = cleaned_text[first_line_end:].strip()
        elif cleaned_text.lower().startswith("json"):
             cleaned_text = cleaned_text[4:].strip()

    elif not (cleaned_text.startswith("{") and cleaned_text.endswith("}")):
        logger.warning(f"Lite LLM response does not look like JSON or Markdown block. Raw: '{text_response[:100]}...'")

    if is_cleaned:
        logger.debug(f"Markdown cleaned. Text for parsing: '{cleaned_text[:100]}...'")

    try:
        parsed_json = json.loads(cleaned_text)

        if isinstance(parsed_json, dict) and \
           "actions_to_perform" in parsed_json and \
           isinstance(parsed_json.get("actions_to_perform"), list):

            actions = parsed_json["actions_to_perform"]

            if not actions:
                logger.info("Lite LLM response parsed: No actions needed.")
                return "NO_ACTION_NEEDED"
            else:
                logger.info(f"Lite LLM response parsed: Actions requested: {actions}")
                valid_actions = []
                for action in actions:
                    if isinstance(action, dict) and \
                       "function_name" in action and \
                       "arguments" in action and \
                       isinstance(action.get("arguments"), dict):

                        args = action["arguments"]
                        try:
                            # Конвертация типов
                            if 'user_id' in args and args['user_id'] is not None and not isinstance(args['user_id'], int):
                                args['user_id'] = int(float(args['user_id']))
                            if 'chat_id' in args and args['chat_id'] is not None and not isinstance(args['chat_id'], int):
                                args['chat_id'] = int(float(args['chat_id']))
                            # Добавьте другие конвертации
                        except (ValueError, TypeError, KeyError) as conv_err:
                            logger.warning(f"Argument conversion/access failed for action {action.get('function_name')}: {conv_err}. Skipping action. Args: {args}")
                            continue

                        valid_actions.append({"function_name": action["function_name"], "arguments": args})
                    else:
                         logger.warning(f"Invalid action structure in JSON: {action}")

                if not valid_actions and actions:
                     error_message = "Actions list contains only invalid action structures."
                     logger.error(f"Lite LLM Error: {error_message}. Original actions: {actions}")
                     return {"error": "INVALID_ACTION_STRUCTURE", "message": error_message, "details": actions}

                return valid_actions
        else:
            error_message = "Invalid JSON structure received from Lite LLM (missing 'actions_to_perform' list)."
            logger.error(f"{error_message} Parsed from: {cleaned_text}")
            return {"error": "INVALID_JSON_STRUCTURE", "message": error_message, "details": cleaned_text}

    except json.JSONDecodeError:
        error_message = "Failed to decode JSON response from Lite LLM (Model did not return valid JSON)."
        logger.error(error_message)
        logger.error(f"Original Response text: '{text_response[:100]}...'")
        logger.error(f"Cleaned text for parsing: '{original_cleaned_text[:100]}...'")
        return {"error": "JSON_DECODE_ERROR", "message": error_message, "original_details": text_response, "cleaned_details": original_cleaned_text}
    except Exception as e:
         error_message = f"Unexpected error parsing Lite LLM response: {e}"
         logger.error(error_message, exc_info=True)
         return {"error": "UNEXPECTED_PARSING_ERROR", "message": error_message, "details": cleaned_text}

========== Файл: core_agent\result_parser.py ==========

# core_agent/result_parser.py
import logging
from typing import Optional, List, Any

try:
    from google.ai import generativelanguage as glm
    Content = glm.Content
    Part = glm.Part
except ImportError:
    Content, Part = Any, Any
    logging.getLogger(__name__).warning("Could not import Google types (Content, Part) in result_parser.")

logger = logging.getLogger(__name__)

def extract_text(final_history_obj_list: List[Content]) -> Optional[str]:
    """
    Извлекает текстовое содержимое из последнего сообщения модели в истории.

    Args:
        final_history_obj_list: Список объектов Content, представляющих историю диалога.

    Returns:
        Объединенный текст из последнего сообщения модели или None, если текста нет
        или последний элемент не является сообщением модели.
    """
    logger.debug(f"Attempting to extract text from final history list (length: {len(final_history_obj_list)}).")

    if not final_history_obj_list:
        logger.warning("Cannot extract text: final_history_obj_list is empty.")
        return None

    # Безопасно получаем последний элемент
    try:
        # Используем try-except на случай, если список не поддерживает индексацию,
        # хотя ожидается список Content объектов.
        last_entry = final_history_obj_list[-1]
    except IndexError:
        logger.warning("Cannot extract text: final_history_obj_list seems empty despite initial check or doesn't support indexing.")
        return None
    except TypeError:
         logger.warning(f"Cannot extract text: final_history_obj_list is not a list or indexable type ({type(final_history_obj_list)}).")
         return None

    # Проверяем роль
    if not hasattr(last_entry, 'role') or last_entry.role != 'model':
        # Если последний элемент - не от модели, текста там быть не должно по нашей логике
        logger.debug(f"Last entry in history is not from model (role: {getattr(last_entry, 'role', 'N/A')}). No text to extract.")
        return None

    # Проверяем наличие parts и итерируемость
    parts_iterable = getattr(last_entry, 'parts', None)
    if parts_iterable is None or not hasattr(parts_iterable, '__iter__'):
        logger.warning(f"Final model response (entry type: {type(last_entry)}) has no iterable 'parts' attribute.")
        # Пытаемся ли мы извлечь текст из самого объекта, если он строка? (Маловероятно для Content)
        if isinstance(last_entry, str):
             logger.warning("The last entry was unexpectedly a string. Returning it as text.")
             return last_entry # Возвращаем строку, если это возможно
        return None # Не можем обработать parts

    # Теперь безопасно итерируем по parts
    extracted_texts = []
    for part in parts_iterable:
        if hasattr(part, 'text') and part.text:
            logger.debug(f"Extracted text part: '{part.text[:50]}...'")
            extracted_texts.append(part.text)
        elif hasattr(part, 'function_call'):
            logger.debug("Ignoring function_call part.")
        elif hasattr(part, 'function_response'):
            logger.debug("Ignoring function_response part.")
        else:
            # Неизвестный тип part
            logger.warning(f"Encountered unknown part type in final model response: {type(part)}")

    if not extracted_texts:
        logger.info("No text found in the final model response parts.")
        return None

    full_text = "".join(extracted_texts)
    logger.info(f"Successfully extracted final text (len={len(full_text)}).")
    return full_text

========== Файл: core_agent\__init__.py ==========



========== Файл: database\connection.py ==========

# database/connection.py
import aiosqlite
import logging
import os
from typing import Optional

# Импортируем настройки из корневого config.py
# Предполагается, что config.py находится на два уровня выше
try:
    from config import settings
except ImportError:
    # Заглушка на случай, если запуск идет из другого места или config.py нет
    class MockSettings:
        db_path: str = "database/bot_db.sqlite" # Путь по умолчанию
    settings = MockSettings()
    logging.warning("Could not import settings from config.py, using default DB path.")


logger = logging.getLogger(__name__)

_connection: Optional[aiosqlite.Connection] = None
BUSY_TIMEOUT_MS = 5000 # 5 секунд

async def get_connection() -> aiosqlite.Connection:
    """
    Получает или создает асинхронное соединение с БД SQLite.
    Использует путь из настроек (config.settings.db_path).
    """
    global _connection
    if _connection is None:
        db_file_path = os.path.abspath(settings.db_path)
        db_dir = os.path.dirname(db_file_path)
        logger.info(f"Database path configured to: {db_file_path}")

        try:
            # Убедимся, что директория существует
            if db_dir:
                os.makedirs(db_dir, exist_ok=True)
                logger.info(f"Ensured database directory exists: {db_dir}")

            _connection = await aiosqlite.connect(
                db_file_path,
                timeout=BUSY_TIMEOUT_MS / 1000.0 # timeout в секундах
            )
            # Включаем поддержку внешних ключей
            await _connection.execute("PRAGMA foreign_keys = ON;")
            # Устанавливаем Row Factory для доступа к колонкам по имени
            _connection.row_factory = aiosqlite.Row
            # Устанавливаем таймаут ожидания при блокировке БД
            await _connection.execute(f"PRAGMA busy_timeout = {BUSY_TIMEOUT_MS};")
            # Включаем WAL режим
            try:
                await _connection.execute("PRAGMA journal_mode=WAL;")
                logger.info("SQLite WAL mode enabled.")
            except Exception as wal_err:
                # Не критично, если не удалось, но логируем
                logger.warning(f"Could not enable WAL journal mode: {wal_err}", exc_info=True)
            await _connection.commit() # Важно закоммитить PRAGMA
            logger.info(f"Database connection established to {db_file_path} with busy_timeout={BUSY_TIMEOUT_MS}ms. Connection object ID: {id(_connection)}")
        except OSError as e:
            logger.critical(f"Failed to create/access database directory {db_dir}: {e}", exc_info=True)
            raise ConnectionError(f"Failed to create/access database directory: {e}") from e
        except aiosqlite.Error as e:
            logger.critical(f"Failed to connect to database {db_file_path}: {e}", exc_info=True)
            raise ConnectionError(f"Failed to connect to database: {e}") from e
        except Exception as e:
            logger.critical(f"Unexpected error connecting to database {db_file_path}: {e}", exc_info=True)
            raise ConnectionError(f"Unexpected error connecting to database: {e}") from e
    else:
        # Логируем ID существующего соединения
        logger.debug(f"Reusing existing DB connection. Connection object ID: {id(_connection)}")
    return _connection

async def close_db():
    """Закрывает активное соединение с БД."""
    global _connection
    if _connection:
        try:
            # <<< Добавляем явный checkpoint перед закрытием >>>
            try:
                logger.debug("Attempting WAL checkpoint before closing connection...")
                # TRUNCATE пытается уменьшить WAL файл, но может быть медленнее
                # Можно попробовать PASSIVE или FULL, если TRUNCATE вызывает проблемы
                await _connection.execute("PRAGMA wal_checkpoint(TRUNCATE);")
                logger.info("WAL checkpoint successful before closing.")
            except Exception as cp_err:
                logger.warning(f"WAL checkpoint failed before closing: {cp_err}", exc_info=True)
            # <<< Конец checkpoint >>>

            await _connection.close()
            _connection = None
            logger.info("Database connection closed.")
        except aiosqlite.Error as e:
             logger.error(f"Error closing database connection: {e}", exc_info=True)

async def init_db():
    """
    Инициализирует структуру базы данных, создавая все необходимые таблицы и индексы,
    если они еще не существуют.
    """
    logger.info("Initializing database schema...")
    conn = await get_connection()
    try:
        # 1. Таблица профилей пользователей
        logger.debug("Executing CREATE TABLE user_profiles...")
        await conn.execute('''
            CREATE TABLE IF NOT EXISTS user_profiles (
                user_id INTEGER PRIMARY KEY,
                username TEXT,
                first_name TEXT,
                last_name TEXT,
                last_seen DATETIME DEFAULT CURRENT_TIMESTAMP,
                avatar_file_id TEXT,
                avatar_description TEXT
            );
        ''')
        logger.debug("Checked/Created table: user_profiles")

        # 2. Таблица заметок пользователей
        logger.debug("Executing CREATE TABLE user_notes...")
        await conn.execute('''
            CREATE TABLE IF NOT EXISTS user_notes (
                note_id INTEGER PRIMARY KEY AUTOINCREMENT,
                user_id INTEGER NOT NULL,
                category TEXT NOT NULL COLLATE NOCASE, -- Категория без учета регистра
                value TEXT NOT NULL,
                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (user_id) REFERENCES user_profiles(user_id) ON DELETE CASCADE,
                UNIQUE (user_id, category) -- Уникальная пара пользователь-категория
            );
        ''')
        logger.debug("Executing CREATE INDEX idx_user_notes_user_id...")
        await conn.execute('CREATE INDEX IF NOT EXISTS idx_user_notes_user_id ON user_notes (user_id);')
        logger.debug("Checked/Created table and index: user_notes")

        # 3. Таблица истории чатов
        logger.debug("Executing CREATE TABLE chat_history...")
        await conn.execute('''
            CREATE TABLE IF NOT EXISTS chat_history (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                chat_id INTEGER NOT NULL,
                role TEXT NOT NULL CHECK(role IN ('user', 'model', 'system', 'function')),
                user_id INTEGER, -- NULL для 'model', 'system' и 'function'
                parts_json TEXT NOT NULL,
                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (user_id) REFERENCES user_profiles(user_id) ON DELETE SET NULL -- При удалении профиля ставим NULL
            );
        ''')
        logger.debug("Executing CREATE INDEX idx_chat_history_chat_id_ts...")
        await conn.execute('CREATE INDEX IF NOT EXISTS idx_chat_history_chat_id_ts ON chat_history (chat_id, timestamp);')
        logger.debug("Checked/Created table and index: chat_history")

        # 4. Таблица настроек чатов
        logger.debug("Executing CREATE TABLE chat_settings...")
        await conn.execute('''
            CREATE TABLE IF NOT EXISTS chat_settings (
                chat_id INTEGER PRIMARY KEY,
                custom_prompt TEXT,
                ai_mode TEXT DEFAULT 'pro', -- 'default' (g4f) или 'pro' (gemini)
                gemini_model TEXT,          -- Имя конкретной модели Gemini
                last_update_ts DATETIME DEFAULT CURRENT_TIMESTAMP
            );
        ''')
        logger.debug("Checked/Created table: chat_settings")

        # 5. Таблица подписок на новости
        logger.debug("Executing CREATE TABLE news_subscriptions...")
        await conn.execute('''
            CREATE TABLE IF NOT EXISTS news_subscriptions (
                subscription_id INTEGER PRIMARY KEY AUTOINCREMENT,
                channel_id INTEGER NOT NULL UNIQUE, -- ID канала Telegram
                topics_json TEXT NOT NULL,          -- Список тем в JSON
                schedule_json TEXT NOT NULL,        -- Список времени в JSON
                last_post_ts DATETIME             -- Время последней успешной отправки
            );
        ''')
        logger.debug("Executing CREATE INDEX idx_news_subs_channel...")
        await conn.execute('CREATE INDEX IF NOT EXISTS idx_news_subs_channel ON news_subscriptions (channel_id);')
        logger.debug("Checked/Created table and index: news_subscriptions")

        # 6. Таблица отправленных GUID новостей
        logger.debug("Executing CREATE TABLE sent_news_guids...")
        await conn.execute('''
            CREATE TABLE IF NOT EXISTS sent_news_guids (
                guid TEXT PRIMARY KEY,
                sent_ts DATETIME DEFAULT CURRENT_TIMESTAMP
            );
        ''')
        logger.debug("Executing CREATE INDEX idx_sent_guids_ts...")
        await conn.execute('CREATE INDEX IF NOT EXISTS idx_sent_guids_ts ON sent_news_guids (sent_ts);')
        logger.debug("Checked/Created table and index: sent_news_guids")

        # 7. Таблица статистики сообщений
        logger.debug("Executing CREATE TABLE message_stats...")
        await conn.execute('''
            CREATE TABLE IF NOT EXISTS message_stats (
                stat_id INTEGER PRIMARY KEY AUTOINCREMENT,
                chat_id INTEGER NOT NULL,
                user_id INTEGER NOT NULL,
                message_count INTEGER DEFAULT 0,
                last_message_ts DATETIME DEFAULT CURRENT_TIMESTAMP
                -- Убираем FOREIGN KEY для теста
                -- FOREIGN KEY (user_id) REFERENCES user_profiles(user_id) ON DELETE CASCADE,
                -- UNIQUE (chat_id, user_id) -- Уникальная пара чат-пользователь
            );
        ''')
        logger.debug("Executing CREATE INDEX idx_msg_stats_chat_user...")
        await conn.execute('CREATE INDEX IF NOT EXISTS idx_msg_stats_chat_user ON message_stats (chat_id, user_id);')
        logger.debug("Executing CREATE INDEX idx_msg_stats_chat_count...")
        await conn.execute('CREATE INDEX IF NOT EXISTS idx_msg_stats_chat_count ON message_stats (chat_id, message_count DESC);')
        logger.debug("Checked/Created table and indexes: message_stats")

        # 8. Таблица предупреждений пользователей
        logger.debug("Executing CREATE TABLE user_warnings...")
        await conn.execute('''
            CREATE TABLE IF NOT EXISTS user_warnings (
                warn_id INTEGER PRIMARY KEY AUTOINCREMENT,
                chat_id INTEGER NOT NULL,
                user_id INTEGER NOT NULL,
                warn_count INTEGER DEFAULT 0,
                last_warn_ts DATETIME DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (user_id) REFERENCES user_profiles(user_id) ON DELETE CASCADE,
                UNIQUE (chat_id, user_id) -- Уникальная пара чат-пользователь
            );
        ''')
        logger.debug("Executing CREATE INDEX idx_user_warns_chat_user...")
        await conn.execute('CREATE INDEX IF NOT EXISTS idx_user_warns_chat_user ON user_warnings (chat_id, user_id);')
        logger.debug("Checked/Created table and index: user_warnings")

        # 9. Таблица логов выполнения инструментов (Tool Executions)
        logger.debug("Executing CREATE TABLE tool_executions...")
        await conn.execute('''
            CREATE TABLE IF NOT EXISTS tool_executions (
                execution_id INTEGER PRIMARY KEY AUTOINCREMENT,
                chat_id INTEGER NOT NULL,
                user_id INTEGER, -- Пользователь, инициировавший взаимодействие (может быть NULL)
                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                tool_name TEXT NOT NULL,
                tool_args_json TEXT, -- Аргументы вызова функции в JSON
                status TEXT NOT NULL CHECK(status IN ('success', 'error', 'not_found', 'warning', 'timeout')),
                return_code INTEGER, -- Код возврата для команд/скриптов
                result_message TEXT, -- Сообщение из словаря результата
                stdout TEXT, -- Стандартный вывод (ограничить длину при записи!)
                stderr TEXT, -- Стандартный вывод ошибок (ограничить длину при записи!)
                full_result_json TEXT, 
                trigger_message_id INTEGER -- Опционально: ID сообщения пользователя
            );
        ''')
        logger.debug("Executing CREATE INDEX idx_tool_exec_chat_time...")
        await conn.execute('CREATE INDEX IF NOT EXISTS idx_tool_exec_chat_time ON tool_executions (chat_id, timestamp DESC);')
        logger.debug("Executing CREATE INDEX idx_tool_exec_tool_name...")
        await conn.execute('CREATE INDEX IF NOT EXISTS idx_tool_exec_tool_name ON tool_executions (tool_name);')
        logger.debug("Checked/Created table and indexes: tool_executions")

        logger.debug("Committing schema changes...") # Лог перед коммитом
        await conn.commit()
        logger.info("Database schema initialization complete.")



        # 10. Таблица обратной связи от разработчика/модели
        logger.debug("Executing CREATE TABLE developer_feedback...")
        await conn.execute('''
            CREATE TABLE IF NOT EXISTS developer_feedback (
                feedback_id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                chat_id INTEGER,      -- ID чата, откуда пришел запрос (если применимо)
                user_id INTEGER,      -- ID пользователя, инициировавшего запрос (если применимо)
                model_name TEXT,      -- Модель, сгенерировавшая фидбек (опционально)
                degree_of_importance TEXT NOT NULL CHECK(degree_of_importance IN ('high', 'medium', 'low', 'critical', 'suggestion')), -- Важность
                reason TEXT NOT NULL, -- Краткая причина/категория
                problem_description TEXT NOT NULL, -- Детальное описание
                status TEXT DEFAULT 'new' CHECK(status IN ('new', 'acknowledged', 'in_progress', 'resolved', 'wont_fix')) -- Статус обработки (опционально)
            );
        ''')
        logger.debug("Executing CREATE INDEX idx_dev_feedback_ts...")
        await conn.execute('CREATE INDEX IF NOT EXISTS idx_dev_feedback_ts ON developer_feedback (timestamp DESC);')
        logger.debug("Executing CREATE INDEX idx_dev_feedback_status...")
        await conn.execute('CREATE INDEX IF NOT EXISTS idx_dev_feedback_status ON developer_feedback (status);')
        logger.debug("Checked/Created table and indexes: developer_feedback")

    except aiosqlite.Error as e:
        logger.error(f"Error during database initialization: {e}", exc_info=True)
        try:
            await conn.rollback() # Откатываем изменения при ошибке
        except Exception as rb_e:
            logger.error(f"Error during rollback after DB init failure: {rb_e}")
        raise # Перевыбрасываем исключение, т.к. инициализация критична
    except Exception as e:
         logger.error(f"Unexpected error during database initialization: {e}", exc_info=True)
         raise

========== Файл: database\models.py ==========



========== Файл: database\__init__.py ==========

# database/__init__.py

# Импортируем ключевые функции из подмодулей
from .connection import get_connection, close_db, init_db
# Импортируем всё из crud_ops для доступа типа database.add_message_to_history(...)
from .crud_ops import *

__all__ = [
    "get_connection",
    "close_db",
    "init_db",
    # Добавляем сюда все импортированные из crud_ops.__all__
    # history
    "add_message_to_history", "get_chat_history", "clear_chat_history",
    # profiles
    "upsert_user_profile", "get_user_profile", "update_avatar_description", "find_user_id_by_profile",
    # notes
    "upsert_user_note", "get_user_notes", "delete_user_note", "delete_user_note_nested", "get_user_data_combined",
    # settings
    "upsert_chat_settings", "get_chat_settings", "delete_chat_settings", "AI_MODE_PRO", "AI_MODE_DEFAULT",
    # news
    "add_or_update_subscription", "get_subscription", "get_all_subscriptions", "update_subscription_last_post",
    "delete_subscription", "add_sent_guid", "is_guid_sent", "load_recent_sent_guids", "cleanup_old_guids",
    # stats
    "increment_message_count", "get_chat_stats_top_users", "get_user_warn_count", "add_user_warning",
    "remove_user_warning", "get_chat_warnings", "reset_user_warnings",
    # execution_logs
    "add_tool_execution_log", "get_recent_tool_executions", "add_developer_feedback"
]

========== Файл: database\crud_ops\execution_logs.py ==========

# database/crud_ops/execution_logs.py

import logging
import json
from typing import Optional, Dict, List, Any

import aiosqlite

# Локальный импорт для получения соединения
try:
    from ..connection import get_connection
except ImportError:
    # Заглушка для тестов или изолированного запуска
    async def get_connection(): raise ImportError("Could not import get_connection from parent package")

# Импорт настроек для лимитов
try:
    from config import settings
except ImportError:
    class MockSettings:
        # Добавляем заглушку для max_command_output_len, если settings не импортируется
        max_command_output_len: int = 4000
    settings = MockSettings()
    logging.warning("Could not import settings from config.py, using default command output len for logs.")

# Определяем максимальную длину для сохранения в лог
# Используем существующую настройку как разумное ограничение
MAX_LOG_LEN = settings.max_command_output_len if hasattr(settings, 'max_command_output_len') else 4000 # Fallback

logger = logging.getLogger(__name__)

async def add_tool_execution_log(
    chat_id: int,
    user_id: Optional[int],
    tool_name: str,
    tool_args: Optional[Dict] = None,
    status: str = 'error',
    return_code: Optional[int] = None,
    result_message: Optional[str] = None,
    stdout: Optional[str] = None,
    stderr: Optional[str] = None,
    full_result: Optional[Dict] = None,
    trigger_message_id: Optional[int] = None
) -> Optional[int]:
    """
    Добавляет запись о выполнении инструмента в таблицу tool_executions.

    Args:
        chat_id (int): ID чата.
        user_id (Optional[int]): ID пользователя, инициировавшего вызов.
        tool_name (str): Название выполненного инструмента.
        tool_args (Optional[Dict]): Аргументы вызова инструмента (сериализуются в JSON).
        status (str): Статус выполнения ('success', 'error', 'not_found', 'warning', 'timeout').
        return_code (Optional[int]): Код возврата (для команд/скриптов).
        result_message (Optional[str]): Сообщение из результата выполнения.
        stdout (Optional[str]): Стандартный вывод (будет обрезан).
        stderr (Optional[str]): Стандартный вывод ошибок (будет обрезан).
        trigger_message_id (Optional[int]): ID сообщения, вызвавшего инструмент.

    Returns:
        Optional[int]: ID созданной записи лога или None при ошибке.
    """
    # Инициализация переменных
    conn: Optional[aiosqlite.Connection] = None
    cursor: Optional[aiosqlite.Cursor] = None
    inserted_id: Optional[int] = None

    try:
        # Сериализация и обрезка данных
        tool_args_json = json.dumps(tool_args, ensure_ascii=False) if tool_args else None
        truncated_stdout = (stdout[:MAX_LOG_LEN] + '...[truncated]') if stdout and len(stdout) > MAX_LOG_LEN else stdout
        truncated_stderr = (stderr[:MAX_LOG_LEN] + '...[truncated]') if stderr and len(stderr) > MAX_LOG_LEN else stderr

        # <<< НОВОЕ: Сериализация полного результата >>>
        full_result_json_str = None
        if full_result is not None:
            try:
                full_result_json_str = json.dumps(full_result, ensure_ascii=False, default=str) # Добавим default=str на всякий случай
            except Exception as json_err:
                logger.error(f"Failed to serialize full_result for tool log '{tool_name}': {json_err}. Storing error message.", exc_info=True)
                full_result_json_str = json.dumps({"error": f"Serialization failed: {json_err}"})

        # Добавляем проверку статуса на допустимые значения
        valid_statuses = {'success', 'error', 'not_found', 'warning', 'timeout'}
        if status not in valid_statuses:
            logger.warning(f"Invalid status '{status}' provided for tool log. Using 'error'.")
            status = 'error'

        # Получение соединения и выполнение запроса
        conn = await get_connection()
        cursor = await conn.execute(
            """
            INSERT INTO tool_executions (
                chat_id, user_id, tool_name, tool_args_json, status,
                return_code, result_message, stdout, stderr, full_result_json,
                trigger_message_id
            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """,
            (
                chat_id, user_id, tool_name, tool_args_json, status,
                return_code, result_message, truncated_stdout, truncated_stderr,
                full_result_json_str, # <-- Теперь это значение соответствует 10-му полю
                trigger_message_id  # <-- Теперь это значение соответствует 11-му полю
            )
        )
        inserted_id = cursor.lastrowid # Получаем ID СРАЗУ после execute
        await conn.commit() # Коммитим
        await cursor.close() # ЗАКРЫВАЕМ КУРСОР ЯВНО
        cursor = None # Сбрасываем ссылку

        if inserted_id is not None:
            # Используем полученный ID в логе
            logger.info(f"Added tool execution log ID: {inserted_id} for tool '{tool_name}' in chat {chat_id}")
        else:
             # Эта ситуация маловероятна с lastrowid после INSERT, но логируем на всякий случай
             logger.warning(f"Could not retrieve lastrowid after inserting tool log for tool '{tool_name}' in chat {chat_id}. INSERT seemed successful.")

        return inserted_id # Возвращаем полученный ID

    except (aiosqlite.Error, json.JSONDecodeError, Exception) as e:
        # Используем f-string для основного сообщения об ошибке
        logger.error(f"Failed to log tool execution for chat={chat_id}, tool={tool_name}: {e}", exc_info=True)
        # Попытка отката, если соединение было установлено
        if conn:
            try: await conn.rollback()
            except Exception as rb_err:
                 logger.error(f"Rollback failed after error logging tool execution: {rb_err}")
        # Попытка закрыть курсор, если он остался открытым
        if cursor:
            try: await cursor.close()
            except Exception as c_err:
                 logger.error(f"Failed to close cursor after error logging tool execution: {c_err}")
        return None # Возвращаем None при любой ошибке

async def get_recent_tool_executions(chat_id: int, limit: int = 3) -> List[Dict[str, Any]]:
    """
    Получает последние N записей логов выполнения инструментов для указанного чата.

    Args:
        chat_id (int): ID чата.
        limit (int): Максимальное количество записей для возврата.

    Returns:
        List[Dict[str, Any]]: Список словарей, представляющих записи логов.
                              Каждый словарь содержит все поля таблицы tool_executions.
                              Возвращает пустой список при ошибке или отсутствии логов.
    """
    conn = await get_connection()
    try:
        async with conn.cursor() as cursor:
            await cursor.execute(
                '''
                SELECT execution_id, chat_id, user_id, timestamp, tool_name, tool_args_json,
                       status, return_code, result_message, stdout, stderr, full_result_json,
                       trigger_message_id
                FROM tool_executions
                WHERE chat_id = ?
                ORDER BY timestamp DESC
                LIMIT ?
                ''',
                (chat_id, limit)
            )
            rows = await cursor.fetchall()
            # Преобразуем строки в словари
            results = [dict(row) for row in rows]
            logger.debug(f"Retrieved {len(results)} recent tool execution logs for chat {chat_id}.")
            return results
    except aiosqlite.Error as e:
        logger.error(f"Error fetching recent tool execution logs for chat {chat_id}: {e}", exc_info=True)
        return []
    except Exception as e:
        logger.error(f"Unexpected error fetching recent tool execution logs for chat {chat_id}: {e}", exc_info=True)
        return [] 

========== Файл: database\crud_ops\feedback.py ==========

# database/crud_ops/feedback.py

import logging
import aiosqlite
from typing import Optional

try:
    from ..connection import get_connection
except ImportError:
    async def get_connection(): raise ImportError("Connection module not loaded")

logger = logging.getLogger(__name__)

async def add_developer_feedback(
    degree_of_importance: str,
    reason: str,
    problem_description: str,
    chat_id: Optional[int] = None,
    user_id: Optional[int] = None,
    model_name: Optional[str] = None
) -> Optional[int]:
    """
    Добавляет запись обратной связи в таблицу developer_feedback.

    Args:
        degree_of_importance (str): Важность ('high', 'medium', 'low', etc.).
        reason (str): Краткая причина/категория.
        problem_description (str): Детальное описание проблемы.
        chat_id (Optional[int]): ID чата (если есть).
        user_id (Optional[int]): ID пользователя (если есть).
        model_name (Optional[str]): Имя модели (если известно).

    Returns:
        Optional[int]: ID созданной записи или None при ошибке.
    """
    conn: aiosqlite.Connection
    inserted_id: Optional[int] = None

    # Валидация важности (опционально, можно положиться на CHECK в БД)
    valid_degrees = {'high', 'medium', 'low', 'critical', 'suggestion'}
    if degree_of_importance.lower() not in valid_degrees:
        logger.warning(f"Invalid degree_of_importance '{degree_of_importance}'. Using 'medium'.")
        degree_of_importance = 'medium'

    try:
        conn = await get_connection()
        cursor = await conn.execute(
            """
            INSERT INTO developer_feedback (
                chat_id, user_id, model_name, degree_of_importance, reason, problem_description
            ) VALUES (?, ?, ?, ?, ?, ?)
            """,
            (
                chat_id, user_id, model_name, degree_of_importance.lower(),
                reason, problem_description
            )
        )
        inserted_id = cursor.lastrowid
        await conn.commit()
        await cursor.close()

        if inserted_id is not None:
            logger.info(f"Added developer feedback log ID: {inserted_id}. Importance: {degree_of_importance}, Reason: {reason[:50]}...")
        else:
            logger.warning("Could not retrieve lastrowid after inserting developer feedback.")

        return inserted_id

    except (aiosqlite.Error, ImportError) as e:
        logger.error(f"Failed to add developer feedback: {e}", exc_info=True)
        if 'conn' in locals() and conn and not isinstance(e, ImportError):
            try: await conn.rollback()
            except Exception as rb_err: logger.error(f"Rollback failed after feedback insert error: {rb_err}")
        return None
    except Exception as e:
         logger.error(f"Unexpected error adding developer feedback: {e}", exc_info=True)
         return None

========== Файл: database\crud_ops\history.py ==========

# database/crud_ops/history.py
import aiosqlite
import json
import logging
from typing import List, Dict, Any, Optional

# Используем относительный импорт для связи с connection.py и converters.py
try:
    from ..connection import get_connection
    # Используем абсолютный импорт от корня проекта для utils
    from utils.converters import _serialize_parts, _deserialize_parts
except ImportError as e:
    # Логгируем более конкретную ошибку
    logging.getLogger(__name__).critical(f"Failed to import dependencies in history.py: {e}", exc_info=True)
    # Заглушки
    async def get_connection(): raise ImportError("Connection module not loaded")
    def _serialize_parts(parts: List[Any]) -> str: return "[]"
    def _deserialize_parts(parts_json: str) -> List[Dict[str, Any]]: return []

logger = logging.getLogger(__name__)

# --- Основные CRUD операции ---

async def add_message_to_history(
    chat_id: int,
    role: str,
    parts: str, # <<< ИЗМЕНЕНО: Теперь принимаем JSON строку
    user_id: Optional[int] = None
):
    """
    Добавляет сообщение в историю чата.
    `parts` должен быть валидной JSON строкой.
    """
    if role not in ('user', 'model', 'system', 'function'):
        logger.error(f"Invalid role '{role}' provided for chat history (chat_id: {chat_id}).")
        return

    # Проверяем, что parts - это строка
    if not isinstance(parts, str):
         logger.error(f"add_message_to_history expected 'parts' argument to be a JSON string, got {type(parts)}. History not saved.")
         return

    parts_json = parts # Переименовываем для ясности

    # --- УБИРАЕМ ВЫЗОВ СЕРИАЛИЗАЦИИ ---
    # parts_json = _serialize_parts(parts) # <<< УДАЛЕН ВЫЗОВ
    # -------------------------------

    # <<< Переносим проверку на пустой JSON сюда (для роли model) >>>
    if parts_json == "[]" and role != 'model':
         # Оставляем ошибку для не-model ролей, если исходные parts НЕ были пустыми
         logger.error(f"Serialization resulted in empty JSON '[]' for non-empty parts chat={chat_id}, role={role}. History not saved.")
         return
    elif parts_json == "[]" and role == 'model':
         logger.info(f"Saving history entry for model with empty parts (parts_json='[]') for chat={chat_id}.")
    # elif parts_json != "[]":
         # logger.debug(f"Serialized parts to JSON (size: {len(parts_json)}) for chat={chat_id}, role={role}")

    conn: aiosqlite.Connection
    try:
        conn = await get_connection()
        await conn.execute(
            """
            INSERT INTO chat_history (chat_id, role, user_id, parts_json)
            VALUES (?, ?, ?, ?)
            """,
            (chat_id, role, user_id, parts_json) # <<< Передаем parts_json
        )
        logger.debug(f"Executed INSERT for chat={chat_id}, role={role}. Preparing to commit...") # Лог перед commit
        await conn.commit()
        logger.info(f"Successfully committed history entry: chat={chat_id}, role={role}, user={user_id}, json_size={len(parts_json)}") # Лог после commit

        # <<< ПРОВЕРКА СРАЗУ ПОСЛЕ КОММИТА >>>
        try:
            # Ищем последнюю запись для этого чата и роли (немного неточно, но для теста сойдет)
            sql = "SELECT id, timestamp FROM chat_history WHERE chat_id = ? AND role = ? ORDER BY id DESC LIMIT 1"
            params = (chat_id, role)
            async with conn.execute(sql, params) as cursor:
                row = await cursor.fetchone()
                if row:
                    logger.info(f"VERIFY AFTER COMMIT: Found history for {chat_id}/{role}, id: {row['id']}, ts: {row['timestamp']}")
                else:
                    logger.error(f"VERIFY AFTER COMMIT: FAILED TO FIND history for {chat_id}/{role} immediately after commit!")
        except Exception as verify_err:
            logger.error(f"VERIFY AFTER COMMIT: Error during verification select for {chat_id}/{role}: {verify_err}", exc_info=True)
        # <<< КОНЕЦ ПРОВЕРКИ >>>

    except (aiosqlite.Error, ImportError) as e:
        logger.error(f"Failed insert history chat={chat_id}, role={role}, user={user_id}: {e}", exc_info=True)
        # Попытка отката
        if 'conn' in locals() and conn and not isinstance(e, ImportError):
            try:
                logger.warning(f"Attempting rollback after failed history insert for chat={chat_id}, role={role}...") # Лог перед rollback
                await conn.rollback()
                logger.info(f"Rollback successful after failed history insert for chat={chat_id}, role={role}.") # Лог после rollback
            except Exception as rb_e:
                logger.error(f"Rollback failed after history insert error: {rb_e}")
    except Exception as e:
        logger.error(f"Unexpected error adding history chat={chat_id}, role={role}, user={user_id}: {e}", exc_info=True)


async def get_chat_history(chat_id: int, limit: int = 50) -> List[Dict[str, Any]]:
    """
    Получает историю чата из БД в виде списка словарей.
    Возвращает [{role: ..., user_id: ... (opt), parts: [{text: ...}, ...]}, ...].
    """
    if not isinstance(limit, int) or limit <= 0:
        limit = 50

    conn: aiosqlite.Connection
    history_list: List[Dict[str, Any]] = []
    try:
        conn = await get_connection()
        async with conn.execute(
            """
            SELECT role, user_id, parts_json, timestamp
            FROM chat_history
            WHERE chat_id = ?
            ORDER BY timestamp DESC
            LIMIT ?
            """,
            (chat_id, limit)
        ) as cursor:
            rows = await cursor.fetchall()

        for row in reversed(rows):
            # --- ВЫЗОВ ДЕСЕРИАЛИЗАЦИИ ---
            parts_list = _deserialize_parts(row['parts_json']) # <-- Сначала десериализуем
            # ---------------------------

            # --->>> НАЧАЛО ИСПРАВЛЕННОГО БЛОКА <<<---
            deserialization_error = False
            # Проверяем на маркер ошибки ПОСЛЕ десериализации
            # Убираем лишний отступ у этого if
            if parts_list and isinstance(parts_list, list) and len(parts_list) > 0 and isinstance(parts_list[0], dict) and parts_list[0].get("error") == "deserialization_failed":
                # Логгируем ошибку и устанавливаем флаг
                logger.error(f"History entry skipped due to deserialization error: chat={chat_id}, role={row['role']}, ts={row['timestamp']}")
                deserialization_error = True
                # Пропускаем обработку этой записи, так как она повреждена
                continue # <-- ВАЖНО: переходим к следующей строке истории
            # --->>> КОНЕЦ ИСПРАВЛЕННОГО БЛОКА <<<---

            # Добавляем запись в историю, только если не было ошибки десериализации
            # и список частей не пустой (если мы все же решили не сохранять пустые)
            if not deserialization_error and parts_list:
                entry = {"role": row["role"], "parts": parts_list}
                if row["role"] == 'user' and row['user_id'] is not None:
                    entry['user_id'] = row['user_id']
                history_list.append(entry)
            elif not deserialization_error: # Если список пуст, но ошибки не было
                 logger.warning(f"Deserialized parts resulted in empty list (and no error marker), skipping history entry. chat={chat_id}, role={row['role']}, ts={row['timestamp']}")

        logger.debug(f"Retrieved {len(history_list)} history entries for chat_id={chat_id} (limit={limit})")
        return history_list

    except (aiosqlite.Error, ImportError) as e:
        logger.error(f"Failed fetch chat history chat_id={chat_id}: {e}", exc_info=True)
        return []
    except Exception as e:
        logger.error(f"Unexpected error fetching chat history chat_id={chat_id}: {e}", exc_info=True)
        return []
        
async def clear_chat_history(chat_id: int) -> int:
    """
    Удаляет всю историю сообщений для указанного chat_id.
    Возвращает количество удаленных записей.
    """
    conn: aiosqlite.Connection
    deleted_count = 0
    try:
        conn = await get_connection()
        cursor = await conn.execute("DELETE FROM chat_history WHERE chat_id = ?", (chat_id,))
        deleted_count = cursor.rowcount
        logger.debug(f"Executed DELETE and committed for clear_history chat={chat_id}.") # Лог после commit
        await cursor.close()
        if deleted_count > 0:
             logger.info(f"Cleared {deleted_count} history entries for chat_id={chat_id}")
        else:
             logger.info(f"No history entries found to clear for chat_id={chat_id}")
    except (aiosqlite.Error, ImportError) as e:
        logger.error(f"Failed to clear history for chat_id={chat_id}: {e}", exc_info=True)
        if 'conn' in locals() and conn and not isinstance(e, ImportError):
              try:
                  logger.warning(f"Attempting rollback after failed history clear for chat={chat_id}...") # Лог перед rollback
                  await conn.rollback()
                  logger.info(f"Rollback successful after failed history clear for chat={chat_id}.") # Лог после rollback
              except Exception as rb_e: logger.error(f"Rollback failed after history clear error: {rb_e}")
    except Exception as e:
        logger.error(f"Unexpected error clearing history for chat_id={chat_id}: {e}", exc_info=True)
    return deleted_count

========== Файл: database\crud_ops\news.py ==========

# database/crud_ops/news.py
import aiosqlite
import json
import logging
from typing import List, Dict, Any, Optional, Set
from datetime import datetime, timedelta, timezone # Добавляем timezone

# Используем относительный импорт
try:
    from ..connection import get_connection
except ImportError:
    async def get_connection(): raise ImportError("Connection module not loaded")
    logging.getLogger(__name__).critical("Failed to import get_connection from ..connection")

logger = logging.getLogger(__name__)

# --- Функции для news_subscriptions ---

async def add_or_update_subscription(
    channel_id: int,
    topics: List[str],
    schedule: List[str]
) -> bool:
    """
    Добавляет или обновляет подписку на новости для канала.
    Возвращает True при успехе, False при ошибке.
    """
    if not isinstance(channel_id, int):
        logger.error(f"add_or_update_subscription: Invalid channel_id: {channel_id}")
        return False
    if not isinstance(topics, list) or not all(isinstance(t, str) for t in topics):
        logger.error(f"add_or_update_subscription: Invalid topics format for channel {channel_id}")
        return False
    if not isinstance(schedule, list) or not all(isinstance(t, str) for t in schedule):
         logger.error(f"add_or_update_subscription: Invalid schedule format for channel {channel_id}")
         return False

    conn: aiosqlite.Connection
    try:
        conn = await get_connection()
        topics_json = json.dumps(topics, ensure_ascii=False)
        schedule_json = json.dumps(schedule, ensure_ascii=False)

        # Используем INSERT ... ON CONFLICT для атомарного добавления/обновления
        await conn.execute('''
            INSERT INTO news_subscriptions (channel_id, topics_json, schedule_json)
            VALUES (?, ?, ?)
            ON CONFLICT(channel_id) DO UPDATE SET
                topics_json = excluded.topics_json,
                schedule_json = excluded.schedule_json,
                -- last_post_ts не сбрасываем при обновлении тем/расписания, сохраняем старое значение
                last_post_ts = last_post_ts
            WHERE channel_id = excluded.channel_id;
        ''', (channel_id, topics_json, schedule_json))
        await conn.commit()
        logger.info(f"Upserted news subscription for channel_id={channel_id}")
        return True

    except (aiosqlite.Error, ImportError, json.JSONDecodeError) as e:
        logger.error(f"Error upserting news subscription channel={channel_id}: {e}", exc_info=True)
        if 'conn' in locals() and conn and not isinstance(e, ImportError):
              try: await conn.rollback()
              except Exception as rb_e: logger.error(f"Rollback failed after news subscription upsert error: {rb_e}")
        return False
    except Exception as e:
        logger.error(f"Unexpected error upserting news subscription channel={channel_id}: {e}", exc_info=True)
        return False


async def get_subscription(channel_id: int) -> Optional[Dict[str, Any]]:
    """
    Получает данные подписки для канала.
    Возвращает словарь с 'channel_id', 'topics' (list), 'schedule' (list), 'last_post_ts' (datetime или None) или None.
    """
    if not isinstance(channel_id, int):
        logger.error(f"get_subscription: Invalid channel_id: {channel_id}")
        return None

    conn: aiosqlite.Connection
    subscription_data: Optional[Dict[str, Any]] = None
    try:
        conn = await get_connection()
        async with conn.execute(
            "SELECT channel_id, topics_json, schedule_json, last_post_ts FROM news_subscriptions WHERE channel_id = ?",
            (channel_id,)
        ) as cursor:
            row = await cursor.fetchone()
            if row:
                try:
                    topics = json.loads(row['topics_json'])
                    schedule = json.loads(row['schedule_json'])
                    # Конвертируем строку времени из БД в datetime объект, если она есть
                    last_post_ts_str = row['last_post_ts']
                    last_post_ts = datetime.fromisoformat(last_post_ts_str) if last_post_ts_str else None

                    subscription_data = {
                        "channel_id": row['channel_id'],
                        "topics": topics,
                        "schedule": schedule,
                        "last_post_ts": last_post_ts # Объект datetime или None
                    }
                    logger.debug(f"Retrieved subscription for channel_id={channel_id}")
                except (json.JSONDecodeError, TypeError, ValueError) as parse_error:
                     logger.error(f"Error parsing subscription data channel={channel_id}: {parse_error}")
                     # subscription_data останется None
            else:
                logger.debug(f"No subscription found for channel_id={channel_id}")

    except (aiosqlite.Error, ImportError) as e:
        logger.error(f"Error getting subscription channel={channel_id}: {e}", exc_info=True)
    except Exception as e:
        logger.error(f"Unexpected error getting subscription channel={channel_id}: {e}", exc_info=True)

    return subscription_data


async def get_all_subscriptions() -> List[Dict[str, Any]]:
    """
    Получает список всех активных подписок.
    Возвращает пустой список при ошибке или отсутствии подписок.
    """
    conn: aiosqlite.Connection
    subscriptions: List[Dict[str, Any]] = []
    try:
        conn = await get_connection()
        async with conn.execute(
            "SELECT channel_id, topics_json, schedule_json, last_post_ts FROM news_subscriptions ORDER BY channel_id"
        ) as cursor:
            rows = await cursor.fetchall()
            for row in rows:
                 try:
                    topics = json.loads(row['topics_json'])
                    schedule = json.loads(row['schedule_json'])
                    last_post_ts_str = row['last_post_ts']
                    last_post_ts = datetime.fromisoformat(last_post_ts_str) if last_post_ts_str else None
                    subscriptions.append({
                        "channel_id": row['channel_id'],
                        "topics": topics,
                        "schedule": schedule,
                        "last_post_ts": last_post_ts
                    })
                 except (json.JSONDecodeError, TypeError, ValueError) as parse_error:
                      logger.error(f"Error parsing subscription JSON during get_all channel={row['channel_id']}: {parse_error}")
                      continue # Пропускаем поврежденную запись

        logger.info(f"Retrieved {len(subscriptions)} news subscriptions.")
    except (aiosqlite.Error, ImportError) as e:
        logger.error(f"Error getting all subscriptions: {e}", exc_info=True)
    except Exception as e:
        logger.error(f"Unexpected error getting all subscriptions: {e}", exc_info=True)

    return subscriptions


async def update_subscription_last_post(channel_id: int, timestamp: datetime) -> bool:
    """
    Обновляет время последнего поста для подписки.
    Принимает объект datetime.
    """
    if not isinstance(channel_id, int):
        logger.error(f"update_subscription_last_post: Invalid channel_id: {channel_id}")
        return False
    if not isinstance(timestamp, datetime):
         logger.error(f"update_subscription_last_post: Invalid timestamp type for channel {channel_id}: {type(timestamp)}")
         return False

    conn: aiosqlite.Connection
    try:
        conn = await get_connection()
        # Преобразуем datetime в строку ISO формата для записи в БД
        ts_iso_string = timestamp.isoformat()
        cursor = await conn.execute(
            "UPDATE news_subscriptions SET last_post_ts = ? WHERE channel_id = ?",
            (ts_iso_string, channel_id)
        )
        rows_affected = cursor.rowcount
        await conn.commit()
        await cursor.close()
        if rows_affected > 0:
             logger.debug(f"Updated last_post_ts for channel={channel_id} to {ts_iso_string}")
             return True
        else:
             logger.warning(f"Subscription not found to update last_post_ts for channel={channel_id}")
             return False # Подписка не найдена, но ошибки не было
    except (aiosqlite.Error, ImportError) as e:
        logger.error(f"Error updating last_post_ts channel={channel_id}: {e}", exc_info=True)
        if 'conn' in locals() and conn and not isinstance(e, ImportError):
              try: await conn.rollback()
              except Exception as rb_e: logger.error(f"Rollback failed after last_post_ts update error: {rb_e}")
        return False
    except Exception as e:
         logger.error(f"Unexpected error updating last_post_ts channel={channel_id}: {e}", exc_info=True)
         return False


async def delete_subscription(channel_id: int) -> bool:
    """Удаляет подписку канала."""
    if not isinstance(channel_id, int):
        logger.error(f"delete_subscription: Invalid channel_id: {channel_id}")
        return False

    conn: aiosqlite.Connection
    success = False
    try:
        conn = await get_connection()
        cursor = await conn.execute("DELETE FROM news_subscriptions WHERE channel_id = ?", (channel_id,))
        deleted_count = cursor.rowcount
        await conn.commit()
        await cursor.close()
        if deleted_count > 0:
            logger.info(f"Deleted news subscription for channel_id={channel_id}")
            success = True
        else:
            logger.info(f"Subscription not found for deletion: channel_id={channel_id}")
            success = False # Запись не найдена, но ошибки не было
    except (aiosqlite.Error, ImportError) as e:
        logger.error(f"Error deleting subscription channel={channel_id}: {e}", exc_info=True)
        if 'conn' in locals() and conn and not isinstance(e, ImportError):
              try: await conn.rollback()
              except Exception as rb_e: logger.error(f"Rollback failed after subscription delete error: {rb_e}")
        success = False
    except Exception as e:
         logger.error(f"Unexpected error deleting subscription channel={channel_id}: {e}", exc_info=True)
         success = False
    return success


# --- Функции для работы с sent_news_guids ---

async def add_sent_guid(guid: str) -> bool:
    """Добавляет GUID новости в базу данных. Использует INSERT OR IGNORE."""
    if not guid or not isinstance(guid, str):
        logger.warning("add_sent_guid: Attempted to add empty or invalid GUID.")
        return False

    conn: aiosqlite.Connection
    try:
        conn = await get_connection()
        # Используем CURRENT_TIMESTAMP для времени отправки
        await conn.execute(
            "INSERT OR IGNORE INTO sent_news_guids (guid, sent_ts) VALUES (?, CURRENT_TIMESTAMP)",
            (guid,)
        )
        await conn.commit()
        # Не логируем успех для каждой новости, чтобы не засорять логи
        # logger.debug(f"Added or ignored sent GUID: {guid}")
        return True
    except (aiosqlite.Error, ImportError) as e:
        logger.error(f"Error adding sent GUID '{guid}': {e}", exc_info=True)
        if 'conn' in locals() and conn and not isinstance(e, ImportError):
              try: await conn.rollback()
              except Exception as rb_e: logger.error(f"Rollback failed after adding sent GUID error: {rb_e}")
        return False
    except Exception as e:
         logger.error(f"Unexpected error adding sent GUID '{guid}': {e}", exc_info=True)
         return False


async def is_guid_sent(guid: str) -> bool:
    """Проверяет, был ли уже отправлен GUID."""
    if not guid or not isinstance(guid, str):
        return False # Считаем невалидный GUID "не отправленным"

    conn: aiosqlite.Connection
    is_sent = False
    try:
        conn = await get_connection()
        async with conn.execute("SELECT 1 FROM sent_news_guids WHERE guid = ? LIMIT 1", (guid,)) as cursor:
            row = await cursor.fetchone()
            is_sent = row is not None
    except (aiosqlite.Error, ImportError) as e:
        logger.error(f"Error checking sent GUID '{guid}': {e}", exc_info=True)
    except Exception as e:
         logger.error(f"Unexpected error checking sent GUID '{guid}': {e}", exc_info=True)
    return is_sent


async def load_recent_sent_guids(days: int = 7) -> Set[str]:
    """Загружает GUIDы, отправленные за последние N дней."""
    conn: aiosqlite.Connection
    guids: Set[str] = set()
    try:
        conn = await get_connection()
        # Вычисляем дату N дней назад (с учетом часового пояса UTC)
        cutoff_date = datetime.now(timezone.utc) - timedelta(days=days)
        # Сравниваем с меткой времени в БД (которая должна сохраняться в UTC по умолчанию)
        async with conn.execute(
            "SELECT guid FROM sent_news_guids WHERE sent_ts >= ?",
            (cutoff_date.isoformat(),) # Передаем дату в ISO формате
        ) as cursor:
            rows = await cursor.fetchall()
            guids = {row['guid'] for row in rows}
        logger.info(f"Loaded {len(guids)} recent sent GUIDs (last {days} days).")
    except (aiosqlite.Error, ImportError) as e:
        logger.error(f"Error loading recent sent GUIDs: {e}", exc_info=True)
    except Exception as e:
         logger.error(f"Unexpected error loading recent sent GUIDs: {e}", exc_info=True)
    return guids


async def cleanup_old_guids(days: int = 30) -> int:
    """Удаляет GUIDы старше N дней. Возвращает количество удаленных."""
    conn: aiosqlite.Connection
    deleted_count = 0
    try:
        conn = await get_connection()
        cutoff_date = datetime.now(timezone.utc) - timedelta(days=days)
        cursor = await conn.execute("DELETE FROM sent_news_guids WHERE sent_ts < ?", (cutoff_date.isoformat(),))
        deleted_count = cursor.rowcount
        await conn.commit()
        await cursor.close()
        if deleted_count > 0:
            logger.info(f"Cleaned up {deleted_count} old sent GUIDs (older than {days} days).")
        else:
             logger.info(f"No old GUIDs found to cleanup (older than {days} days).")
    except (aiosqlite.Error, ImportError) as e:
        logger.error(f"Error cleaning up old GUIDs: {e}", exc_info=True)
        if 'conn' in locals() and conn and not isinstance(e, ImportError):
              try: await conn.rollback()
              except Exception as rb_e: logger.error(f"Rollback failed after GUID cleanup error: {rb_e}")
    except Exception as e:
        logger.error(f"Unexpected error cleaning up old GUIDs: {e}", exc_info=True)
    return deleted_count

========== Файл: database\crud_ops\notes.py ==========

# database/crud_ops/notes.py
import aiosqlite
import json
import logging
from typing import Dict, Any, Optional, List

# Используем относительный импорт
try:
    from ..connection import get_connection
    # Импортируем функции профиля для get_user_data_combined
    from .profiles import get_user_profile
except ImportError:
    async def get_connection(): raise ImportError("Connection module not loaded")
    async def get_user_profile(uid): return None # Заглушка
    logging.getLogger(__name__).critical("Failed to import dependencies from ..connection or .profiles")

logger = logging.getLogger(__name__)

async def upsert_user_note(
    user_id: int,
    category: str,
    value: str,
    merge_lists: bool = True
) -> bool:
    """
    Добавляет или обновляет заметку о пользователе.
    При merge_lists=True обрабатывает JSON-списки/словари для объединения.
    Возвращает True при успехе, False при ошибке.
    """
    if not isinstance(user_id, int) or user_id <= 0:
        logger.error(f"upsert_user_note: Invalid user_id: {user_id}")
        return False
    if not category or not isinstance(category, str):
        logger.warning(f"upsert_user_note: Attempted save with empty/invalid category for user {user_id}")
        return False
    if value is None: # Пустая строка допустима, None - нет
        logger.warning(f"upsert_user_note: Attempted save None value for user {user_id}, category '{category}'")
        return False
    if not isinstance(value, str):
         logger.warning(f"upsert_user_note: value not string ({type(value)}), converting for user {user_id}, cat '{category}'")
         value = str(value)

    conn: aiosqlite.Connection
    category_cleaned = category.strip().lower() # Приводим категорию к нижнему регистру
    value_cleaned = value.strip()
    final_value = value_cleaned # Значение для записи по умолчанию

    try:
        conn = await get_connection()
        # Получаем текущее значение, если нужно объединять
        current_data: Optional[Any] = None
        if merge_lists:
            async with conn.execute(
                "SELECT value FROM user_notes WHERE user_id = ? AND category = ?",
                (user_id, category_cleaned)
            ) as cursor:
                row = await cursor.fetchone()
                if row:
                    try:
                        # Пытаемся распарсить существующее значение
                        current_data = json.loads(row['value'])
                        logger.debug(f"Found existing JSON data for merging: user={user_id}, cat={category_cleaned}")
                    except (json.JSONDecodeError, TypeError):
                        # Если не JSON, объединять не с чем
                        current_data = None
                        logger.debug(f"Existing value is not JSON, cannot merge. user={user_id}, cat={category_cleaned}")

        # Пытаемся объединить, если нужно и возможно
        if merge_lists and current_data is not None:
            try:
                # Пытаемся распарсить новое значение
                new_data = json.loads(value_cleaned)

                if isinstance(current_data, list) and isinstance(new_data, list):
                    # Объединяем списки, добавляя уникальные элементы из нового
                    existing_set = set(json.dumps(item, sort_keys=True) if isinstance(item, (dict, list)) else item for item in current_data)
                    for item in new_data:
                        item_key = json.dumps(item, sort_keys=True) if isinstance(item, (dict, list)) else item
                        if item_key not in existing_set:
                            current_data.append(item)
                            existing_set.add(item_key) # Добавляем в set для проверки дубликатов внутри new_data
                    final_value = json.dumps(current_data, ensure_ascii=False)
                    logger.info(f"Merged lists for user={user_id}, cat='{category_cleaned}', new size={len(current_data)}")
                elif isinstance(current_data, dict) and isinstance(new_data, dict):
                    # Обновляем словарь (новые ключи заменят старые)
                    current_data.update(new_data)
                    final_value = json.dumps(current_data, ensure_ascii=False)
                    logger.info(f"Updated dictionary for user={user_id}, cat='{category_cleaned}'")
                else:
                    # Типы не совпадают или не список/словарь - не объединяем
                    logger.debug(f"Cannot merge: type mismatch ({type(current_data)} vs {type(new_data)}) or not list/dict. user={user_id}, cat={category_cleaned}")
                    # final_value остается value_cleaned

            except (json.JSONDecodeError, TypeError):
                # Новое значение не JSON - не объединяем
                logger.debug(f"Cannot merge: new value is not JSON. user={user_id}, cat={category_cleaned}")
                # final_value остается value_cleaned

        # Выполняем INSERT OR REPLACE (или ON CONFLICT DO UPDATE)
        await conn.execute('''
            INSERT INTO user_notes (user_id, category, value, timestamp)
            VALUES (?, ?, ?, CURRENT_TIMESTAMP)
            ON CONFLICT(user_id, category) DO UPDATE SET
                value = excluded.value,
                timestamp = CURRENT_TIMESTAMP
            WHERE user_id = excluded.user_id AND category = excluded.category;
        ''', (user_id, category_cleaned, final_value))
        await conn.commit()
        logger.info(f"Upserted note for user={user_id}: category='{category_cleaned}'")
        return True

    except (aiosqlite.Error, ImportError) as e:
        logger.error(f"Error upserting note user={user_id}, cat='{category_cleaned}': {e}", exc_info=True)
        if 'conn' in locals() and conn and not isinstance(e, ImportError):
              try: await conn.rollback()
              except Exception as rb_e: logger.error(f"Rollback failed after note upsert error: {rb_e}")
        return False
    except Exception as e:
        logger.error(f"Unexpected error upserting note user={user_id}, cat='{category_cleaned}': {e}", exc_info=True)
        return False


async def get_user_notes(user_id: int, parse_json: bool = True) -> Dict[str, Any]:
    """
    Получает все заметки о пользователе в виде словаря {категория: значение}.
    Если parse_json=True, пытается автоматически распарсить значения как JSON.
    Возвращает пустой словарь при ошибке или отсутствии заметок.
    """
    if not isinstance(user_id, int) or user_id <= 0:
        logger.error(f"get_user_notes: Invalid user_id: {user_id}")
        return {}

    conn: aiosqlite.Connection
    notes: Dict[str, Any] = {}
    try:
        conn = await get_connection()
        async with conn.execute(
            "SELECT category, value FROM user_notes WHERE user_id = ? ORDER BY category",
            (user_id,)
        ) as cursor:
            rows = await cursor.fetchall()
            if not rows:
                logger.debug(f"No notes found for user_id={user_id}")
                return {}

            for row in rows:
                category = row['category'] # Категория уже должна быть lowercase из БД
                value_str = row['value']
                if parse_json:
                    try:
                        # Пробуем распарсить, только если похоже на JSON
                        if value_str and (value_str.startswith('[') or value_str.startswith('{')):
                            notes[category] = json.loads(value_str)
                        else:
                            notes[category] = value_str # Оставляем как строку
                    except (json.JSONDecodeError, TypeError):
                        logger.warning(f"Failed to parse note as JSON user={user_id}, cat='{category}'. Returning as string.")
                        notes[category] = value_str # Возвращаем как строку при ошибке парсинга
                else:
                    notes[category] = value_str

            logger.debug(f"Retrieved {len(notes)} notes for user_id={user_id}")

    except (aiosqlite.Error, ImportError) as e:
        logger.error(f"Error getting notes for user_id {user_id}: {e}", exc_info=True)
        return {} # Возвращаем пустой словарь при ошибке
    except Exception as e:
        logger.error(f"Unexpected error getting notes for user_id {user_id}: {e}", exc_info=True)
        return {}

    return notes


async def delete_user_note(user_id: int, category: str) -> bool:
    """
    Удаляет заметку пользователя по категории (без учета регистра).
    Возвращает True при успехе, False если заметка не найдена или произошла ошибка.
    """
    if not isinstance(user_id, int) or user_id <= 0:
        logger.error(f"delete_user_note: Invalid user_id: {user_id}")
        return False
    if not category or not isinstance(category, str):
        logger.warning(f"delete_user_note: Attempted delete with empty/invalid category user={user_id}")
        return False

    conn: aiosqlite.Connection
    success = False
    category_cleaned = category.strip().lower()
    try:
        conn = await get_connection()
        cursor = await conn.execute(
            # Используем LOWER() для сравнения без учета регистра, если в таблице не COLLATE NOCASE
            "DELETE FROM user_notes WHERE user_id = ? AND category = ?",
            (user_id, category_cleaned)
        )
        deleted_count = cursor.rowcount
        await conn.commit()
        await cursor.close()

        if deleted_count > 0:
            logger.info(f"Deleted note user={user_id}, category='{category_cleaned}'")
            success = True
        else:
            logger.info(f"Note not found for deletion: user={user_id}, category='{category_cleaned}'")
            success = False # Явно указываем, что не найдена

    except (aiosqlite.Error, ImportError) as e:
        logger.error(f"Error deleting note user={user_id}, cat='{category_cleaned}': {e}", exc_info=True)
        if 'conn' in locals() and conn and not isinstance(e, ImportError):
              try: await conn.rollback()
              except Exception as rb_e: logger.error(f"Rollback failed after note delete error: {rb_e}")
        success = False
    except Exception as e:
        logger.error(f"Unexpected error deleting note user={user_id}, cat='{category_cleaned}': {e}", exc_info=True)
        success = False

    return success


async def delete_user_note_nested(
    user_id: int,
    category: str,
    key: Optional[str] = None,
    list_item: Optional[Any] = None # Принимаем любой тип для list_item
) -> bool:
    """
    Удаляет часть заметки пользователя (ключ из словаря или элемент из списка).
    Если key и list_item не указаны, вызывает delete_user_note.
    Возвращает True при успехе, False при ошибке или если элемент/ключ не найден.
    """
    if not isinstance(user_id, int) or user_id <= 0: return False
    if not category or not isinstance(category, str): return False

    # Если не указано, что удалять внутри, удаляем всю заметку
    if key is None and list_item is None:
        logger.debug(f"Redirecting nested delete to full delete for user={user_id}, cat='{category}'")
        return await delete_user_note(user_id, category)

    conn: aiosqlite.Connection
    success = False
    category_cleaned = category.strip().lower()

    try:
        conn = await get_connection()
        # 1. Получаем текущее значение
        async with conn.execute(
            "SELECT value FROM user_notes WHERE user_id = ? AND category = ?",
            (user_id, category_cleaned)
        ) as cursor:
            row = await cursor.fetchone()

        if not row:
            logger.info(f"Note not found for nested delete: user={user_id}, cat='{category_cleaned}'")
            return False

        current_value_str = row['value']

        # 2. Пытаемся распарсить как JSON
        try:
            current_data = json.loads(current_value_str)
            original_data_repr = str(current_data)[:100] # Для логов до изменения
            data_modified = False

            # 3. Удаляем ключ из словаря
            if key is not None and isinstance(current_data, dict):
                if key in current_data:
                    del current_data[key]
                    logger.info(f"Deleted key '{key}' from note dict user={user_id}, cat='{category_cleaned}'")
                    data_modified = True
                else:
                    logger.info(f"Key '{key}' not found in note dict user={user_id}, cat='{category_cleaned}'")
                    return False # Ключ не найден, считаем неудачей

            # 4. Удаляем элемент из списка
            elif list_item is not None and isinstance(current_data, list):
                 initial_len = len(current_data)
                 # Удаляем все вхождения элемента, сравнивая напрямую
                 current_data = [item for item in current_data if item != list_item]
                 if len(current_data) < initial_len:
                      logger.info(f"Removed item '{str(list_item)[:50]}...' from list note user={user_id}, cat='{category_cleaned}'")
                      data_modified = True
                 else:
                      logger.info(f"Item '{str(list_item)[:50]}...' not found in list note user={user_id}, cat='{category_cleaned}'")
                      return False # Элемент не найден

            # 5. Если ни ключ, ни элемент не подходят
            elif key is not None or list_item is not None:
                logger.warning(f"Cannot perform nested deletion: data type ({type(current_data)}) is not dict/list or mismatch for user={user_id}, cat='{category_cleaned}'")
                return False

            # 6. Обновляем или удаляем запись в БД
            if data_modified:
                # Если словарь/список стал пустым после удаления, удаляем всю заметку
                if not current_data:
                    logger.info(f"Data became empty after nested delete user={user_id}, cat='{category_cleaned}'. Deleting full note.")
                    # Закрываем предыдущий курсор перед вызовом delete_user_note
                    # (хотя async with должен был это сделать)
                    await cursor.close()
                    return await delete_user_note(user_id, category_cleaned)
                else:
                    # Обновляем JSON в БД
                    new_value_str = json.dumps(current_data, ensure_ascii=False)
                    # Используем новый курсор для UPDATE
                    await conn.execute(
                        "UPDATE user_notes SET value = ?, timestamp = CURRENT_TIMESTAMP WHERE user_id = ? AND category = ?",
                        (new_value_str, user_id, category_cleaned)
                    )
                    await conn.commit()
                    success = True
            # else: Не было модификаций (ошибка выше или элемент не найден)

        except json.JSONDecodeError:
            logger.warning(f"Cannot perform nested deletion: note value is not valid JSON user={user_id}, cat='{category_cleaned}'")
            return False

    except (aiosqlite.Error, ImportError) as e:
        logger.error(f"DB Error nested delete user={user_id}, cat='{category_cleaned}': {e}", exc_info=True)
        if 'conn' in locals() and conn and not isinstance(e, ImportError):
              try: await conn.rollback()
              except Exception as rb_e: logger.error(f"Rollback failed after nested note delete error: {rb_e}")
        success = False
    except Exception as e:
        logger.error(f"Unexpected error nested delete user={user_id}, cat='{category_cleaned}': {e}", exc_info=True)
        success = False

    return success


async def get_user_data_combined(user_id: int) -> Dict[str, Any]:
    """
    Получает все данные о пользователе из таблиц user_profiles и user_notes.
    Возвращает словарь с ключами 'profile' и 'notes', или пустой словарь при ошибке.
    """
    if not isinstance(user_id, int) or user_id <= 0:
        logger.error(f"get_user_data_combined: Invalid user_id: {user_id}")
        return {}

    result: Dict[str, Any] = {}
    try:
        # Получаем данные профиля
        profile_data = await get_user_profile(user_id)
        if profile_data:
            result["profile"] = profile_data

        # Получаем заметки с автоматическим парсингом JSON
        notes_data = await get_user_notes(user_id, parse_json=True)
        if notes_data:
            result["notes"] = notes_data

        if not result:
             logger.debug(f"No profile or notes found for user_id={user_id}")

    except Exception as e:
        # Логируем ошибку, если она произошла в get_user_profile или get_user_notes
        logger.error(f"Error combining user data for user_id={user_id}: {e}", exc_info=True)
        return {} # Возвращаем пустой словарь при ошибке

    return result

========== Файл: database\crud_ops\profiles.py ==========

# database/crud_ops/profiles.py
import aiosqlite
import logging
from typing import Dict, Any, Optional

# Используем относительный импорт для связи с connection.py
try:
    from ..connection import get_connection
except ImportError:
     # Заглушка на случай проблем с импортом
    async def get_connection(): raise ImportError("Connection module not loaded")
    logging.getLogger(__name__).critical("Failed to import get_connection from ..connection")

logger = logging.getLogger(__name__)

async def upsert_user_profile(
    user_id: int,
    username: Optional[str],
    first_name: Optional[str],
    last_name: Optional[str]
) -> bool:
    """
    Добавляет или обновляет базовую информацию о пользователе
    (username, first_name, last_name, last_seen).
    Возвращает True при успехе, False при ошибке.
    """
    if not isinstance(user_id, int) or user_id <= 0:
        logger.error(f"Attempted to upsert profile with invalid user_id: {user_id}")
        return False

    conn: aiosqlite.Connection
    try:
        conn = await get_connection()
        await conn.execute('''
            INSERT INTO user_profiles (user_id, username, first_name, last_name, last_seen)
            VALUES (?, ?, ?, ?, CURRENT_TIMESTAMP)
            ON CONFLICT(user_id) DO UPDATE SET
                username = excluded.username,
                first_name = excluded.first_name,
                last_name = excluded.last_name,
                last_seen = CURRENT_TIMESTAMP
            WHERE user_id = excluded.user_id;
        ''', (user_id, username, first_name, last_name))
        logger.debug(f"Executed UPSERT for user_id {user_id}. Preparing to commit...")
        await conn.commit()
        logger.info(f"Successfully committed upsert for user profile for user_id {user_id}")

        # <<< ПРОВЕРКА СРАЗУ ПОСЛЕ КОММИТА >>>
        try:
            async with conn.execute("SELECT last_seen FROM user_profiles WHERE user_id = ?", (user_id,)) as cursor:
                row = await cursor.fetchone()
                if row:
                    logger.info(f"VERIFY AFTER COMMIT: Found profile for {user_id}, last_seen: {row['last_seen']}")
                else:
                    logger.error(f"VERIFY AFTER COMMIT: FAILED TO FIND profile for {user_id} immediately after commit!")
        except Exception as verify_err:
            logger.error(f"VERIFY AFTER COMMIT: Error during verification select for {user_id}: {verify_err}", exc_info=True)
        # <<< КОНЕЦ ПРОВЕРКИ >>>

        return True
    except (aiosqlite.Error, ImportError) as e: # Ловим и ImportError от get_connection
         logger.error(f"Failed to upsert user profile for user_id {user_id}: {e}", exc_info=True)
         # Попытка отката не нужна при SELECT/INSERT OR REPLACE, но не помешает
         if 'conn' in locals() and conn and not isinstance(e, ImportError):
              try:
                  logger.warning(f"Attempting rollback after failed profile upsert for user_id={user_id}...")
                  await conn.rollback()
                  logger.info(f"Rollback successful after failed profile upsert for user_id={user_id}.")
              except Exception as rb_e: logger.error(f"Rollback failed after profile upsert error: {rb_e}")
         return False
    except Exception as e:
        logger.error(f"Unexpected error upserting profile for user_id {user_id}: {e}", exc_info=True)
        return False


async def get_user_profile(user_id: int) -> Optional[Dict[str, Any]]:
    """
    Получает данные профиля пользователя из таблицы user_profiles.
    Возвращает словарь с данными или None, если пользователь не найден или произошла ошибка.
    """
    if not isinstance(user_id, int) or user_id <= 0:
        logger.error(f"Attempted to get profile with invalid user_id: {user_id}")
        return None

    conn: aiosqlite.Connection
    profile_data: Optional[Dict[str, Any]] = None
    try:
        conn = await get_connection()
        async with conn.execute(
            """
            SELECT user_id, username, first_name, last_name, last_seen, avatar_file_id, avatar_description
            FROM user_profiles
            WHERE user_id = ?
            """,
            (user_id,)
        ) as cursor:
            row = await cursor.fetchone()
            if row:
                # Преобразуем aiosqlite.Row в обычный словарь
                profile_data = dict(row)
                logger.debug(f"Retrieved profile data for user_id={user_id}")
            else:
                logger.debug(f"No profile found for user_id={user_id}")
    except (aiosqlite.Error, ImportError) as e:
        logger.error(f"Error getting user profile for user_id {user_id}: {e}", exc_info=True)
    except Exception as e:
        logger.error(f"Unexpected error getting profile for user_id {user_id}: {e}", exc_info=True)

    return profile_data # Возвращаем словарь или None


async def update_avatar_description(
    user_id: int,
    avatar_file_id: Optional[str] = None,
    avatar_description: Optional[str] = None
) -> bool:
    """
    Обновляет информацию об аватаре пользователя (file_id и/или description) в его профиле.
    Если профиль не существует, пытается создать его с этой информацией.
    Возвращает True при успехе, False при ошибке.
    """
    if not isinstance(user_id, int) or user_id <= 0:
        logger.error(f"Attempted avatar update with invalid user_id: {user_id}")
        return False
    if avatar_file_id is None and avatar_description is None:
        logger.warning(f"Attempted avatar update with no data provided for user_id {user_id}")
        # Считаем это успехом, т.к. не было ошибки, просто нечего делать
        return True

    conn: aiosqlite.Connection
    updated = False
    try:
        conn = await get_connection()
        update_fields = []
        params = []
        if avatar_file_id is not None:
            update_fields.append("avatar_file_id = ?")
            params.append(avatar_file_id)
        if avatar_description is not None:
            update_fields.append("avatar_description = ?")
            params.append(avatar_description)

        params.append(user_id) # Добавляем user_id для WHERE

        sql_update = f"UPDATE user_profiles SET {', '.join(update_fields)}, last_seen = CURRENT_TIMESTAMP WHERE user_id = ?"

        logger.debug(f"Executing UPDATE avatar for user_id={user_id}. Preparing to commit...")
        cursor = await conn.execute(sql_update, tuple(params))
        rows_affected = cursor.rowcount
        await conn.commit()
        logger.info(f"Successfully committed avatar UPDATE for user_id={user_id}. Rows affected: {rows_affected}")
        await cursor.close()

        if rows_affected > 0:
            logger.info(f"Successfully updated avatar info for user_id={user_id}")
            updated = True
        else:
            # Профиль мог не существовать, пытаемся вставить
            logger.info(f"Profile not found for update user_id={user_id}, attempting insert...")
            insert_fields = ["user_id", "last_seen"]
            insert_placeholders = ["?", "CURRENT_TIMESTAMP"]
            insert_params = [user_id]

            if avatar_file_id is not None:
                insert_fields.append("avatar_file_id")
                insert_placeholders.append("?")
                insert_params.append(avatar_file_id)
            if avatar_description is not None:
                insert_fields.append("avatar_description")
                insert_placeholders.append("?")
                insert_params.append(avatar_description)

            # Используем INSERT OR IGNORE на случай гонки потоков
            sql_insert = f"INSERT OR IGNORE INTO user_profiles ({', '.join(insert_fields)}) VALUES ({', '.join(insert_placeholders)})"

            logger.debug(f"Executing INSERT avatar for user_id={user_id}. Preparing to commit...")
            cursor = await conn.execute(sql_insert, tuple(insert_params))
            rows_inserted = cursor.rowcount
            await conn.commit()
            logger.info(f"Successfully committed avatar INSERT for user_id={user_id}. Rows inserted: {rows_inserted}")
            await cursor.close()

            if rows_inserted > 0:
                logger.info(f"Successfully inserted profile with avatar info for user_id={user_id}")
                updated = True
            else:
                # Возможно, конфликт ключа при одновременной вставке, или другая ошибка IGNORE
                logger.warning(f"Failed to insert profile with avatar info for user_id={user_id} (maybe already exists or other IGNORE issue).")
                updated = False # Считаем неудачей, если не обновили и не вставили

    except (aiosqlite.Error, ImportError) as e:
        logger.error(f"Error updating/inserting avatar info for user_id={user_id}: {e}", exc_info=True)
        if 'conn' in locals() and conn and not isinstance(e, ImportError):
              try:
                  logger.warning(f"Attempting rollback after failed avatar update/insert for user_id={user_id}...")
                  await conn.rollback()
                  logger.info(f"Rollback successful after failed avatar update/insert for user_id={user_id}.")
              except Exception as rb_e: logger.error(f"Rollback failed after avatar update error: {rb_e}")
        updated = False
    except Exception as e:
        logger.error(f"Unexpected error updating avatar info for user_id={user_id}: {e}", exc_info=True)
        updated = False

    return updated


async def find_user_id_by_profile(query: str) -> Optional[int]:
    """
    Ищет user_id в таблице user_profiles по имени (first_name) или username (без @).
    Поиск без учета регистра.

    Args:
        query (str): Имя или username пользователя для поиска.

    Returns:
        Optional[int]: Найденный user_id или None.
    """
    if not query or not isinstance(query, str):
        logger.warning("find_user_id_by_profile called with empty or invalid query.")
        return None

    conn: aiosqlite.Connection
    query_lower = query.lower().strip()
    username_query = query_lower.lstrip('@') # Убираем @ для поиска по username

    found_id: Optional[int] = None
    try:
        conn = await get_connection()
        # Сначала ищем по точному совпадению username (без учета регистра)
        sql_user = 'SELECT user_id FROM user_profiles WHERE LOWER(username) = ? LIMIT 1'
        async with conn.execute(sql_user, (username_query,)) as cursor:
            row = await cursor.fetchone()
            if row:
                found_id = row['user_id']
                logger.info(f"Found user_id {found_id} by username '{query}'")

        # Если не нашли по username, ищем по точному совпадению first_name (без учета регистра)
        if found_id is None:
            sql_name = 'SELECT user_id FROM user_profiles WHERE LOWER(first_name) = ? LIMIT 1'
            async with conn.execute(sql_name, (query_lower,)) as cursor:
                row = await cursor.fetchone()
                if row:
                    found_id = row['user_id']
                    logger.info(f"Found user_id {found_id} by first_name '{query}'")

        # Если ничего не нашли
        if found_id is None:
            logger.info(f"User ID not found for query: '{query}'")

    except (aiosqlite.Error, ImportError) as e:
        logger.error(f"Error searching for user_id with query '{query}': {e}", exc_info=True)
    except Exception as e:
        logger.error(f"Unexpected error searching for user_id with query '{query}': {e}", exc_info=True)

    return found_id

========== Файл: database\crud_ops\settings.py ==========

# database/crud_ops/settings.py
import aiosqlite
import logging
from typing import Dict, Any, Optional

# Используем относительный импорт для связи с connection.py
try:
    from ..connection import get_connection
except ImportError:
    # Заглушка на случай проблем с импортом
    async def get_connection(): raise ImportError("Connection module not loaded")
    logging.getLogger(__name__).critical("Failed to import get_connection from ..connection")

logger = logging.getLogger(__name__)

# Константы для ai_mode, чтобы избежать опечаток и обеспечить согласованность
# Эти же константы можно будет импортировать в другие модули
AI_MODE_PRO = "pro"
AI_MODE_DEFAULT = "default" # Используем 'default' как имя для g4f или другого стандартного режима

async def upsert_chat_settings(
    chat_id: int,
    custom_prompt: Optional[str] = None,
    ai_mode: Optional[str] = None, # Принимает строки, соответствующие константам
    gemini_model: Optional[str] = None
) -> bool:
    """
    Обновляет или вставляет настройки для указанного чата.
    Обновляет только переданные не-None значения.
    Возвращает True при успехе, False при ошибке.
    """
    if not isinstance(chat_id, int):
        logger.error(f"upsert_chat_settings: Invalid chat_id: {chat_id}")
        return False

    conn: aiosqlite.Connection
    update_parts = []
    params: List[Any] = [] # Список для параметров SQL запроса

    # Собираем части для обновления
    if custom_prompt is not None:
        update_parts.append("custom_prompt = ?")
        params.append(custom_prompt)
    if ai_mode is not None:
        # Валидируем значение ai_mode
        if ai_mode not in [AI_MODE_PRO, AI_MODE_DEFAULT]:
            logger.warning(f"upsert_chat_settings: Invalid ai_mode '{ai_mode}' provided for chat {chat_id}. Ignoring update for this field.")
            # Не добавляем некорректное значение в запрос
        else:
            update_parts.append("ai_mode = ?")
            params.append(ai_mode)
    if gemini_model is not None:
        # TODO: Возможно, добавить валидацию имени модели по списку из config?
        update_parts.append("gemini_model = ?")
        params.append(gemini_model)

    # Если нечего обновлять/вставлять, считаем операцию успешной
    if not update_parts:
        logger.debug(f"No valid settings provided to upsert for chat_id {chat_id}.")
        return True # Успех, т.к. не было ошибки и нечего делать

    update_parts.append("last_update_ts = CURRENT_TIMESTAMP") # Всегда обновляем время

    try:
        conn = await get_connection()
        # Сначала пытаемся обновить существующую запись
        sql_update = f"UPDATE chat_settings SET {', '.join(update_parts)} WHERE chat_id = ?"
        params.append(chat_id) # Добавляем chat_id для WHERE
        cursor = await conn.execute(sql_update, tuple(params))
        rows_affected = cursor.rowcount
        await conn.commit() # Коммитим после UPDATE

        if rows_affected > 0:
            logger.info(f"Updated chat settings for chat_id={chat_id}")
            await cursor.close() # Закрываем курсор
            return True
        else:
            # Если не обновилось, значит записи нет - вставляем
            await cursor.close() # Закрываем курсор от UPDATE
            logger.info(f"Settings not found for update chat_id={chat_id}, attempting insert...")

            # Собираем параметры для вставки (только те, что были переданы и валидны)
            insert_fields = ["chat_id", "last_update_ts"]
            insert_placeholders = ["?", "CURRENT_TIMESTAMP"]
            insert_params = [chat_id]

            # Используем исходные значения из аргументов функции
            if custom_prompt is not None:
                insert_fields.append("custom_prompt")
                insert_placeholders.append("?")
                insert_params.append(custom_prompt)
            if ai_mode in [AI_MODE_PRO, AI_MODE_DEFAULT]: # Вставляем только валидный режим
                insert_fields.append("ai_mode")
                insert_placeholders.append("?")
                insert_params.append(ai_mode)
            elif ai_mode is not None: # Если передан невалидный, вставляем дефолтный
                 logger.warning(f"Inserting default AI mode for chat {chat_id} as provided mode '{ai_mode}' was invalid.")
                 insert_fields.append("ai_mode")
                 insert_placeholders.append("?")
                 insert_params.append(AI_MODE_DEFAULT) # Вставляем дефолтный
            # Если ai_mode не передан, будет использовано значение DEFAULT из схемы таблицы

            if gemini_model is not None:
                insert_fields.append("gemini_model")
                insert_placeholders.append("?")
                insert_params.append(gemini_model)

            # Используем INSERT OR IGNORE на случай гонки потоков
            sql_insert = f"INSERT OR IGNORE INTO chat_settings ({', '.join(insert_fields)}) VALUES ({', '.join(insert_placeholders)})"
            cursor = await conn.execute(sql_insert, tuple(insert_params))
            rows_inserted = cursor.rowcount
            await conn.commit() # Коммитим после INSERT
            await cursor.close() # Закрываем курсор

            if rows_inserted > 0:
                logger.info(f"Inserted new chat settings for chat_id={chat_id}")
                return True
            else:
                # Может произойти при одновременной попытке вставки (IGNORE) или если запись уже появилась между UPDATE и INSERT
                logger.warning(f"Failed to insert chat settings for chat_id={chat_id} (maybe race condition or other IGNORE issue). Settings might have been updated by another process.")
                # Попробуем еще раз прочитать настройки, чтобы убедиться
                current_settings = await get_chat_settings(chat_id)
                if current_settings:
                     logger.info(f"Settings for chat {chat_id} seem to exist now. Considering upsert successful despite failed INSERT.")
                     return True # Считаем успехом, если запись теперь есть
                return False # Считаем неудачей, если не обновили и не вставили

    except (aiosqlite.Error, ImportError) as e:
        logger.error(f"Error upserting chat settings for chat_id={chat_id}: {e}", exc_info=True)
        if 'conn' in locals() and conn and not isinstance(e, ImportError):
              try: await conn.rollback()
              except Exception as rb_e: logger.error(f"Rollback failed after settings upsert error: {rb_e}")
        return False
    except Exception as e:
        logger.error(f"Unexpected error upserting chat settings for chat_id={chat_id}: {e}", exc_info=True)
        return False


async def get_chat_settings(chat_id: int) -> Optional[Dict[str, Any]]:
    """
    Получает настройки чата по его ID.
    Возвращает словарь настроек или None, если не найдено или ошибка.
    В словаре будут ключи: chat_id, custom_prompt, ai_mode, gemini_model, last_update_ts.
    """
    if not isinstance(chat_id, int):
        logger.error(f"get_chat_settings: Invalid chat_id: {chat_id}")
        return None

    conn: aiosqlite.Connection
    settings_data: Optional[Dict[str, Any]] = None
    try:
        conn = await get_connection()
        async with conn.execute(
            """
            SELECT chat_id, custom_prompt, ai_mode, gemini_model, last_update_ts
            FROM chat_settings
            WHERE chat_id = ?
            """,
            (chat_id,)
        ) as cursor:
            row = await cursor.fetchone()
            if row:
                settings_data = dict(row)
                logger.debug(f"Retrieved settings for chat_id={chat_id}")
            else:
                logger.debug(f"No settings found for chat_id={chat_id}")

    except (aiosqlite.Error, ImportError) as e:
        logger.error(f"Error getting chat settings for chat_id {chat_id}: {e}", exc_info=True)
    except Exception as e:
        logger.error(f"Unexpected error getting settings for chat_id {chat_id}: {e}", exc_info=True)

    return settings_data


async def delete_chat_settings(chat_id: int) -> bool:
    """
    Удаляет настройки для указанного chat_id.
    Возвращает True при успехе, False если запись не найдена или произошла ошибка.
    """
    if not isinstance(chat_id, int):
        logger.error(f"delete_chat_settings: Invalid chat_id: {chat_id}")
        return False

    conn: aiosqlite.Connection
    success = False
    try:
        conn = await get_connection()
        cursor = await conn.execute("DELETE FROM chat_settings WHERE chat_id = ?", (chat_id,))
        deleted_count = cursor.rowcount
        await conn.commit()
        await cursor.close()

        if deleted_count > 0:
            logger.info(f"Deleted chat settings for chat_id={chat_id}")
            success = True
        else:
            logger.info(f"Settings not found for deletion: chat_id={chat_id}")
            success = False # Запись не найдена, но ошибки не было

    except (aiosqlite.Error, ImportError) as e:
        logger.error(f"Error deleting chat settings for chat_id={chat_id}: {e}", exc_info=True)
        if 'conn' in locals() and conn and not isinstance(e, ImportError):
              try: await conn.rollback()
              except Exception as rb_e: logger.error(f"Rollback failed after settings delete error: {rb_e}")
        success = False
    except Exception as e:
        logger.error(f"Unexpected error deleting settings for chat_id={chat_id}: {e}", exc_info=True)
        success = False

    return success

========== Файл: database\crud_ops\stats.py ==========

# database/crud_ops/stats.py
import aiosqlite
import logging
from typing import List, Tuple, Dict, Optional
from datetime import datetime, timezone

# Используем относительный импорт
try:
    from ..connection import get_connection
except ImportError:
    async def get_connection(): raise ImportError("Connection module not loaded")
    logging.getLogger(__name__).critical("Failed to import get_connection from ..connection")

logger = logging.getLogger(__name__)

# --- Статистика сообщений ---

async def increment_message_count(chat_id: int, user_id: int) -> bool:
    """
    Увеличивает счетчик сообщений для пользователя в чате.
    Создает запись, если ее нет. Использует INSERT ON CONFLICT DO UPDATE.
    Возвращает True при успехе, False при ошибке.
    """
    if not isinstance(chat_id, int) or not isinstance(user_id, int) or user_id <= 0:
        logger.error(f"increment_message_count: Invalid chat_id or user_id: c={chat_id}, u={user_id}")
        return False

    conn: aiosqlite.Connection
    try:
        conn = await get_connection()
        # INSERT OR ... ON CONFLICT ... DO UPDATE - атомарная операция
        await conn.execute('''
            INSERT INTO message_stats (chat_id, user_id, message_count, last_message_ts)
            VALUES (?, ?, 1, CURRENT_TIMESTAMP)
            ON CONFLICT(chat_id, user_id) DO UPDATE SET
                message_count = message_count + 1,
                last_message_ts = CURRENT_TIMESTAMP
            WHERE chat_id = excluded.chat_id AND user_id = excluded.user_id;
        ''', (chat_id, user_id))
        await conn.commit()
        # Не логируем успех, т.к. слишком часто вызывается
        # logger.debug(f"Incremented message count user={user_id}, chat={chat_id}")
        return True
    except (aiosqlite.Error, ImportError) as e:
        logger.error(f"Error incrementing msg count user={user_id}, chat={chat_id}: {e}", exc_info=True)
        if 'conn' in locals() and conn and not isinstance(e, ImportError):
              try: await conn.rollback()
              except Exception as rb_e: logger.error(f"Rollback failed after msg count increment error: {rb_e}")
        return False
    except Exception as e:
         logger.error(f"Unexpected error incrementing msg count user={user_id}, chat={chat_id}: {e}", exc_info=True)
         return False


async def get_chat_stats_top_users(chat_id: int, limit: int = 10) -> List[Tuple[int, int]]:
    """
    Получает топ N пользователей по количеству сообщений в чате.
    Возвращает список кортежей (user_id, message_count) или пустой список.
    """
    if not isinstance(chat_id, int) or not isinstance(limit, int) or limit <= 0:
        logger.error(f"get_chat_stats_top_users: Invalid chat_id or limit: c={chat_id}, l={limit}")
        return []

    conn: aiosqlite.Connection
    top_users: List[Tuple[int, int]] = []
    try:
        conn = await get_connection()
        async with conn.execute(
            """
            SELECT user_id, message_count
            FROM message_stats
            WHERE chat_id = ? AND message_count > 0 -- Исключаем пользователей с 0 сообщений
            ORDER BY message_count DESC
            LIMIT ?
            """,
            (chat_id, limit)
        ) as cursor:
            rows = await cursor.fetchall()
            top_users = [(row['user_id'], row['message_count']) for row in rows]
        logger.debug(f"Retrieved top {len(top_users)} users for chat_id={chat_id}")
    except (aiosqlite.Error, ImportError) as e:
        logger.error(f"Error getting chat stats chat_id={chat_id}: {e}", exc_info=True)
    except Exception as e:
        logger.error(f"Unexpected error getting chat stats chat_id={chat_id}: {e}", exc_info=True)

    return top_users

# --- Предупреждения пользователей ---

async def get_user_warn_count(chat_id: int, user_id: int) -> int:
    """
    Получает текущее количество предупреждений пользователя в чате.
    Возвращает 0, если запись не найдена или произошла ошибка.
    """
    if not isinstance(chat_id, int) or not isinstance(user_id, int) or user_id <= 0:
        logger.error(f"get_user_warn_count: Invalid chat_id or user_id: c={chat_id}, u={user_id}")
        return 0

    conn: aiosqlite.Connection
    count = 0
    try:
        conn = await get_connection()
        async with conn.execute(
            "SELECT warn_count FROM user_warnings WHERE chat_id = ? AND user_id = ?",
            (chat_id, user_id)
        ) as cursor:
            row = await cursor.fetchone()
            if row:
                count = row['warn_count']
    except (aiosqlite.Error, ImportError) as e:
        logger.error(f"Error getting warn count user={user_id}, chat={chat_id}: {e}", exc_info=True)
    except Exception as e:
         logger.error(f"Unexpected error getting warn count user={user_id}, chat={chat_id}: {e}", exc_info=True)
    return count


async def add_user_warning(chat_id: int, user_id: int) -> Optional[int]:
    """
    Добавляет одно предупреждение пользователю в чате.
    Создает запись, если ее нет. Использует INSERT ON CONFLICT DO UPDATE.
    Возвращает НОВОЕ количество предупреждений или None при ошибке.
    """
    if not isinstance(chat_id, int) or not isinstance(user_id, int) or user_id <= 0:
        logger.error(f"add_user_warning: Invalid chat_id or user_id: c={chat_id}, u={user_id}")
        return None

    conn: aiosqlite.Connection
    new_count: Optional[int] = None
    try:
        conn = await get_connection()
        # Атомарное добавление/обновление
        await conn.execute('''
            INSERT INTO user_warnings (chat_id, user_id, warn_count, last_warn_ts)
            VALUES (?, ?, 1, CURRENT_TIMESTAMP)
            ON CONFLICT(chat_id, user_id) DO UPDATE SET
                warn_count = warn_count + 1,
                last_warn_ts = CURRENT_TIMESTAMP
            WHERE chat_id = excluded.chat_id AND user_id = excluded.user_id;
        ''', (chat_id, user_id))
        await conn.commit()

        # Получаем новое значение (надежнее, чем предполагать +1)
        new_count = await get_user_warn_count(chat_id, user_id)
        if new_count is not None: # get_user_warn_count вернет 0 если ошибка, None тут быть не должно
            logger.info(f"Added warning user={user_id}, chat={chat_id}. New count: {new_count}")
        else:
             logger.error(f"Failed to retrieve new warn count after adding user={user_id}, chat={chat_id}")

        return new_count

    except (aiosqlite.Error, ImportError) as e:
        logger.error(f"Error adding warning user={user_id}, chat={chat_id}: {e}", exc_info=True)
        if 'conn' in locals() and conn and not isinstance(e, ImportError):
              try: await conn.rollback()
              except Exception as rb_e: logger.error(f"Rollback failed after adding warning error: {rb_e}")
        return None
    except Exception as e:
         logger.error(f"Unexpected error adding warning user={user_id}, chat={chat_id}: {e}", exc_info=True)
         return None


async def remove_user_warning(chat_id: int, user_id: int, count: int = 1) -> Optional[int]:
    """
    Уменьшает количество предупреждений пользователя на 'count'.
    Не позволяет счетчику уйти ниже нуля.
    Возвращает НОВОЕ количество предупреждений или None при ошибке.
    """
    if not isinstance(chat_id, int) or not isinstance(user_id, int) or user_id <= 0 or not isinstance(count, int) or count <= 0:
        logger.error(f"remove_user_warning: Invalid params: c={chat_id}, u={user_id}, count={count}")
        return None

    conn: aiosqlite.Connection
    new_count: Optional[int] = None
    try:
        conn = await get_connection()
        # Обновляем, используя MAX(0, ...)
        # Обновляем только если есть что уменьшать (warn_count > 0)
        cursor = await conn.execute(
            """
            UPDATE user_warnings
            SET warn_count = MAX(0, warn_count - ?),
                last_warn_ts = CURRENT_TIMESTAMP
            WHERE chat_id = ? AND user_id = ? AND warn_count > 0;
            """,
            (count, chat_id, user_id)
        )
        rows_affected = cursor.rowcount
        await conn.commit()
        await cursor.close()

        # Получаем новое значение
        new_count = await get_user_warn_count(chat_id, user_id)
        if new_count is not None:
            if rows_affected > 0:
                logger.info(f"Removed {count} warning(s) user={user_id}, chat={chat_id}. New count: {new_count}")
            else:
                 logger.info(f"No warnings to remove or user not found user={user_id}, chat={chat_id}. Current count: {new_count}")
        else:
             logger.error(f"Failed to retrieve new warn count after removing user={user_id}, chat={chat_id}")

        return new_count

    except (aiosqlite.Error, ImportError) as e:
        logger.error(f"Error removing warning user={user_id}, chat={chat_id}: {e}", exc_info=True)
        if 'conn' in locals() and conn and not isinstance(e, ImportError):
              try: await conn.rollback()
              except Exception as rb_e: logger.error(f"Rollback failed after removing warning error: {rb_e}")
        return None
    except Exception as e:
         logger.error(f"Unexpected error removing warning user={user_id}, chat={chat_id}: {e}", exc_info=True)
         return None


async def get_chat_warnings(chat_id: int) -> Dict[int, int]:
    """
    Получает словарь {user_id: warn_count} для всех пользователей с варнами > 0 в чате.
    Возвращает пустой словарь при ошибке или отсутствии варнов.
    """
    if not isinstance(chat_id, int):
        logger.error(f"get_chat_warnings: Invalid chat_id: {chat_id}")
        return {}

    conn: aiosqlite.Connection
    warnings_dict: Dict[int, int] = {}
    try:
        conn = await get_connection()
        async with conn.execute(
            "SELECT user_id, warn_count FROM user_warnings WHERE chat_id = ? AND warn_count > 0 ORDER BY user_id",
            (chat_id,)
        ) as cursor:
            rows = await cursor.fetchall()
            warnings_dict = {row['user_id']: row['warn_count'] for row in rows}
        logger.debug(f"Retrieved {len(warnings_dict)} users with warnings for chat_id={chat_id}")
    except (aiosqlite.Error, ImportError) as e:
        logger.error(f"Error getting chat warnings chat_id={chat_id}: {e}", exc_info=True)
    except Exception as e:
        logger.error(f"Unexpected error getting chat warnings chat_id={chat_id}: {e}", exc_info=True)

    return warnings_dict


async def reset_user_warnings(chat_id: int, user_id: int) -> bool:
    """
    Сбрасывает счетчик предупреждений пользователя в чате до 0 (удаляет запись).
    Возвращает True при успехе (даже если записи не было), False при ошибке БД.
    """
    if not isinstance(chat_id, int) or not isinstance(user_id, int) or user_id <= 0:
        logger.error(f"reset_user_warnings: Invalid chat_id or user_id: c={chat_id}, u={user_id}")
        return False

    conn: aiosqlite.Connection
    success = False
    try:
        conn = await get_connection()
        cursor = await conn.execute("DELETE FROM user_warnings WHERE chat_id = ? AND user_id = ?", (chat_id, user_id))
        deleted_count = cursor.rowcount
        await conn.commit()
        await cursor.close()
        if deleted_count > 0:
            logger.info(f"Reset warnings for user={user_id} in chat={chat_id}")
            success = True
        else:
            # Если записи не было, это тоже успех (счетчик уже 0)
            logger.info(f"No warnings found to reset for user={user_id} in chat={chat_id}")
            success = True
    except (aiosqlite.Error, ImportError) as e:
        logger.error(f"Error resetting warnings user={user_id}, chat={chat_id}: {e}", exc_info=True)
        if 'conn' in locals() and conn and not isinstance(e, ImportError):
              try: await conn.rollback()
              except Exception as rb_e: logger.error(f"Rollback failed after resetting warnings error: {rb_e}")
        success = False
    except Exception as e:
         logger.error(f"Unexpected error resetting warnings user={user_id}, chat={chat_id}: {e}", exc_info=True)
         success = False
    return success

========== Файл: database\crud_ops\__init__.py ==========

# database/crud_ops/__init__.py

# Импортируем основные функции для удобного доступа
# Например: from database.crud_ops import history, profiles, ...

from .history import (
    add_message_to_history,
    get_chat_history,
    clear_chat_history
)
from .profiles import (
    upsert_user_profile,
    get_user_profile,
    update_avatar_description,
    find_user_id_by_profile
)

from .feedback import ( # <<< Добавляем
    add_developer_feedback
)

from .notes import (
    upsert_user_note,
    get_user_notes,
    delete_user_note,
    delete_user_note_nested,
    get_user_data_combined
)
from .settings import (
    upsert_chat_settings,
    get_chat_settings,
    delete_chat_settings,
    AI_MODE_PRO, # Экспортируем константы
    AI_MODE_DEFAULT
)
from .news import (
    add_or_update_subscription,
    get_subscription,
    get_all_subscriptions,
    update_subscription_last_post,
    delete_subscription,
    add_sent_guid,
    is_guid_sent,
    load_recent_sent_guids,
    cleanup_old_guids
)
from .stats import (
    increment_message_count,
    get_chat_stats_top_users,
    get_user_warn_count,
    add_user_warning,
    remove_user_warning,
    get_chat_warnings,
    reset_user_warnings
)

# Импорт из нового модуля логов
from .execution_logs import (
    add_tool_execution_log,
    get_recent_tool_executions
)

# Можно определить __all__ для явного экспорта
__all__ = [
    # history
    "add_message_to_history", "get_chat_history", "clear_chat_history",
    # profiles
    "upsert_user_profile", "get_user_profile", "update_avatar_description", "find_user_id_by_profile",
    # notes
    "upsert_user_note", "get_user_notes", "delete_user_note", "delete_user_note_nested", "get_user_data_combined",
    # settings
    "upsert_chat_settings", "get_chat_settings", "delete_chat_settings", "AI_MODE_PRO", "AI_MODE_DEFAULT",
    # news
    "add_or_update_subscription", "get_subscription", "get_all_subscriptions", "update_subscription_last_post",
    "delete_subscription", "add_sent_guid", "is_guid_sent", "load_recent_sent_guids", "cleanup_old_guids",
    # stats
    "increment_message_count", "get_chat_stats_top_users", "get_user_warn_count", "add_user_warning",
    "remove_user_warning", "get_chat_warnings", "reset_user_warnings",
    # execution_logs
    "add_tool_execution_log", "get_recent_tool_executions", "add_developer_feedback"

]

========== Файл: database\migrations\__init__.py ==========



========== Файл: declarations\lite_functions.json ==========

[] 

========== Файл: declarations\pro_functions.json ==========

[
  {
    "name": "send_telegram_message",
    "description": "[CRITICAL] Sends a text message to the user in the current chat. Use this function for ALL textual communication directed at the user, including greetings, answers, confirmations, results, errors, and asking questions. Use sequential calls if you need to send multiple messages. Set 'requires_user_response' to true ONLY if you need the user to reply before you can proceed.",
    "parameters": {
      "type": "OBJECT",
      "properties": {
        "text": {
          "type": "STRING",
          "description": "The content of the message to send to the user. Must be plain text."
        },
        "delay_seconds": {
          "type": "INTEGER",
          "description": "(Optional) Delay in seconds before sending the message. Useful for creating pauses or simulating thought."
        },
        "requires_user_response": {
          "type": "BOOLEAN",
          "description": "(Optional) Set to 'true' ONLY if this message is a question or confirmation that requires an immediate user response before executing subsequent actions or function calls. Defaults to 'false' if omitted. For sequences of messages (like multiple questions or steps), set to 'false'."
        }
      },
      "required": ["text"]
    }
  },
  {
    "name": "find_user_id",
    "description": "[ESSENTIAL] Searches the database for a user's unique ID (`user_id`) based on their first name or username (e.g., 'John Doe' or '@johndoe'). Returns the user_id if found. This is often necessary before using functions that require a specific user_id like `remember_user_info` or `reading_user_info` when targeting someone other than the current user.",
    "parameters": {
      "type": "OBJECT",
      "properties": {
        "query": {
          "type": "STRING",
          "description": "The user's first name or username to search for. The '@' symbol is optional for usernames."
        }
      },
      "required": ["query"]
    }
  },
  {
    "name": "remember_user_info",
    "description": "[MEMORY] Saves or updates a piece of information (a note or fact) about ANY user in the persistent database, identified by their `user_id`. If the current user's ID is provided, saves info about them. If another user's ID is provided, saves info about that user. Use this to store preferences, facts, reminders, etc.",
    "parameters": {
      "type": "OBJECT",
      "properties": {
        "user_id": {
          "type": "INTEGER",
          "description": "The unique ID of the user for whom the information is being saved."
        },
        "info_category": {
          "type": "STRING",
          "description": "A category for the information (e.g., 'hobby', 'location', 'reminder', 'preferred_language'). Acts like a key."
        },
        "info_value": {
          "type": "STRING",
          "description": "The actual information to store. Can be plain text or a JSON string for lists/dictionaries (e.g., '\"Loves hiking\"', '[\"python\", \"javascript\"]', '{\"city\": \"London\", \"country\": \"UK\"}'). Ensure JSON strings are valid."
        },
        "merge_lists": {
          "type": "BOOLEAN",
          "description": "(Optional) If True (default) and `info_value` is a JSON list/dictionary, attempts to merge with existing data in that category instead of overwriting. If False, overwrites."
        }
      },
      "required": ["user_id", "info_category", "info_value"]
    }
  },
  {
    "name": "reading_user_info",
    "description": "[MEMORY] Retrieves all known information (profile data + stored notes/facts from `remember_user_info`) about ANY user, identified by their `user_id`.",
    "parameters": {
      "type": "OBJECT",
      "properties": {
        "user_id": {
          "type": "INTEGER",
          "description": "The unique ID of the user whose information needs to be retrieved."
        }
      },
      "required": ["user_id"]
    }
  },
  {
    "name": "forget_user_info",
    "description": "[MEMORY] Deletes specific stored information (a note/fact) about ANY user from the database, identified by `user_id`. Can delete an entire category, a specific key within a JSON dictionary category, or a specific item within a JSON list category.",
    "parameters": {
      "type": "OBJECT",
      "properties": {
        "user_id": {
          "type": "INTEGER",
          "description": "The unique ID of the user whose information needs to be deleted."
        },
        "info_category": {
          "type": "STRING",
          "description": "The category of information to delete from."
        },
        "key": {
          "type": "STRING",
          "description": "(Optional) If the `info_category` stores a JSON dictionary, specify the key to remove."
        },
        "list_item": {
          "type": "STRING",
          "description": "(Optional) If the `info_category` stores a JSON list, specify the exact string value of the item to remove."
        }
      },
      "required": ["user_id", "info_category"]
    }
  },
  {
    "name": "Developer_Feedback",
    "description": "[META] Use this function ONLY to report operational issues, suspected bugs, limitations, or suggestions directly to the bot developer/administrator. Specify the importance, a brief reason/category, and a detailed description. DO NOT use this for regular user interaction or responding to user queries.",
    "parameters": {
      "type": "OBJECT",
      "properties": {
        "Degree_of_importance": {
          "type": "STRING",
          "description": "Severity or type of the feedback. Recommended values: 'critical', 'high', 'medium', 'low', 'suggestion'."
        },
        "Reason": {
          "type": "STRING",
          "description": "A brief category or reason for the feedback (e.g., 'Tool Error', 'Unexpected Behavior', 'API Limit Reached', 'Prompt Suggestion', 'Feature Request')."
        },
        "Problem": {
          "type": "STRING",
          "description": "A detailed description of the issue, observation, or suggestion."
        }
      },
      "required": ["Degree_of_importance", "Reason", "Problem"]
    }
  },
  {
      "name": "execute_terminal_command_in_env",
      "description": "[POWERFUL ENV TOOL] Executes a raw shell command within the user's chat environment's terminal (working directory). Use cautiously for essential file system operations like listing files (`ls -la`), checking the current directory (`pwd`), reading small files (`cat filename.txt`), creating directories (`mkdir dirname`), checking disk usage (`df -h`), etc. Avoid potentially harmful or long-running commands (e.g., `rm -rf`, network scans, complex scripts) unless absolutely necessary and confirmed. Admins might have elevated permissions to operate in other chat directories. The command runs directly as provided.",
      "parameters": {
        "type": "OBJECT",
        "properties": {
          "command": {
            "type": "STRING",
            "description": "The shell command to execute (e.g., 'ls -la work_files/', 'pwd', 'cat config.json')."
          }
        },
        "required": ["command"]
      }
  },
  {
    "name": "read_file_from_env",
    "description": "[ENV TOOL] Reads the entire content of a specified file from the chat's environment storage and returns it as a string. Useful for accessing notes, data files, code, configuration, etc. Specify the full path if needed. Admins might be able to read files from other chat directories (e.g., using paths like '-100.../file.txt').",
    "parameters": {
      "type": "OBJECT",
      "properties": {
        "filename": {
          "type": "STRING",
          "description": "Path to the file to read (e.g., 'my_notes.txt', 'data/input.csv', '../shared/config.yaml', '-100123456789/script.py')."
        }
      },
      "required": ["filename"]
    }
  },
  {
    "name": "write_file_to_env",
    "description": "[ENV TOOL] Writes (or overwrites) the given text content to a specified file in the chat's environment storage. Useful for saving notes, results, generated code, configuration, etc. Ensure the content is appropriate for the file type. Admins might have permissions to write files in other chat directories.",
    "parameters": {
      "type": "OBJECT",
      "properties": {
        "filename": {
          "type": "STRING",
          "description": "Path and name of the file to write to (e.g., 'results.txt', 'output/data.json', 'script.py')."
        },
        "content": {
          "type": "STRING",
          "description": "The full text content to write into the file."
        }
      },
      "required": ["filename", "content"]
    }
  },
  {
    "name": "edit_file_content",
    "description": "[ENV TOOL] Edits a text file within the chat environment by replacing ALL occurrences of a specific string with another string. Useful for simple bulk replacements in configuration files or text documents. Admins might have permissions to edit files in other chat directories.",
    "parameters": {
      "type": "OBJECT",
      "properties": {
        "filename": {
          "type": "STRING",
          "description": "Path to the file to edit."
        },
        "search_string": {
          "type": "STRING",
          "description": "The exact string to find within the file."
        },
        "replace_string": {
          "type": "STRING",
          "description": "The string to replace each occurrence of `search_string` with."
        }
      },
      "required": ["filename", "search_string", "replace_string"]
    }
  },
  {
    "name": "edit_json_file",
    "description": "[ENV TOOL] Edits a specific value within a JSON file in the chat environment using a JSONPath expression. Reads the JSON, modifies the value at the specified path, and overwrites the file. Admins might have permissions to edit files in other chat directories.",
    "parameters": {
      "type": "OBJECT",
      "properties": {
        "filename": {
          "type": "STRING",
          "description": "Path to the JSON file (.json) to edit."
        },
        "json_path": {
          "type": "STRING",
          "description": "JSONPath expression to locate the value to modify (e.g., '$.user.name', '$.items[0].price', '$.config.settings.enabled'). Use single quotes or escaped double quotes inside the path if needed for keys with special characters: '$.user[\"first-name\"]'."
        },
        "new_value_json": {
          "type": "STRING",
          "description": "The new value to set, formatted as a valid JSON string (e.g., '\"New Name\"', '123.45', 'true', '[\"a\", \"b\"]', '{\"new_key\": \"new_value\"}'). String values inside JSON MUST use double quotes."
        }
      },
      "required": ["filename", "json_path", "new_value_json"]
    }
  },
   {
    "name": "create_file_in_env",
    "description": "[ENV TOOL] Creates a new, empty file at the specified path in the chat's environment storage. Useful for initializing log files, scripts, or data files before writing to them. Fails if the file already exists. Admins might have permissions to create files in other chat directories.",
    "parameters": {
      "type": "OBJECT",
      "properties": {
        "filename": {
          "type": "STRING",
          "description": "Path and name for the new file to create (e.g., 'new_log.txt', 'scripts/init.py')."
        }
      },
      "required": ["filename"]
    }
  },
  {
    "name": "execute_python_script_in_env",
    "description": "[ENV TOOL] Executes a Python script (.py file) located within the chat's environment storage. The script runs within the context of the environment. Use this to perform complex logic, data processing, or automation tasks defined in a Python file. Ensure the script exists and is safe to run. Admins might have permissions to execute scripts from other chat directories.",
    "parameters": {
      "type": "OBJECT",
      "properties": {
        "filename": {
          "type": "STRING",
          "description": "Path to the Python script file (.py) to execute (e.g., 'process_data.py', 'utils/helper.py')."
        }
      },
      "required": ["filename"]
    }
  },
  {
    "name": "refine_text_with_deep_search",
    "description": "[ADVANCED CONTENT] Use this tool for in-depth research on a topic or significantly improving existing text. It performs web searches to gather information, then uses multiple AI steps to generate clarifying questions, find answers, and synthesize a comprehensive final report or refined text. Suitable for complex queries or when high-quality, detailed output is required.",
    "parameters": {
      "type": "OBJECT",
      "properties": {
        "initial_query_or_text": {
          "type": "STRING",
          "description": "The initial topic query (e.g., 'Explain quantum computing') or the existing text passage to be improved and expanded upon."
        },
        "max_iterations": {
          "type": "INTEGER",
          "description": "(Optional) Maximum number of research/refinement iterations (default is 3). More iterations lead to deeper research but take longer."
        }
      },
      "required": ["initial_query_or_text"]
    }
  },
  {
    "name": "get_current_weather",
    "description": "[EXTERNAL DATA] Fetches the current weather conditions for a specified location.",
    "parameters": {
      "type": "OBJECT",
      "properties": {
        "location": {
          "type": "STRING",
          "description": "The city or location name (e.g., 'Moscow', 'London, UK', 'San Francisco, CA'). Be specific for better accuracy."
        },
        "unit": {
          "type": "STRING",
          "description": "Temperature unit: 'celsius' or 'fahrenheit'. Defaults to 'celsius'."
        }
      },
      "required": ["location"]
    }
  },
  {
    "name": "get_stock_price",
    "description": "[EXTERNAL DATA] Retrieves the current price for a publicly traded stock using its ticker symbol.",
    "parameters": {
      "type": "OBJECT",
      "properties": {
        "ticker_symbol": {
          "type": "STRING",
          "description": "The stock's ticker symbol (e.g., 'GOOGL', 'AAPL', 'MSFT', 'YNDX.ME'). Ensure the correct symbol for the market."
        }
      },
      "required": ["ticker_symbol"]
    }
  },
   {
    "name": "get_music_charts",
    "description": "[EXTERNAL DATA] Fetches top music tracks from a specified chart source (e.g., Yandex.Music).",
    "parameters": {
      "type": "OBJECT",
      "properties": {
        "source": {
          "type": "STRING",
          "description": "The source of the music chart (e.g., 'yandex'). Check available sources."
        },
        "limit": {
          "type": "INTEGER",
          "description": "Maximum number of tracks to return (default 10)."
        }
      },
      "required": ["source"]
    }
  },
  {
    "name": "send_file_from_env",
    "description": "[ENV TOOL] Sends a specified file from the chat's environment storage directly to the user in the current chat. Use this to provide requested files, logs, script outputs, etc. Admins might be able to send files from other chat directories.",
    "parameters": {
      "type": "OBJECT",
      "properties": {
        "filename": {
          "type": "STRING",
          "description": "Path to the file within the environment storage to send (e.g., 'results.txt', 'logs/debug.log', '../shared_data/report.pdf')."
        }
      },
      "required": ["filename"]
    }
  },
  {
    "name": "get_avatar_description",
    "description": "[USER INFO] Retrieves a textual description of a user's avatar (profile picture). It first checks if a description was previously generated and saved. If not, it may trigger a request to generate a new description using a vision model (if available and feasible).",
    "parameters": {
      "type": "OBJECT",
      "properties": {
        "user_id": {
          "type": "INTEGER",
          "description": "The unique ID of the user whose avatar description is needed."
        }
      },
      "required": ["user_id"]
    }
  },
  {
    "name": "generate_image_description",
    "description": "[VISION TOOL] Generates a textual description for a given image. This tool is primarily used internally by other functions like `get_avatar_description` when a description needs to be created on-demand. It requires the image data itself.",
    "parameters": {
      "type": "OBJECT",
      "properties": {
        "image_bytes": {
          "type": "STRING",
          "description": "The image encoded as a Base64 string. Do not call this directly unless you have the image bytes."
        },
         "prompt": {
            "type": "STRING",
            "description": "(Optional) A specific prompt or context to guide the description generation (e.g., 'Focus on the main subject', 'Describe the style')."
          }
      },
      "required": ["image_bytes"]
    }
  }
]

========== Файл: logs\bot_44.log ==========

2025-04-28 12:34:25 - INFO - __main__ - --- Bot Startup Sequence Initiated ---
2025-04-28 12:34:25 - INFO - __main__ - Startup and shutdown handlers registered.
2025-04-28 12:34:25 - INFO - __main__ - Attempting to delete webhook and drop pending updates...
2025-04-28 12:34:26 - INFO - __main__ - Webhook deleted and pending updates dropped successfully.
2025-04-28 12:34:26 - INFO - __main__ - Starting bot polling...
2025-04-28 12:34:26 - INFO - bot_lifecycle - Executing bot startup sequence...
2025-04-28 12:34:26 - INFO - bot_lifecycle - Found 6 Google API keys.
2025-04-28 12:34:26 - INFO - database.connection - Initializing database schema...
2025-04-28 12:34:26 - INFO - database.connection - Database path configured to: /root/AgentTG/database/bot_db.sqlite
2025-04-28 12:34:26 - INFO - database.connection - Ensured database directory exists: /root/AgentTG/database
2025-04-28 12:34:26 - DEBUG - aiosqlite - executing <function connect.<locals>.connector at 0x7f841b6e7ac0>
2025-04-28 12:34:26 - DEBUG - aiosqlite - operation <function connect.<locals>.connector at 0x7f841b6e7ac0> completed
2025-04-28 12:34:26 - DEBUG - aiosqlite - executing functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, 'PRAGMA foreign_keys = ON;', [])
2025-04-28 12:34:26 - DEBUG - aiosqlite - operation functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, 'PRAGMA foreign_keys = ON;', []) completed
2025-04-28 12:34:26 - DEBUG - aiosqlite - executing functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, 'PRAGMA busy_timeout = 5000;', [])
2025-04-28 12:34:26 - DEBUG - aiosqlite - operation functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, 'PRAGMA busy_timeout = 5000;', []) completed
2025-04-28 12:34:26 - DEBUG - aiosqlite - executing functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, 'PRAGMA journal_mode=WAL;', [])
2025-04-28 12:34:26 - DEBUG - aiosqlite - operation functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, 'PRAGMA journal_mode=WAL;', []) completed
2025-04-28 12:34:26 - INFO - database.connection - SQLite WAL mode enabled.
2025-04-28 12:34:26 - DEBUG - aiosqlite - executing functools.partial(<built-in method commit of sqlite3.Connection object at 0x7f841c62b140>)
2025-04-28 12:34:26 - DEBUG - aiosqlite - operation functools.partial(<built-in method commit of sqlite3.Connection object at 0x7f841c62b140>) completed
2025-04-28 12:34:26 - INFO - database.connection - Database connection established to /root/AgentTG/database/bot_db.sqlite with busy_timeout=5000ms. Connection object ID: 140205373025024
2025-04-28 12:34:26 - DEBUG - database.connection - Executing CREATE TABLE user_profiles...
2025-04-28 12:34:26 - DEBUG - aiosqlite - executing functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, '\n            CREATE TABLE IF NOT EXISTS user_profiles (\n                user_id INTEGER PRIMARY KEY,\n                username TEXT,\n                first_name TEXT,\n                last_name TEXT,\n                last_seen DATETIME DEFAULT CURRENT_TIMESTAMP,\n                avatar_file_id TEXT,\n                avatar_description TEXT\n            );\n        ', [])
2025-04-28 12:34:26 - DEBUG - aiosqlite - operation functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, '\n            CREATE TABLE IF NOT EXISTS user_profiles (\n                user_id INTEGER PRIMARY KEY,\n                username TEXT,\n                first_name TEXT,\n                last_name TEXT,\n                last_seen DATETIME DEFAULT CURRENT_TIMESTAMP,\n                avatar_file_id TEXT,\n                avatar_description TEXT\n            );\n        ', []) completed
2025-04-28 12:34:26 - DEBUG - database.connection - Checked/Created table: user_profiles
2025-04-28 12:34:26 - DEBUG - database.connection - Executing CREATE TABLE user_notes...
2025-04-28 12:34:26 - DEBUG - aiosqlite - executing functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, '\n            CREATE TABLE IF NOT EXISTS user_notes (\n                note_id INTEGER PRIMARY KEY AUTOINCREMENT,\n                user_id INTEGER NOT NULL,\n                category TEXT NOT NULL COLLATE NOCASE, -- Категория без учета регистра\n                value TEXT NOT NULL,\n                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,\n                FOREIGN KEY (user_id) REFERENCES user_profiles(user_id) ON DELETE CASCADE,\n                UNIQUE (user_id, category) -- Уникальная пара пользователь-категория\n            );\n        ', [])
2025-04-28 12:34:26 - DEBUG - aiosqlite - operation functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, '\n            CREATE TABLE IF NOT EXISTS user_notes (\n                note_id INTEGER PRIMARY KEY AUTOINCREMENT,\n                user_id INTEGER NOT NULL,\n                category TEXT NOT NULL COLLATE NOCASE, -- Категория без учета регистра\n                value TEXT NOT NULL,\n                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,\n                FOREIGN KEY (user_id) REFERENCES user_profiles(user_id) ON DELETE CASCADE,\n                UNIQUE (user_id, category) -- Уникальная пара пользователь-категория\n            );\n        ', []) completed
2025-04-28 12:34:26 - DEBUG - database.connection - Executing CREATE INDEX idx_user_notes_user_id...
2025-04-28 12:34:26 - DEBUG - aiosqlite - executing functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, 'CREATE INDEX IF NOT EXISTS idx_user_notes_user_id ON user_notes (user_id);', [])
2025-04-28 12:34:26 - DEBUG - aiosqlite - operation functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, 'CREATE INDEX IF NOT EXISTS idx_user_notes_user_id ON user_notes (user_id);', []) completed
2025-04-28 12:34:26 - DEBUG - database.connection - Checked/Created table and index: user_notes
2025-04-28 12:34:26 - DEBUG - database.connection - Executing CREATE TABLE chat_history...
2025-04-28 12:34:26 - DEBUG - aiosqlite - executing functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, "\n            CREATE TABLE IF NOT EXISTS chat_history (\n                id INTEGER PRIMARY KEY AUTOINCREMENT,\n                chat_id INTEGER NOT NULL,\n                role TEXT NOT NULL CHECK(role IN ('user', 'model', 'system', 'function')),\n                user_id INTEGER, -- NULL для 'model', 'system' и 'function'\n                parts_json TEXT NOT NULL,\n                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,\n                FOREIGN KEY (user_id) REFERENCES user_profiles(user_id) ON DELETE SET NULL -- При удалении профиля ставим NULL\n            );\n        ", [])
2025-04-28 12:34:26 - DEBUG - aiosqlite - operation functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, "\n            CREATE TABLE IF NOT EXISTS chat_history (\n                id INTEGER PRIMARY KEY AUTOINCREMENT,\n                chat_id INTEGER NOT NULL,\n                role TEXT NOT NULL CHECK(role IN ('user', 'model', 'system', 'function')),\n                user_id INTEGER, -- NULL для 'model', 'system' и 'function'\n                parts_json TEXT NOT NULL,\n                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,\n                FOREIGN KEY (user_id) REFERENCES user_profiles(user_id) ON DELETE SET NULL -- При удалении профиля ставим NULL\n            );\n        ", []) completed
2025-04-28 12:34:26 - DEBUG - database.connection - Executing CREATE INDEX idx_chat_history_chat_id_ts...
2025-04-28 12:34:26 - DEBUG - aiosqlite - executing functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, 'CREATE INDEX IF NOT EXISTS idx_chat_history_chat_id_ts ON chat_history (chat_id, timestamp);', [])
2025-04-28 12:34:26 - DEBUG - aiosqlite - operation functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, 'CREATE INDEX IF NOT EXISTS idx_chat_history_chat_id_ts ON chat_history (chat_id, timestamp);', []) completed
2025-04-28 12:34:26 - DEBUG - database.connection - Checked/Created table and index: chat_history
2025-04-28 12:34:26 - DEBUG - database.connection - Executing CREATE TABLE chat_settings...
2025-04-28 12:34:26 - DEBUG - aiosqlite - executing functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, "\n            CREATE TABLE IF NOT EXISTS chat_settings (\n                chat_id INTEGER PRIMARY KEY,\n                custom_prompt TEXT,\n                ai_mode TEXT DEFAULT 'pro', -- 'default' (g4f) или 'pro' (gemini)\n                gemini_model TEXT,          -- Имя конкретной модели Gemini\n                last_update_ts DATETIME DEFAULT CURRENT_TIMESTAMP\n            );\n        ", [])
2025-04-28 12:34:26 - DEBUG - aiosqlite - operation functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, "\n            CREATE TABLE IF NOT EXISTS chat_settings (\n                chat_id INTEGER PRIMARY KEY,\n                custom_prompt TEXT,\n                ai_mode TEXT DEFAULT 'pro', -- 'default' (g4f) или 'pro' (gemini)\n                gemini_model TEXT,          -- Имя конкретной модели Gemini\n                last_update_ts DATETIME DEFAULT CURRENT_TIMESTAMP\n            );\n        ", []) completed
2025-04-28 12:34:26 - DEBUG - database.connection - Checked/Created table: chat_settings
2025-04-28 12:34:26 - DEBUG - database.connection - Executing CREATE TABLE news_subscriptions...
2025-04-28 12:34:26 - DEBUG - aiosqlite - executing functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, '\n            CREATE TABLE IF NOT EXISTS news_subscriptions (\n                subscription_id INTEGER PRIMARY KEY AUTOINCREMENT,\n                channel_id INTEGER NOT NULL UNIQUE, -- ID канала Telegram\n                topics_json TEXT NOT NULL,          -- Список тем в JSON\n                schedule_json TEXT NOT NULL,        -- Список времени в JSON\n                last_post_ts DATETIME             -- Время последней успешной отправки\n            );\n        ', [])
2025-04-28 12:34:26 - DEBUG - aiosqlite - operation functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, '\n            CREATE TABLE IF NOT EXISTS news_subscriptions (\n                subscription_id INTEGER PRIMARY KEY AUTOINCREMENT,\n                channel_id INTEGER NOT NULL UNIQUE, -- ID канала Telegram\n                topics_json TEXT NOT NULL,          -- Список тем в JSON\n                schedule_json TEXT NOT NULL,        -- Список времени в JSON\n                last_post_ts DATETIME             -- Время последней успешной отправки\n            );\n        ', []) completed
2025-04-28 12:34:26 - DEBUG - database.connection - Executing CREATE INDEX idx_news_subs_channel...
2025-04-28 12:34:26 - DEBUG - aiosqlite - executing functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, 'CREATE INDEX IF NOT EXISTS idx_news_subs_channel ON news_subscriptions (channel_id);', [])
2025-04-28 12:34:26 - DEBUG - aiosqlite - operation functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, 'CREATE INDEX IF NOT EXISTS idx_news_subs_channel ON news_subscriptions (channel_id);', []) completed
2025-04-28 12:34:26 - DEBUG - database.connection - Checked/Created table and index: news_subscriptions
2025-04-28 12:34:26 - DEBUG - database.connection - Executing CREATE TABLE sent_news_guids...
2025-04-28 12:34:26 - DEBUG - aiosqlite - executing functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, '\n            CREATE TABLE IF NOT EXISTS sent_news_guids (\n                guid TEXT PRIMARY KEY,\n                sent_ts DATETIME DEFAULT CURRENT_TIMESTAMP\n            );\n        ', [])
2025-04-28 12:34:26 - DEBUG - aiosqlite - operation functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, '\n            CREATE TABLE IF NOT EXISTS sent_news_guids (\n                guid TEXT PRIMARY KEY,\n                sent_ts DATETIME DEFAULT CURRENT_TIMESTAMP\n            );\n        ', []) completed
2025-04-28 12:34:26 - DEBUG - database.connection - Executing CREATE INDEX idx_sent_guids_ts...
2025-04-28 12:34:26 - DEBUG - aiosqlite - executing functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, 'CREATE INDEX IF NOT EXISTS idx_sent_guids_ts ON sent_news_guids (sent_ts);', [])
2025-04-28 12:34:26 - DEBUG - aiosqlite - operation functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, 'CREATE INDEX IF NOT EXISTS idx_sent_guids_ts ON sent_news_guids (sent_ts);', []) completed
2025-04-28 12:34:26 - DEBUG - database.connection - Checked/Created table and index: sent_news_guids
2025-04-28 12:34:26 - DEBUG - database.connection - Executing CREATE TABLE message_stats...
2025-04-28 12:34:26 - DEBUG - aiosqlite - executing functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, '\n            CREATE TABLE IF NOT EXISTS message_stats (\n                stat_id INTEGER PRIMARY KEY AUTOINCREMENT,\n                chat_id INTEGER NOT NULL,\n                user_id INTEGER NOT NULL,\n                message_count INTEGER DEFAULT 0,\n                last_message_ts DATETIME DEFAULT CURRENT_TIMESTAMP\n                -- Убираем FOREIGN KEY для теста\n                -- FOREIGN KEY (user_id) REFERENCES user_profiles(user_id) ON DELETE CASCADE,\n                -- UNIQUE (chat_id, user_id) -- Уникальная пара чат-пользователь\n            );\n        ', [])
2025-04-28 12:34:26 - DEBUG - aiosqlite - operation functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, '\n            CREATE TABLE IF NOT EXISTS message_stats (\n                stat_id INTEGER PRIMARY KEY AUTOINCREMENT,\n                chat_id INTEGER NOT NULL,\n                user_id INTEGER NOT NULL,\n                message_count INTEGER DEFAULT 0,\n                last_message_ts DATETIME DEFAULT CURRENT_TIMESTAMP\n                -- Убираем FOREIGN KEY для теста\n                -- FOREIGN KEY (user_id) REFERENCES user_profiles(user_id) ON DELETE CASCADE,\n                -- UNIQUE (chat_id, user_id) -- Уникальная пара чат-пользователь\n            );\n        ', []) completed
2025-04-28 12:34:26 - DEBUG - database.connection - Executing CREATE INDEX idx_msg_stats_chat_user...
2025-04-28 12:34:26 - DEBUG - aiosqlite - executing functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, 'CREATE INDEX IF NOT EXISTS idx_msg_stats_chat_user ON message_stats (chat_id, user_id);', [])
2025-04-28 12:34:26 - DEBUG - aiosqlite - operation functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, 'CREATE INDEX IF NOT EXISTS idx_msg_stats_chat_user ON message_stats (chat_id, user_id);', []) completed
2025-04-28 12:34:26 - DEBUG - database.connection - Executing CREATE INDEX idx_msg_stats_chat_count...
2025-04-28 12:34:26 - DEBUG - aiosqlite - executing functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, 'CREATE INDEX IF NOT EXISTS idx_msg_stats_chat_count ON message_stats (chat_id, message_count DESC);', [])
2025-04-28 12:34:26 - DEBUG - aiosqlite - operation functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, 'CREATE INDEX IF NOT EXISTS idx_msg_stats_chat_count ON message_stats (chat_id, message_count DESC);', []) completed
2025-04-28 12:34:26 - DEBUG - database.connection - Checked/Created table and indexes: message_stats
2025-04-28 12:34:26 - DEBUG - database.connection - Executing CREATE TABLE user_warnings...
2025-04-28 12:34:26 - DEBUG - aiosqlite - executing functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, '\n            CREATE TABLE IF NOT EXISTS user_warnings (\n                warn_id INTEGER PRIMARY KEY AUTOINCREMENT,\n                chat_id INTEGER NOT NULL,\n                user_id INTEGER NOT NULL,\n                warn_count INTEGER DEFAULT 0,\n                last_warn_ts DATETIME DEFAULT CURRENT_TIMESTAMP,\n                FOREIGN KEY (user_id) REFERENCES user_profiles(user_id) ON DELETE CASCADE,\n                UNIQUE (chat_id, user_id) -- Уникальная пара чат-пользователь\n            );\n        ', [])
2025-04-28 12:34:26 - DEBUG - aiosqlite - operation functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, '\n            CREATE TABLE IF NOT EXISTS user_warnings (\n                warn_id INTEGER PRIMARY KEY AUTOINCREMENT,\n                chat_id INTEGER NOT NULL,\n                user_id INTEGER NOT NULL,\n                warn_count INTEGER DEFAULT 0,\n                last_warn_ts DATETIME DEFAULT CURRENT_TIMESTAMP,\n                FOREIGN KEY (user_id) REFERENCES user_profiles(user_id) ON DELETE CASCADE,\n                UNIQUE (chat_id, user_id) -- Уникальная пара чат-пользователь\n            );\n        ', []) completed
2025-04-28 12:34:26 - DEBUG - database.connection - Executing CREATE INDEX idx_user_warns_chat_user...
2025-04-28 12:34:26 - DEBUG - aiosqlite - executing functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, 'CREATE INDEX IF NOT EXISTS idx_user_warns_chat_user ON user_warnings (chat_id, user_id);', [])
2025-04-28 12:34:26 - DEBUG - aiosqlite - operation functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, 'CREATE INDEX IF NOT EXISTS idx_user_warns_chat_user ON user_warnings (chat_id, user_id);', []) completed
2025-04-28 12:34:26 - DEBUG - database.connection - Checked/Created table and index: user_warnings
2025-04-28 12:34:26 - DEBUG - database.connection - Executing CREATE TABLE tool_executions...
2025-04-28 12:34:26 - DEBUG - aiosqlite - executing functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, "\n            CREATE TABLE IF NOT EXISTS tool_executions (\n                execution_id INTEGER PRIMARY KEY AUTOINCREMENT,\n                chat_id INTEGER NOT NULL,\n                user_id INTEGER, -- Пользователь, инициировавший взаимодействие (может быть NULL)\n                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,\n                tool_name TEXT NOT NULL,\n                tool_args_json TEXT, -- Аргументы вызова функции в JSON\n                status TEXT NOT NULL CHECK(status IN ('success', 'error', 'not_found', 'warning', 'timeout')),\n                return_code INTEGER, -- Код возврата для команд/скриптов\n                result_message TEXT, -- Сообщение из словаря результата\n                stdout TEXT, -- Стандартный вывод (ограничить длину при записи!)\n                stderr TEXT, -- Стандартный вывод ошибок (ограничить длину при записи!)\n                full_result_json TEXT, \n                trigger_message_id INTEGER -- Опционально: ID сообщения пользователя\n            );\n        ", [])
2025-04-28 12:34:26 - DEBUG - aiosqlite - operation functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, "\n            CREATE TABLE IF NOT EXISTS tool_executions (\n                execution_id INTEGER PRIMARY KEY AUTOINCREMENT,\n                chat_id INTEGER NOT NULL,\n                user_id INTEGER, -- Пользователь, инициировавший взаимодействие (может быть NULL)\n                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,\n                tool_name TEXT NOT NULL,\n                tool_args_json TEXT, -- Аргументы вызова функции в JSON\n                status TEXT NOT NULL CHECK(status IN ('success', 'error', 'not_found', 'warning', 'timeout')),\n                return_code INTEGER, -- Код возврата для команд/скриптов\n                result_message TEXT, -- Сообщение из словаря результата\n                stdout TEXT, -- Стандартный вывод (ограничить длину при записи!)\n                stderr TEXT, -- Стандартный вывод ошибок (ограничить длину при записи!)\n                full_result_json TEXT, \n                trigger_message_id INTEGER -- Опционально: ID сообщения пользователя\n            );\n        ", []) completed
2025-04-28 12:34:26 - DEBUG - database.connection - Executing CREATE INDEX idx_tool_exec_chat_time...
2025-04-28 12:34:26 - DEBUG - aiosqlite - executing functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, 'CREATE INDEX IF NOT EXISTS idx_tool_exec_chat_time ON tool_executions (chat_id, timestamp DESC);', [])
2025-04-28 12:34:26 - DEBUG - aiosqlite - operation functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, 'CREATE INDEX IF NOT EXISTS idx_tool_exec_chat_time ON tool_executions (chat_id, timestamp DESC);', []) completed
2025-04-28 12:34:26 - DEBUG - database.connection - Executing CREATE INDEX idx_tool_exec_tool_name...
2025-04-28 12:34:26 - DEBUG - aiosqlite - executing functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, 'CREATE INDEX IF NOT EXISTS idx_tool_exec_tool_name ON tool_executions (tool_name);', [])
2025-04-28 12:34:26 - DEBUG - aiosqlite - operation functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, 'CREATE INDEX IF NOT EXISTS idx_tool_exec_tool_name ON tool_executions (tool_name);', []) completed
2025-04-28 12:34:26 - DEBUG - database.connection - Checked/Created table and indexes: tool_executions
2025-04-28 12:34:26 - DEBUG - database.connection - Committing schema changes...
2025-04-28 12:34:26 - DEBUG - aiosqlite - executing functools.partial(<built-in method commit of sqlite3.Connection object at 0x7f841c62b140>)
2025-04-28 12:34:26 - DEBUG - aiosqlite - operation functools.partial(<built-in method commit of sqlite3.Connection object at 0x7f841c62b140>) completed
2025-04-28 12:34:26 - INFO - database.connection - Database schema initialization complete.
2025-04-28 12:34:26 - DEBUG - database.connection - Executing CREATE TABLE developer_feedback...
2025-04-28 12:34:26 - DEBUG - aiosqlite - executing functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, "\n            CREATE TABLE IF NOT EXISTS developer_feedback (\n                feedback_id INTEGER PRIMARY KEY AUTOINCREMENT,\n                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,\n                chat_id INTEGER,      -- ID чата, откуда пришел запрос (если применимо)\n                user_id INTEGER,      -- ID пользователя, инициировавшего запрос (если применимо)\n                model_name TEXT,      -- Модель, сгенерировавшая фидбек (опционально)\n                degree_of_importance TEXT NOT NULL CHECK(degree_of_importance IN ('high', 'medium', 'low', 'critical', 'suggestion')), -- Важность\n                reason TEXT NOT NULL, -- Краткая причина/категория\n                problem_description TEXT NOT NULL, -- Детальное описание\n                status TEXT DEFAULT 'new' CHECK(status IN ('new', 'acknowledged', 'in_progress', 'resolved', 'wont_fix')) -- Статус обработки (опционально)\n            );\n        ", [])
2025-04-28 12:34:26 - DEBUG - aiosqlite - operation functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, "\n            CREATE TABLE IF NOT EXISTS developer_feedback (\n                feedback_id INTEGER PRIMARY KEY AUTOINCREMENT,\n                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,\n                chat_id INTEGER,      -- ID чата, откуда пришел запрос (если применимо)\n                user_id INTEGER,      -- ID пользователя, инициировавшего запрос (если применимо)\n                model_name TEXT,      -- Модель, сгенерировавшая фидбек (опционально)\n                degree_of_importance TEXT NOT NULL CHECK(degree_of_importance IN ('high', 'medium', 'low', 'critical', 'suggestion')), -- Важность\n                reason TEXT NOT NULL, -- Краткая причина/категория\n                problem_description TEXT NOT NULL, -- Детальное описание\n                status TEXT DEFAULT 'new' CHECK(status IN ('new', 'acknowledged', 'in_progress', 'resolved', 'wont_fix')) -- Статус обработки (опционально)\n            );\n        ", []) completed
2025-04-28 12:34:26 - DEBUG - database.connection - Executing CREATE INDEX idx_dev_feedback_ts...
2025-04-28 12:34:26 - DEBUG - aiosqlite - executing functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, 'CREATE INDEX IF NOT EXISTS idx_dev_feedback_ts ON developer_feedback (timestamp DESC);', [])
2025-04-28 12:34:26 - DEBUG - aiosqlite - operation functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, 'CREATE INDEX IF NOT EXISTS idx_dev_feedback_ts ON developer_feedback (timestamp DESC);', []) completed
2025-04-28 12:34:26 - DEBUG - database.connection - Executing CREATE INDEX idx_dev_feedback_status...
2025-04-28 12:34:26 - DEBUG - aiosqlite - executing functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, 'CREATE INDEX IF NOT EXISTS idx_dev_feedback_status ON developer_feedback (status);', [])
2025-04-28 12:34:26 - DEBUG - aiosqlite - operation functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, 'CREATE INDEX IF NOT EXISTS idx_dev_feedback_status ON developer_feedback (status);', []) completed
2025-04-28 12:34:26 - DEBUG - database.connection - Checked/Created table and indexes: developer_feedback
2025-04-28 12:34:26 - INFO - bot_lifecycle - Database schema initialized successfully.
2025-04-28 12:34:26 - DEBUG - bot_lifecycle - Short sleep after DB init finished.
2025-04-28 12:34:26 - INFO - bot_lifecycle - News service background task scheduled after DB init.
2025-04-28 12:34:26 - INFO - bot_lifecycle - Loaded 0 items from /root/AgentTG/declarations/lite_functions.json.
2025-04-28 12:34:26 - INFO - bot_lifecycle - Loaded 20 items from /root/AgentTG/declarations/pro_functions.json.
2025-04-28 12:34:26 - INFO - bot_lifecycle - Loaded text file /root/AgentTG/prompts/lite_analyzer.txt (3664 chars).
2025-04-28 12:34:26 - INFO - bot_lifecycle - Loaded text file /root/AgentTG/prompts/pro_assistant.txt (9325 chars).
2025-04-28 12:34:26 - INFO - bot_lifecycle - Initializing models for API key index 0 (...tn6M)
2025-04-28 12:34:26 - DEBUG - bot_lifecycle - genai configured with API key index 0.
2025-04-28 12:34:26 - INFO - ai_interface.gemini_api - Function Calling disabled for model 'gemini-1.5-flash-latest'. No tools created.
2025-04-28 12:34:26 - DEBUG - ai_interface.gemini_api - Applying generation config for 'gemini-1.5-flash-latest': {'temperature': 0.2}
2025-04-28 12:34:26 - DEBUG - ai_interface.gemini_api - Applying safety settings for 'gemini-1.5-flash-latest': [{'category': 'HARM_CATEGORY_HARASSMENT', 'threshold': 'BLOCK_NONE'}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'threshold': 'BLOCK_NONE'}, {'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'threshold': 'BLOCK_NONE'}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'threshold': 'BLOCK_NONE'}]
2025-04-28 12:34:26 - INFO - ai_interface.gemini_api - Applying system instruction for 'gemini-1.5-flash-latest'.
2025-04-28 12:34:26 - INFO - ai_interface.gemini_api - Gemini model 'gemini-1.5-flash-latest' initialized successfully.
2025-04-28 12:34:26 - INFO - bot_lifecycle - Lite model 'gemini-1.5-flash-latest' initialized for key index 0.
2025-04-28 12:34:26 - INFO - ai_interface.gemini_api - Creating Tool configuration for model 'gemini-2.0-flash'...
2025-04-28 12:34:26 - INFO - ai_interface.gemini_api - Tool object created for 'gemini-2.0-flash' with 20 declarations.
2025-04-28 12:34:26 - DEBUG - ai_interface.gemini_api - Applying generation config for 'gemini-2.0-flash': {'temperature': 0.7}
2025-04-28 12:34:26 - DEBUG - ai_interface.gemini_api - Applying safety settings for 'gemini-2.0-flash': [{'category': 'HARM_CATEGORY_HARASSMENT', 'threshold': 'BLOCK_NONE'}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'threshold': 'BLOCK_NONE'}, {'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'threshold': 'BLOCK_NONE'}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'threshold': 'BLOCK_NONE'}]
2025-04-28 12:34:26 - INFO - ai_interface.gemini_api - Applying system instruction for 'gemini-2.0-flash'.
2025-04-28 12:34:26 - INFO - ai_interface.gemini_api - Gemini model 'gemini-2.0-flash' initialized successfully.
2025-04-28 12:34:26 - INFO - bot_lifecycle - Pro model 'gemini-2.0-flash' initialized for key index 0.
2025-04-28 12:34:26 - INFO - bot_lifecycle - Initializing models for API key index 1 (...a7Jo)
2025-04-28 12:34:26 - DEBUG - bot_lifecycle - genai configured with API key index 1.
2025-04-28 12:34:26 - INFO - ai_interface.gemini_api - Function Calling disabled for model 'gemini-1.5-flash-latest'. No tools created.
2025-04-28 12:34:26 - DEBUG - ai_interface.gemini_api - Applying generation config for 'gemini-1.5-flash-latest': {'temperature': 0.2}
2025-04-28 12:34:26 - DEBUG - ai_interface.gemini_api - Applying safety settings for 'gemini-1.5-flash-latest': [{'category': 'HARM_CATEGORY_HARASSMENT', 'threshold': 'BLOCK_NONE'}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'threshold': 'BLOCK_NONE'}, {'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'threshold': 'BLOCK_NONE'}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'threshold': 'BLOCK_NONE'}]
2025-04-28 12:34:26 - INFO - ai_interface.gemini_api - Applying system instruction for 'gemini-1.5-flash-latest'.
2025-04-28 12:34:26 - INFO - ai_interface.gemini_api - Gemini model 'gemini-1.5-flash-latest' initialized successfully.
2025-04-28 12:34:26 - INFO - bot_lifecycle - Lite model 'gemini-1.5-flash-latest' initialized for key index 1.
2025-04-28 12:34:26 - INFO - ai_interface.gemini_api - Creating Tool configuration for model 'gemini-2.0-flash'...
2025-04-28 12:34:26 - INFO - ai_interface.gemini_api - Tool object created for 'gemini-2.0-flash' with 20 declarations.
2025-04-28 12:34:26 - DEBUG - ai_interface.gemini_api - Applying generation config for 'gemini-2.0-flash': {'temperature': 0.7}
2025-04-28 12:34:26 - DEBUG - ai_interface.gemini_api - Applying safety settings for 'gemini-2.0-flash': [{'category': 'HARM_CATEGORY_HARASSMENT', 'threshold': 'BLOCK_NONE'}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'threshold': 'BLOCK_NONE'}, {'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'threshold': 'BLOCK_NONE'}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'threshold': 'BLOCK_NONE'}]
2025-04-28 12:34:26 - INFO - ai_interface.gemini_api - Applying system instruction for 'gemini-2.0-flash'.
2025-04-28 12:34:26 - INFO - ai_interface.gemini_api - Gemini model 'gemini-2.0-flash' initialized successfully.
2025-04-28 12:34:26 - INFO - bot_lifecycle - Pro model 'gemini-2.0-flash' initialized for key index 1.
2025-04-28 12:34:26 - INFO - bot_lifecycle - Initializing models for API key index 2 (...lbZ0)
2025-04-28 12:34:26 - DEBUG - bot_lifecycle - genai configured with API key index 2.
2025-04-28 12:34:26 - INFO - ai_interface.gemini_api - Function Calling disabled for model 'gemini-1.5-flash-latest'. No tools created.
2025-04-28 12:34:26 - DEBUG - ai_interface.gemini_api - Applying generation config for 'gemini-1.5-flash-latest': {'temperature': 0.2}
2025-04-28 12:34:26 - DEBUG - ai_interface.gemini_api - Applying safety settings for 'gemini-1.5-flash-latest': [{'category': 'HARM_CATEGORY_HARASSMENT', 'threshold': 'BLOCK_NONE'}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'threshold': 'BLOCK_NONE'}, {'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'threshold': 'BLOCK_NONE'}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'threshold': 'BLOCK_NONE'}]
2025-04-28 12:34:26 - INFO - ai_interface.gemini_api - Applying system instruction for 'gemini-1.5-flash-latest'.
2025-04-28 12:34:26 - INFO - ai_interface.gemini_api - Gemini model 'gemini-1.5-flash-latest' initialized successfully.
2025-04-28 12:34:26 - INFO - bot_lifecycle - Lite model 'gemini-1.5-flash-latest' initialized for key index 2.
2025-04-28 12:34:26 - INFO - ai_interface.gemini_api - Creating Tool configuration for model 'gemini-2.0-flash'...
2025-04-28 12:34:26 - INFO - ai_interface.gemini_api - Tool object created for 'gemini-2.0-flash' with 20 declarations.
2025-04-28 12:34:26 - DEBUG - ai_interface.gemini_api - Applying generation config for 'gemini-2.0-flash': {'temperature': 0.7}
2025-04-28 12:34:26 - DEBUG - ai_interface.gemini_api - Applying safety settings for 'gemini-2.0-flash': [{'category': 'HARM_CATEGORY_HARASSMENT', 'threshold': 'BLOCK_NONE'}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'threshold': 'BLOCK_NONE'}, {'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'threshold': 'BLOCK_NONE'}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'threshold': 'BLOCK_NONE'}]
2025-04-28 12:34:26 - INFO - ai_interface.gemini_api - Applying system instruction for 'gemini-2.0-flash'.
2025-04-28 12:34:26 - INFO - ai_interface.gemini_api - Gemini model 'gemini-2.0-flash' initialized successfully.
2025-04-28 12:34:26 - INFO - bot_lifecycle - Pro model 'gemini-2.0-flash' initialized for key index 2.
2025-04-28 12:34:26 - INFO - bot_lifecycle - Initializing models for API key index 3 (...qYLg)
2025-04-28 12:34:26 - DEBUG - bot_lifecycle - genai configured with API key index 3.
2025-04-28 12:34:26 - INFO - ai_interface.gemini_api - Function Calling disabled for model 'gemini-1.5-flash-latest'. No tools created.
2025-04-28 12:34:26 - DEBUG - ai_interface.gemini_api - Applying generation config for 'gemini-1.5-flash-latest': {'temperature': 0.2}
2025-04-28 12:34:26 - DEBUG - ai_interface.gemini_api - Applying safety settings for 'gemini-1.5-flash-latest': [{'category': 'HARM_CATEGORY_HARASSMENT', 'threshold': 'BLOCK_NONE'}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'threshold': 'BLOCK_NONE'}, {'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'threshold': 'BLOCK_NONE'}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'threshold': 'BLOCK_NONE'}]
2025-04-28 12:34:26 - INFO - ai_interface.gemini_api - Applying system instruction for 'gemini-1.5-flash-latest'.
2025-04-28 12:34:26 - INFO - ai_interface.gemini_api - Gemini model 'gemini-1.5-flash-latest' initialized successfully.
2025-04-28 12:34:26 - INFO - bot_lifecycle - Lite model 'gemini-1.5-flash-latest' initialized for key index 3.
2025-04-28 12:34:26 - INFO - ai_interface.gemini_api - Creating Tool configuration for model 'gemini-2.0-flash'...
2025-04-28 12:34:26 - INFO - ai_interface.gemini_api - Tool object created for 'gemini-2.0-flash' with 20 declarations.
2025-04-28 12:34:26 - DEBUG - ai_interface.gemini_api - Applying generation config for 'gemini-2.0-flash': {'temperature': 0.7}
2025-04-28 12:34:26 - DEBUG - ai_interface.gemini_api - Applying safety settings for 'gemini-2.0-flash': [{'category': 'HARM_CATEGORY_HARASSMENT', 'threshold': 'BLOCK_NONE'}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'threshold': 'BLOCK_NONE'}, {'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'threshold': 'BLOCK_NONE'}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'threshold': 'BLOCK_NONE'}]
2025-04-28 12:34:26 - INFO - ai_interface.gemini_api - Applying system instruction for 'gemini-2.0-flash'.
2025-04-28 12:34:26 - INFO - ai_interface.gemini_api - Gemini model 'gemini-2.0-flash' initialized successfully.
2025-04-28 12:34:26 - INFO - bot_lifecycle - Pro model 'gemini-2.0-flash' initialized for key index 3.
2025-04-28 12:34:26 - INFO - bot_lifecycle - Initializing models for API key index 4 (...AyJI)
2025-04-28 12:34:26 - DEBUG - bot_lifecycle - genai configured with API key index 4.
2025-04-28 12:34:26 - INFO - ai_interface.gemini_api - Function Calling disabled for model 'gemini-1.5-flash-latest'. No tools created.
2025-04-28 12:34:26 - DEBUG - ai_interface.gemini_api - Applying generation config for 'gemini-1.5-flash-latest': {'temperature': 0.2}
2025-04-28 12:34:26 - DEBUG - ai_interface.gemini_api - Applying safety settings for 'gemini-1.5-flash-latest': [{'category': 'HARM_CATEGORY_HARASSMENT', 'threshold': 'BLOCK_NONE'}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'threshold': 'BLOCK_NONE'}, {'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'threshold': 'BLOCK_NONE'}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'threshold': 'BLOCK_NONE'}]
2025-04-28 12:34:26 - INFO - ai_interface.gemini_api - Applying system instruction for 'gemini-1.5-flash-latest'.
2025-04-28 12:34:26 - INFO - ai_interface.gemini_api - Gemini model 'gemini-1.5-flash-latest' initialized successfully.
2025-04-28 12:34:26 - INFO - bot_lifecycle - Lite model 'gemini-1.5-flash-latest' initialized for key index 4.
2025-04-28 12:34:26 - INFO - ai_interface.gemini_api - Creating Tool configuration for model 'gemini-2.0-flash'...
2025-04-28 12:34:26 - INFO - ai_interface.gemini_api - Tool object created for 'gemini-2.0-flash' with 20 declarations.
2025-04-28 12:34:26 - DEBUG - ai_interface.gemini_api - Applying generation config for 'gemini-2.0-flash': {'temperature': 0.7}
2025-04-28 12:34:26 - DEBUG - ai_interface.gemini_api - Applying safety settings for 'gemini-2.0-flash': [{'category': 'HARM_CATEGORY_HARASSMENT', 'threshold': 'BLOCK_NONE'}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'threshold': 'BLOCK_NONE'}, {'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'threshold': 'BLOCK_NONE'}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'threshold': 'BLOCK_NONE'}]
2025-04-28 12:34:26 - INFO - ai_interface.gemini_api - Applying system instruction for 'gemini-2.0-flash'.
2025-04-28 12:34:26 - INFO - ai_interface.gemini_api - Gemini model 'gemini-2.0-flash' initialized successfully.
2025-04-28 12:34:26 - INFO - bot_lifecycle - Pro model 'gemini-2.0-flash' initialized for key index 4.
2025-04-28 12:34:26 - INFO - bot_lifecycle - Initializing models for API key index 5 (...DAcE)
2025-04-28 12:34:26 - DEBUG - bot_lifecycle - genai configured with API key index 5.
2025-04-28 12:34:26 - INFO - ai_interface.gemini_api - Function Calling disabled for model 'gemini-1.5-flash-latest'. No tools created.
2025-04-28 12:34:26 - DEBUG - ai_interface.gemini_api - Applying generation config for 'gemini-1.5-flash-latest': {'temperature': 0.2}
2025-04-28 12:34:26 - DEBUG - ai_interface.gemini_api - Applying safety settings for 'gemini-1.5-flash-latest': [{'category': 'HARM_CATEGORY_HARASSMENT', 'threshold': 'BLOCK_NONE'}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'threshold': 'BLOCK_NONE'}, {'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'threshold': 'BLOCK_NONE'}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'threshold': 'BLOCK_NONE'}]
2025-04-28 12:34:26 - INFO - ai_interface.gemini_api - Applying system instruction for 'gemini-1.5-flash-latest'.
2025-04-28 12:34:26 - INFO - ai_interface.gemini_api - Gemini model 'gemini-1.5-flash-latest' initialized successfully.
2025-04-28 12:34:26 - INFO - bot_lifecycle - Lite model 'gemini-1.5-flash-latest' initialized for key index 5.
2025-04-28 12:34:26 - INFO - ai_interface.gemini_api - Creating Tool configuration for model 'gemini-2.0-flash'...
2025-04-28 12:34:26 - INFO - ai_interface.gemini_api - Tool object created for 'gemini-2.0-flash' with 20 declarations.
2025-04-28 12:34:26 - DEBUG - ai_interface.gemini_api - Applying generation config for 'gemini-2.0-flash': {'temperature': 0.7}
2025-04-28 12:34:26 - DEBUG - ai_interface.gemini_api - Applying safety settings for 'gemini-2.0-flash': [{'category': 'HARM_CATEGORY_HARASSMENT', 'threshold': 'BLOCK_NONE'}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'threshold': 'BLOCK_NONE'}, {'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'threshold': 'BLOCK_NONE'}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'threshold': 'BLOCK_NONE'}]
2025-04-28 12:34:26 - INFO - ai_interface.gemini_api - Applying system instruction for 'gemini-2.0-flash'.
2025-04-28 12:34:26 - INFO - ai_interface.gemini_api - Gemini model 'gemini-2.0-flash' initialized successfully.
2025-04-28 12:34:26 - INFO - bot_lifecycle - Pro model 'gemini-2.0-flash' initialized for key index 5.
2025-04-28 12:34:26 - INFO - bot_lifecycle - Mapping 21 available tool handlers...
2025-04-28 12:34:26 - WARNING - bot_lifecycle - Found tool handlers that are not declared in PRO JSON: {'replace_code_block_ast'}
2025-04-28 12:34:26 - INFO - bot_lifecycle - Initialized 6 Pro models and 6 Lite models.
2025-04-28 12:34:26 - INFO - bot_lifecycle - Model lists, keys, index, tool handlers, and FC steps added to Dispatcher workflow_data.
2025-04-28 12:34:26 - INFO - bot_lifecycle - Bot startup sequence complete!
2025-04-28 12:34:26 - INFO - aiogram.dispatcher - Start polling
2025-04-28 12:34:26 - INFO - services.news_service - Starting NewsService...
2025-04-28 12:34:26 - DEBUG - services.news_service - Loading recent sent GUIDs (last 7 days)...
2025-04-28 12:34:26 - DEBUG - database.connection - Reusing existing DB connection. Connection object ID: 140205373025024
2025-04-28 12:34:26 - DEBUG - aiosqlite - executing functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, 'SELECT guid FROM sent_news_guids WHERE sent_ts >= ?', ('2025-04-21T12:34:26.254339+00:00',))
2025-04-28 12:34:26 - DEBUG - aiosqlite - operation functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, 'SELECT guid FROM sent_news_guids WHERE sent_ts >= ?', ('2025-04-21T12:34:26.254339+00:00',)) completed
2025-04-28 12:34:26 - DEBUG - aiosqlite - executing functools.partial(<built-in method fetchall of sqlite3.Cursor object at 0x7f841b7153c0>)
2025-04-28 12:34:26 - DEBUG - aiosqlite - operation functools.partial(<built-in method fetchall of sqlite3.Cursor object at 0x7f841b7153c0>) completed
2025-04-28 12:34:26 - DEBUG - aiosqlite - executing functools.partial(<built-in method close of sqlite3.Cursor object at 0x7f841b7153c0>)
2025-04-28 12:34:26 - DEBUG - aiosqlite - operation functools.partial(<built-in method close of sqlite3.Cursor object at 0x7f841b7153c0>) completed
2025-04-28 12:34:26 - INFO - database.crud_ops.news - Loaded 0 recent sent GUIDs (last 7 days).
2025-04-28 12:34:26 - INFO - services.news_service - Loaded 0 recent GUIDs into memory cache.
2025-04-28 12:34:26 - INFO - services.news_service - NewsService scheduler and cleanup tasks started.
2025-04-28 12:34:26 - DEBUG - services.news_service - Checking subscriptions for schedule time: 12:34
2025-04-28 12:34:26 - DEBUG - database.connection - Reusing existing DB connection. Connection object ID: 140205373025024
2025-04-28 12:34:26 - INFO - services.news_service - Running periodic GUID cleanup...
2025-04-28 12:34:26 - DEBUG - aiosqlite - executing functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, 'SELECT channel_id, topics_json, schedule_json, last_post_ts FROM news_subscriptions ORDER BY channel_id', [])
2025-04-28 12:34:26 - DEBUG - database.connection - Reusing existing DB connection. Connection object ID: 140205373025024
2025-04-28 12:34:26 - DEBUG - aiosqlite - operation functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, 'SELECT channel_id, topics_json, schedule_json, last_post_ts FROM news_subscriptions ORDER BY channel_id', []) completed
2025-04-28 12:34:26 - DEBUG - aiosqlite - executing functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, 'DELETE FROM sent_news_guids WHERE sent_ts < ?', ('2025-04-21T12:34:26.256423+00:00',))
2025-04-28 12:34:26 - DEBUG - aiosqlite - operation functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, 'DELETE FROM sent_news_guids WHERE sent_ts < ?', ('2025-04-21T12:34:26.256423+00:00',)) completed
2025-04-28 12:34:26 - DEBUG - aiosqlite - executing functools.partial(<built-in method fetchall of sqlite3.Cursor object at 0x7f841b714c40>)
2025-04-28 12:34:26 - DEBUG - aiosqlite - operation functools.partial(<built-in method fetchall of sqlite3.Cursor object at 0x7f841b714c40>) completed
2025-04-28 12:34:26 - DEBUG - aiosqlite - executing functools.partial(<built-in method commit of sqlite3.Connection object at 0x7f841c62b140>)
2025-04-28 12:34:26 - DEBUG - aiosqlite - operation functools.partial(<built-in method commit of sqlite3.Connection object at 0x7f841c62b140>) completed
2025-04-28 12:34:26 - DEBUG - aiosqlite - executing functools.partial(<built-in method close of sqlite3.Cursor object at 0x7f841b714c40>)
2025-04-28 12:34:26 - DEBUG - aiosqlite - operation functools.partial(<built-in method close of sqlite3.Cursor object at 0x7f841b714c40>) completed
2025-04-28 12:34:26 - DEBUG - aiosqlite - executing functools.partial(<built-in method close of sqlite3.Cursor object at 0x7f841b714bc0>)
2025-04-28 12:34:26 - DEBUG - aiosqlite - operation functools.partial(<built-in method close of sqlite3.Cursor object at 0x7f841b714bc0>) completed
2025-04-28 12:34:26 - INFO - database.crud_ops.news - Retrieved 0 news subscriptions.
2025-04-28 12:34:26 - INFO - database.crud_ops.news - No old GUIDs found to cleanup (older than 7 days).
2025-04-28 12:34:26 - INFO - services.news_service - GUID cleanup finished. Deleted 0 old GUIDs.
2025-04-28 12:34:26 - DEBUG - services.news_service - Loading recent sent GUIDs (last 7 days)...
2025-04-28 12:34:26 - DEBUG - database.connection - Reusing existing DB connection. Connection object ID: 140205373025024
2025-04-28 12:34:26 - DEBUG - aiosqlite - executing functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, 'SELECT guid FROM sent_news_guids WHERE sent_ts >= ?', ('2025-04-21T12:34:26.257476+00:00',))
2025-04-28 12:34:26 - DEBUG - aiosqlite - operation functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, 'SELECT guid FROM sent_news_guids WHERE sent_ts >= ?', ('2025-04-21T12:34:26.257476+00:00',)) completed
2025-04-28 12:34:26 - DEBUG - aiosqlite - executing functools.partial(<built-in method fetchall of sqlite3.Cursor object at 0x7f841b714bc0>)
2025-04-28 12:34:26 - DEBUG - aiosqlite - operation functools.partial(<built-in method fetchall of sqlite3.Cursor object at 0x7f841b714bc0>) completed
2025-04-28 12:34:26 - DEBUG - aiosqlite - executing functools.partial(<built-in method close of sqlite3.Cursor object at 0x7f841b714bc0>)
2025-04-28 12:34:26 - DEBUG - aiosqlite - operation functools.partial(<built-in method close of sqlite3.Cursor object at 0x7f841b714bc0>) completed
2025-04-28 12:34:26 - INFO - database.crud_ops.news - Loaded 0 recent sent GUIDs (last 7 days).
2025-04-28 12:34:26 - INFO - services.news_service - Loaded 0 recent GUIDs into memory cache.
2025-04-28 12:34:26 - INFO - aiogram.dispatcher - Run polling for bot @beykusay_bot id=7205919623 - 'BeykusAgent'
2025-04-28 12:34:43 - DEBUG - utils.helpers - Admin check: User 905302972 is an admin.
2025-04-28 12:34:43 - INFO - telegram_interface.handlers.common_messages - !!! HANDLER process_text_message TRIGGERED for message 68413 !!!
2025-04-28 12:34:43 - DEBUG - telegram_interface.handlers.common_messages - Calling handle_user_request for user 905302972 chat -1001994777988
2025-04-28 12:34:43 - INFO - core_agent.agent_processor - Core Agent: Handling request from user=905302972 in chat=-1001994777988 (type=supergroup, force_pro=False)
2025-04-28 12:34:43 - DEBUG - database.connection - Reusing existing DB connection. Connection object ID: 140205373025024
2025-04-28 12:34:43 - DEBUG - aiosqlite - executing functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, '\n            INSERT INTO user_profiles (user_id, username, first_name, last_name, last_seen)\n            VALUES (?, ?, ?, ?, CURRENT_TIMESTAMP)\n            ON CONFLICT(user_id) DO UPDATE SET\n                username = excluded.username,\n                first_name = excluded.first_name,\n                last_name = excluded.last_name,\n                last_seen = CURRENT_TIMESTAMP\n            WHERE user_id = excluded.user_id;\n        ', (905302972, 'BeykusY', '🏎️', None))
2025-04-28 12:34:43 - DEBUG - aiosqlite - operation functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, '\n            INSERT INTO user_profiles (user_id, username, first_name, last_name, last_seen)\n            VALUES (?, ?, ?, ?, CURRENT_TIMESTAMP)\n            ON CONFLICT(user_id) DO UPDATE SET\n                username = excluded.username,\n                first_name = excluded.first_name,\n                last_name = excluded.last_name,\n                last_seen = CURRENT_TIMESTAMP\n            WHERE user_id = excluded.user_id;\n        ', (905302972, 'BeykusY', '🏎️', None)) completed
2025-04-28 12:34:43 - DEBUG - database.crud_ops.profiles - Executed UPSERT for user_id 905302972. Preparing to commit...
2025-04-28 12:34:43 - DEBUG - aiosqlite - executing functools.partial(<built-in method commit of sqlite3.Connection object at 0x7f841c62b140>)
2025-04-28 12:34:43 - DEBUG - aiosqlite - operation functools.partial(<built-in method commit of sqlite3.Connection object at 0x7f841c62b140>) completed
2025-04-28 12:34:43 - INFO - database.crud_ops.profiles - Successfully committed upsert for user profile for user_id 905302972
2025-04-28 12:34:43 - DEBUG - aiosqlite - executing functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, 'SELECT last_seen FROM user_profiles WHERE user_id = ?', (905302972,))
2025-04-28 12:34:43 - DEBUG - aiosqlite - operation functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, 'SELECT last_seen FROM user_profiles WHERE user_id = ?', (905302972,)) completed
2025-04-28 12:34:43 - DEBUG - aiosqlite - executing functools.partial(<built-in method fetchone of sqlite3.Cursor object at 0x7f841b714bc0>)
2025-04-28 12:34:43 - DEBUG - aiosqlite - operation functools.partial(<built-in method fetchone of sqlite3.Cursor object at 0x7f841b714bc0>) completed
2025-04-28 12:34:43 - INFO - database.crud_ops.profiles - VERIFY AFTER COMMIT: Found profile for 905302972, last_seen: 2025-04-28 12:34:43
2025-04-28 12:34:43 - DEBUG - aiosqlite - executing functools.partial(<built-in method close of sqlite3.Cursor object at 0x7f841b714bc0>)
2025-04-28 12:34:43 - DEBUG - aiosqlite - operation functools.partial(<built-in method close of sqlite3.Cursor object at 0x7f841b714bc0>) completed
2025-04-28 12:34:43 - DEBUG - utils.converters - _serialize_parts received: type=<class 'list'>, value=[{'text': 'привет, что ты знаешь о рыбах?'}]
2025-04-28 12:34:43 - DEBUG - database.connection - Reusing existing DB connection. Connection object ID: 140205373025024
2025-04-28 12:34:43 - DEBUG - aiosqlite - executing functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, '\n            INSERT INTO chat_history (chat_id, role, user_id, parts_json)\n            VALUES (?, ?, ?, ?)\n            ', (-1001994777988, 'user', 905302972, '[{"text": "привет, что ты знаешь о рыбах?"}]'))
2025-04-28 12:34:43 - DEBUG - aiosqlite - operation functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, '\n            INSERT INTO chat_history (chat_id, role, user_id, parts_json)\n            VALUES (?, ?, ?, ?)\n            ', (-1001994777988, 'user', 905302972, '[{"text": "привет, что ты знаешь о рыбах?"}]')) completed
2025-04-28 12:34:43 - DEBUG - database.crud_ops.history - Executed INSERT for chat=-1001994777988, role=user. Preparing to commit...
2025-04-28 12:34:43 - DEBUG - aiosqlite - executing functools.partial(<built-in method commit of sqlite3.Connection object at 0x7f841c62b140>)
2025-04-28 12:34:43 - DEBUG - aiosqlite - operation functools.partial(<built-in method commit of sqlite3.Connection object at 0x7f841c62b140>) completed
2025-04-28 12:34:43 - INFO - database.crud_ops.history - Successfully committed history entry: chat=-1001994777988, role=user, user=905302972, json_size=44
2025-04-28 12:34:43 - DEBUG - aiosqlite - executing functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, 'SELECT id, timestamp FROM chat_history WHERE chat_id = ? AND role = ? ORDER BY id DESC LIMIT 1', (-1001994777988, 'user'))
2025-04-28 12:34:43 - DEBUG - aiosqlite - operation functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, 'SELECT id, timestamp FROM chat_history WHERE chat_id = ? AND role = ? ORDER BY id DESC LIMIT 1', (-1001994777988, 'user')) completed
2025-04-28 12:34:43 - DEBUG - aiosqlite - executing functools.partial(<built-in method fetchone of sqlite3.Cursor object at 0x7f841b714bc0>)
2025-04-28 12:34:43 - DEBUG - aiosqlite - operation functools.partial(<built-in method fetchone of sqlite3.Cursor object at 0x7f841b714bc0>) completed
2025-04-28 12:34:43 - INFO - database.crud_ops.history - VERIFY AFTER COMMIT: Found history for -1001994777988/user, id: 17, ts: 2025-04-28 12:34:43
2025-04-28 12:34:43 - DEBUG - aiosqlite - executing functools.partial(<built-in method close of sqlite3.Cursor object at 0x7f841b714bc0>)
2025-04-28 12:34:43 - DEBUG - aiosqlite - operation functools.partial(<built-in method close of sqlite3.Cursor object at 0x7f841b714bc0>) completed
2025-04-28 12:34:43 - INFO - core_agent.agent_processor - Agent Processor: Saved initial user message and updated profile for user 905302972.
2025-04-28 12:34:43 - INFO - core_agent.agent_processor - Bot info cached in agent_processor: ID=7205919623, Username=@beykusay_bot
2025-04-28 12:34:43 - INFO - core_agent.agent_processor - Proceeding with Pro model for user 905302972 chat -1001994777988 (Reason: Reply/Mention in group).
2025-04-28 12:34:43 - DEBUG - core_agent.agent_processor - Executing Pro model logic for chat -1001994777988 using multi-key setup.
2025-04-28 12:34:43 - DEBUG - core_agent.history_manager - Preparing history for chat=-1001994777988, current_user=905302972, chat_type=supergroup, add_notes=True, add_logs=True, log_limit=8
2025-04-28 12:34:43 - DEBUG - database.connection - Reusing existing DB connection. Connection object ID: 140205373025024
2025-04-28 12:34:43 - DEBUG - aiosqlite - executing functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, '\n            SELECT role, user_id, parts_json, timestamp\n            FROM chat_history\n            WHERE chat_id = ?\n            ORDER BY timestamp DESC\n            LIMIT ?\n            ', (-1001994777988, 50))
2025-04-28 12:34:43 - DEBUG - aiosqlite - operation functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, '\n            SELECT role, user_id, parts_json, timestamp\n            FROM chat_history\n            WHERE chat_id = ?\n            ORDER BY timestamp DESC\n            LIMIT ?\n            ', (-1001994777988, 50)) completed
2025-04-28 12:34:43 - DEBUG - aiosqlite - executing functools.partial(<built-in method fetchall of sqlite3.Cursor object at 0x7f841b714bc0>)
2025-04-28 12:34:43 - DEBUG - aiosqlite - operation functools.partial(<built-in method fetchall of sqlite3.Cursor object at 0x7f841b714bc0>) completed
2025-04-28 12:34:43 - DEBUG - aiosqlite - executing functools.partial(<built-in method close of sqlite3.Cursor object at 0x7f841b714bc0>)
2025-04-28 12:34:43 - DEBUG - aiosqlite - operation functools.partial(<built-in method close of sqlite3.Cursor object at 0x7f841b714bc0>) completed
2025-04-28 12:34:43 - DEBUG - database.crud_ops.history - Retrieved 11 history entries for chat_id=-1001994777988 (limit=50)
2025-04-28 12:34:43 - DEBUG - database.connection - Reusing existing DB connection. Connection object ID: 140205373025024
2025-04-28 12:34:43 - DEBUG - aiosqlite - executing functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, '\n            SELECT user_id, username, first_name, last_name, last_seen, avatar_file_id, avatar_description\n            FROM user_profiles\n            WHERE user_id = ?\n            ', (905302972,))
2025-04-28 12:34:43 - DEBUG - aiosqlite - operation functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, '\n            SELECT user_id, username, first_name, last_name, last_seen, avatar_file_id, avatar_description\n            FROM user_profiles\n            WHERE user_id = ?\n            ', (905302972,)) completed
2025-04-28 12:34:43 - DEBUG - aiosqlite - executing functools.partial(<built-in method fetchone of sqlite3.Cursor object at 0x7f841b714bc0>)
2025-04-28 12:34:43 - DEBUG - aiosqlite - operation functools.partial(<built-in method fetchone of sqlite3.Cursor object at 0x7f841b714bc0>) completed
2025-04-28 12:34:43 - DEBUG - database.crud_ops.profiles - Retrieved profile data for user_id=905302972
2025-04-28 12:34:43 - DEBUG - aiosqlite - executing functools.partial(<built-in method close of sqlite3.Cursor object at 0x7f841b714bc0>)
2025-04-28 12:34:43 - DEBUG - aiosqlite - operation functools.partial(<built-in method close of sqlite3.Cursor object at 0x7f841b714bc0>) completed
2025-04-28 12:34:43 - DEBUG - database.connection - Reusing existing DB connection. Connection object ID: 140205373025024
2025-04-28 12:34:43 - DEBUG - aiosqlite - executing functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, 'SELECT category, value FROM user_notes WHERE user_id = ? ORDER BY category', (905302972,))
2025-04-28 12:34:43 - DEBUG - aiosqlite - operation functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, 'SELECT category, value FROM user_notes WHERE user_id = ? ORDER BY category', (905302972,)) completed
2025-04-28 12:34:43 - DEBUG - aiosqlite - executing functools.partial(<built-in method fetchall of sqlite3.Cursor object at 0x7f841b714bc0>)
2025-04-28 12:34:43 - DEBUG - aiosqlite - operation functools.partial(<built-in method fetchall of sqlite3.Cursor object at 0x7f841b714bc0>) completed
2025-04-28 12:34:43 - DEBUG - database.crud_ops.notes - No notes found for user_id=905302972
2025-04-28 12:34:43 - DEBUG - aiosqlite - executing functools.partial(<built-in method close of sqlite3.Cursor object at 0x7f841b714bc0>)
2025-04-28 12:34:43 - DEBUG - aiosqlite - operation functools.partial(<built-in method close of sqlite3.Cursor object at 0x7f841b714bc0>) completed
2025-04-28 12:34:43 - DEBUG - database.connection - Reusing existing DB connection. Connection object ID: 140205373025024
2025-04-28 12:34:43 - DEBUG - aiosqlite - executing functools.partial(<built-in method cursor of sqlite3.Connection object at 0x7f841c62b140>)
2025-04-28 12:34:43 - DEBUG - aiosqlite - operation functools.partial(<built-in method cursor of sqlite3.Connection object at 0x7f841c62b140>) completed
2025-04-28 12:34:43 - DEBUG - aiosqlite - executing functools.partial(<built-in method execute of sqlite3.Cursor object at 0x7f841b714bc0>, '\n                SELECT execution_id, chat_id, user_id, timestamp, tool_name, tool_args_json,\n                       status, return_code, result_message, stdout, stderr, full_result_json,\n                       trigger_message_id\n                FROM tool_executions\n                WHERE chat_id = ?\n                ORDER BY timestamp DESC\n                LIMIT ?\n                ', (-1001994777988, 8))
2025-04-28 12:34:43 - DEBUG - aiosqlite - operation functools.partial(<built-in method execute of sqlite3.Cursor object at 0x7f841b714bc0>, '\n                SELECT execution_id, chat_id, user_id, timestamp, tool_name, tool_args_json,\n                       status, return_code, result_message, stdout, stderr, full_result_json,\n                       trigger_message_id\n                FROM tool_executions\n                WHERE chat_id = ?\n                ORDER BY timestamp DESC\n                LIMIT ?\n                ', (-1001994777988, 8)) completed
2025-04-28 12:34:43 - DEBUG - aiosqlite - executing functools.partial(<built-in method fetchall of sqlite3.Cursor object at 0x7f841b714bc0>)
2025-04-28 12:34:43 - DEBUG - aiosqlite - operation functools.partial(<built-in method fetchall of sqlite3.Cursor object at 0x7f841b714bc0>) completed
2025-04-28 12:34:43 - DEBUG - database.crud_ops.execution_logs - Retrieved 8 recent tool execution logs for chat -1001994777988.
2025-04-28 12:34:43 - DEBUG - aiosqlite - executing functools.partial(<built-in method close of sqlite3.Cursor object at 0x7f841b714bc0>)
2025-04-28 12:34:43 - DEBUG - aiosqlite - operation functools.partial(<built-in method close of sqlite3.Cursor object at 0x7f841b714bc0>) completed
2025-04-28 12:34:43 - DEBUG - core_agent.history_manager - History Prep: Skipping log entry for tool 'send_telegram_message' (filtered).
2025-04-28 12:34:43 - DEBUG - core_agent.history_manager - History Prep: Skipping log entry for tool 'Developer_Feedback' (filtered).
2025-04-28 12:34:43 - DEBUG - core_agent.history_manager - History Prep: Skipping log entry for tool 'Developer_Feedback' (filtered).
2025-04-28 12:34:43 - INFO - core_agent.history_manager - Added 5 recent non-communication tool execution logs to history context for chat -1001994777988.
2025-04-28 12:34:43 - DEBUG - database.connection - Reusing existing DB connection. Connection object ID: 140205373025024
2025-04-28 12:34:43 - DEBUG - aiosqlite - executing functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, '\n            SELECT user_id, username, first_name, last_name, last_seen, avatar_file_id, avatar_description\n            FROM user_profiles\n            WHERE user_id = ?\n            ', (905302972,))
2025-04-28 12:34:43 - DEBUG - aiosqlite - operation functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, '\n            SELECT user_id, username, first_name, last_name, last_seen, avatar_file_id, avatar_description\n            FROM user_profiles\n            WHERE user_id = ?\n            ', (905302972,)) completed
2025-04-28 12:34:43 - DEBUG - aiosqlite - executing functools.partial(<built-in method fetchone of sqlite3.Cursor object at 0x7f841b714bc0>)
2025-04-28 12:34:43 - DEBUG - aiosqlite - operation functools.partial(<built-in method fetchone of sqlite3.Cursor object at 0x7f841b714bc0>) completed
2025-04-28 12:34:43 - DEBUG - database.crud_ops.profiles - Retrieved profile data for user_id=905302972
2025-04-28 12:34:43 - DEBUG - aiosqlite - executing functools.partial(<built-in method close of sqlite3.Cursor object at 0x7f841b714bc0>)
2025-04-28 12:34:43 - DEBUG - aiosqlite - operation functools.partial(<built-in method close of sqlite3.Cursor object at 0x7f841b714bc0>) completed
2025-04-28 12:34:43 - DEBUG - database.connection - Reusing existing DB connection. Connection object ID: 140205373025024
2025-04-28 12:34:43 - DEBUG - aiosqlite - executing functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, 'SELECT category, value FROM user_notes WHERE user_id = ? ORDER BY category', (905302972,))
2025-04-28 12:34:43 - DEBUG - aiosqlite - operation functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, 'SELECT category, value FROM user_notes WHERE user_id = ? ORDER BY category', (905302972,)) completed
2025-04-28 12:34:43 - DEBUG - aiosqlite - executing functools.partial(<built-in method fetchall of sqlite3.Cursor object at 0x7f841b714bc0>)
2025-04-28 12:34:43 - DEBUG - aiosqlite - operation functools.partial(<built-in method fetchall of sqlite3.Cursor object at 0x7f841b714bc0>) completed
2025-04-28 12:34:43 - DEBUG - database.crud_ops.notes - No notes found for user_id=905302972
2025-04-28 12:34:43 - DEBUG - aiosqlite - executing functools.partial(<built-in method close of sqlite3.Cursor object at 0x7f841b714bc0>)
2025-04-28 12:34:43 - DEBUG - aiosqlite - operation functools.partial(<built-in method close of sqlite3.Cursor object at 0x7f841b714bc0>) completed
2025-04-28 12:34:43 - INFO - core_agent.history_manager - Added combined profile/notes context for current user 905302972 in chat -1001994777988.
2025-04-28 12:34:43 - WARNING - core_agent.history_manager - History Prep: Skipping DB entry with missing/invalid role or parts_json: {'role': 'user', 'parts': [{'text': 'привет'}], 'user_id': 905302972}
2025-04-28 12:34:43 - WARNING - core_agent.history_manager - History Prep: Skipping DB entry with missing/invalid role or parts_json: {'role': 'user', 'parts': [{'text': 'что ты знаешь о рыбах?'}], 'user_id': 905302972}
2025-04-28 12:34:43 - WARNING - core_agent.history_manager - History Prep: Skipping DB entry with missing/invalid role or parts_json: {'role': 'user', 'parts': [{'text': 'а еще?'}], 'user_id': 905302972}
2025-04-28 12:34:43 - WARNING - core_agent.history_manager - History Prep: Skipping DB entry with missing/invalid role or parts_json: {'role': 'user', 'parts': [{'text': 'ХАХААХАХАХХАХХА'}], 'user_id': 2105984481}
2025-04-28 12:34:43 - WARNING - core_agent.history_manager - History Prep: Skipping DB entry with missing/invalid role or parts_json: {'role': 'user', 'parts': [{'text': 'привет'}], 'user_id': 905302972}
2025-04-28 12:34:43 - WARNING - core_agent.history_manager - History Prep: Skipping DB entry with missing/invalid role or parts_json: {'role': 'user', 'parts': [{'text': 'кто ты'}], 'user_id': 905302972}
2025-04-28 12:34:43 - WARNING - core_agent.history_manager - History Prep: Skipping DB entry with missing/invalid role or parts_json: {'role': 'user', 'parts': [{'text': 'а я?'}], 'user_id': 905302972}
2025-04-28 12:34:43 - WARNING - core_agent.history_manager - History Prep: Skipping DB entry with missing/invalid role or parts_json: {'role': 'user', 'parts': [{'text': 'что ты знаешь о рыбах?'}], 'user_id': 905302972}
2025-04-28 12:34:43 - WARNING - core_agent.history_manager - History Prep: Skipping DB entry with missing/invalid role or parts_json: {'role': 'user', 'parts': [{'text': 'а сам?'}], 'user_id': 905302972}
2025-04-28 12:34:43 - WARNING - core_agent.history_manager - History Prep: Skipping DB entry with missing/invalid role or parts_json: {'role': 'user', 'parts': [{'text': 'Ору'}], 'user_id': 2105984481}
2025-04-28 12:34:43 - WARNING - core_agent.history_manager - History Prep: Skipping DB entry with missing/invalid role or parts_json: {'role': 'user', 'parts': [{'text': 'привет, что ты знаешь о рыбах?'}], 'user_id': 905302972}
2025-04-28 12:34:43 - DEBUG - core_agent.history_manager - History Prep: Finished processing 0 entries from DB history. Prepared 2 Content objects.
2025-04-28 12:34:43 - DEBUG - core_agent.history_manager - Final history prepared for API call. Length: 2
2025-04-28 12:34:43 - INFO - core_agent.ai_interaction - Running Gemini interaction for chat=-1001994777988, user=905302972, chat_type=supergroup
2025-04-28 12:34:43 - DEBUG - core_agent.ai_interaction - Found 6 Pro models (API keys) to use.
2025-04-28 12:34:43 - INFO - core_agent.ai_interaction - Attempt 1/6. Using API key index 0 (...tn6M) for chat -1001994777988
2025-04-28 12:34:43 - DEBUG - core_agent.ai_interaction - Chat session started successfully for key index 0.
2025-04-28 12:34:43 - DEBUG - core_agent.ai_interaction - Attempting Gemini API call with key index 0 for chat -1001994777988
2025-04-28 12:34:45 - INFO - ai_interface.gemini_api - Raw Gemini Response: Parts=[Part 0: Type=Part, Text='...', FunctionCall(Name='refine_text_with_deep_search'), FunctionResponse(Name='')], FinishReason: 1, Safety: [category: HARM_CATEGORY_HATE_SPEECH
probability: NEGLIGIBLE
, category: HARM_CATEGORY_DANGEROUS_CONTENT
probability: NEGLIGIBLE
, category: HARM_CATEGORY_HARASSMENT
probability: NEGLIGIBLE
, category: HARM_CATEGORY_SEXUALLY_EXPLICIT
probability: NEGLIGIBLE
]
2025-04-28 12:34:45 - DEBUG - core_agent.ai_interaction - Raw Gemini Response object (key index 0) for chat -1001994777988: response:
GenerateContentResponse(
    done=True,
    iterator=None,
    result=protos.GenerateContentResponse({
      "candidates": [
        {
          "content": {
            "parts": [
              {
                "function_call": {
                  "name": "refine_text_with_deep_search",
                  "args": {
                    "initial_query_or_text": "\u0427\u0442\u043e \u0442\u044b \u0437\u043d\u0430\u0435\u0448\u044c \u043e \u0440\u044b\u0431\u0430\u0445?"
                  }
                }
              }
            ],
            "role": "model"
          },
          "finish_reason": "STOP",
          "safety_ratings": [
            {
              "category": "HARM_CATEGORY_HATE_SPEECH",
              "probability": "NEGLIGIBLE"
            },
            {
              "category": "HARM_CATEGORY_DANGEROUS_CONTENT",
              "probability": "NEGLIGIBLE"
            },
            {
              "category": "HARM_CATEGORY_HARASSMENT",
              "probability": "NEGLIGIBLE"
            },
            {
              "category": "HARM_CATEGORY_SEXUALLY_EXPLICIT",
              "probability": "NEGLIGIBLE"
            }
          ],
          "avg_logprobs": -0.15250378069670303
        }
      ],
      "usage_metadata": {
        "prompt_token_count": 5320,
        "candidates_token_count": 23,
        "total_token_count": 5343
      },
      "model_version": "gemini-2.0-flash"
    }),
)
2025-04-28 12:34:45 - INFO - core_agent.ai_interaction - API call successful with key index 0 for chat -1001994777988
2025-04-28 12:34:45 - INFO - bot_lifecycle - API Key index incremented. New index: 1 (Key: ...a7Jo)
2025-04-28 12:34:45 - INFO - ai_interface.fc_processing - --- FC Analysis (models/gemini-2.0-flash Step 1/10) Chat: -1001994777988 ---
2025-04-28 12:34:45 - DEBUG - ai_interface.fc_processing - Found valid FC to process: refine_text_with_deep_search
2025-04-28 12:34:45 - DEBUG - ai_interface.fc_processing - Ignoring FunctionResponse with empty/missing name found in model response part: 
2025-04-28 12:34:45 - INFO - ai_interface.fc_processing - Found 1 valid FCs by models/gemini-2.0-flash to process.
2025-04-28 12:34:45 - DEBUG - utils.converters - Converting MapComposite-like object to dict: <class 'proto.marshal.collections.maps.MapComposite'>
2025-04-28 12:34:45 - INFO - ai_interface.fc_processing - Executing FC 1/1 sequentially: refine_text_with_deep_search({'initial_query_or_text': 'Что ты знаешь о рыбах?'}) for chat -1001994777988
2025-04-28 12:34:45 - DEBUG - ai_interface.fc_processing - Executing handler 'refine_text_with_deep_search' with final args: {}
2025-04-28 12:34:45 - INFO - tools.deep_search_tool - --- Tool Call: refine_text_with_deep_search(topic='None', initial_text_len=0, iters=None) ---
2025-04-28 12:34:45 - INFO - ai_interface.fc_processing - Sending 1 function responses back to Gemini for chat -1001994777988.
2025-04-28 12:34:45 - DEBUG - database.connection - Reusing existing DB connection. Connection object ID: 140205373025024
2025-04-28 12:34:45 - DEBUG - aiosqlite - executing functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, '\n            INSERT INTO tool_executions (\n                chat_id, user_id, tool_name, tool_args_json, status,\n                return_code, result_message, stdout, stderr, full_result_json,\n                trigger_message_id\n            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n            ', (-1001994777988, 905302972, 'refine_text_with_deep_search', '{"initial_query_or_text": "Что ты знаешь о рыбах?"}', 'error', None, "Either 'topic' or 'initial_text' must be provided.", None, None, '"{\\"status\\": \\"error\\", \\"message\\": \\"Either \'topic\' or \'initial_text\' must be provided.\\"}"', None))
2025-04-28 12:34:45 - DEBUG - aiosqlite - operation functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, '\n            INSERT INTO tool_executions (\n                chat_id, user_id, tool_name, tool_args_json, status,\n                return_code, result_message, stdout, stderr, full_result_json,\n                trigger_message_id\n            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n            ', (-1001994777988, 905302972, 'refine_text_with_deep_search', '{"initial_query_or_text": "Что ты знаешь о рыбах?"}', 'error', None, "Either 'topic' or 'initial_text' must be provided.", None, None, '"{\\"status\\": \\"error\\", \\"message\\": \\"Either \'topic\' or \'initial_text\' must be provided.\\"}"', None)) completed
2025-04-28 12:34:45 - DEBUG - aiosqlite - executing functools.partial(<built-in method commit of sqlite3.Connection object at 0x7f841c62b140>)
2025-04-28 12:34:45 - DEBUG - aiosqlite - operation functools.partial(<built-in method commit of sqlite3.Connection object at 0x7f841c62b140>) completed
2025-04-28 12:34:45 - DEBUG - aiosqlite - executing functools.partial(<built-in method close of sqlite3.Cursor object at 0x7f841b714bc0>)
2025-04-28 12:34:45 - DEBUG - aiosqlite - operation functools.partial(<built-in method close of sqlite3.Cursor object at 0x7f841b714bc0>) completed
2025-04-28 12:34:45 - INFO - database.crud_ops.execution_logs - Added tool execution log ID: 10 for tool 'refine_text_with_deep_search' in chat -1001994777988
2025-04-28 12:34:46 - INFO - ai_interface.gemini_api - Raw Gemini Response: Parts=[Part 0: Type=Part, Text='Произошла ошибка. Похоже, что я не передал нужный параметр в функцию. Попробую е...', FunctionCall(Name=''), FunctionResponse(Name=''); Part 1: Type=Part, Text='...', FunctionCall(Name='refine_text_with_deep_search'), FunctionResponse(Name='')], FinishReason: 1, Safety: [category: HARM_CATEGORY_HATE_SPEECH
probability: NEGLIGIBLE
, category: HARM_CATEGORY_DANGEROUS_CONTENT
probability: NEGLIGIBLE
, category: HARM_CATEGORY_HARASSMENT
probability: NEGLIGIBLE
, category: HARM_CATEGORY_SEXUALLY_EXPLICIT
probability: NEGLIGIBLE
]
2025-04-28 12:34:46 - DEBUG - ai_interface.fc_processing - Received next response from Gemini after sending FRs for chat -1001994777988
2025-04-28 12:34:46 - INFO - ai_interface.fc_processing - --- FC Analysis (models/gemini-2.0-flash Step 2/10) Chat: -1001994777988 ---
2025-04-28 12:34:46 - DEBUG - ai_interface.fc_processing - Ignoring FunctionCall with empty name found in model response part: 
2025-04-28 12:34:46 - DEBUG - ai_interface.fc_processing - Ignoring FunctionResponse with empty/missing name found in model response part: 
2025-04-28 12:34:46 - DEBUG - ai_interface.fc_processing - Found valid FC to process: refine_text_with_deep_search
2025-04-28 12:34:46 - DEBUG - ai_interface.fc_processing - Ignoring FunctionResponse with empty/missing name found in model response part: 
2025-04-28 12:34:46 - INFO - ai_interface.fc_processing - Found 1 valid FCs by models/gemini-2.0-flash to process.
2025-04-28 12:34:46 - DEBUG - utils.converters - Converting MapComposite-like object to dict: <class 'proto.marshal.collections.maps.MapComposite'>
2025-04-28 12:34:46 - INFO - ai_interface.fc_processing - Executing FC 1/1 sequentially: refine_text_with_deep_search({'initial_query_or_text': 'Рыбы'}) for chat -1001994777988
2025-04-28 12:34:46 - DEBUG - ai_interface.fc_processing - Executing handler 'refine_text_with_deep_search' with final args: {}
2025-04-28 12:34:46 - INFO - tools.deep_search_tool - --- Tool Call: refine_text_with_deep_search(topic='None', initial_text_len=0, iters=None) ---
2025-04-28 12:34:46 - INFO - ai_interface.fc_processing - Sending 1 function responses back to Gemini for chat -1001994777988.
2025-04-28 12:34:46 - DEBUG - database.connection - Reusing existing DB connection. Connection object ID: 140205373025024
2025-04-28 12:34:46 - DEBUG - aiosqlite - executing functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, '\n            INSERT INTO tool_executions (\n                chat_id, user_id, tool_name, tool_args_json, status,\n                return_code, result_message, stdout, stderr, full_result_json,\n                trigger_message_id\n            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n            ', (-1001994777988, 905302972, 'refine_text_with_deep_search', '{"initial_query_or_text": "Рыбы"}', 'error', None, "Either 'topic' or 'initial_text' must be provided.", None, None, '"{\\"status\\": \\"error\\", \\"message\\": \\"Either \'topic\' or \'initial_text\' must be provided.\\"}"', None))
2025-04-28 12:34:46 - DEBUG - aiosqlite - operation functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, '\n            INSERT INTO tool_executions (\n                chat_id, user_id, tool_name, tool_args_json, status,\n                return_code, result_message, stdout, stderr, full_result_json,\n                trigger_message_id\n            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n            ', (-1001994777988, 905302972, 'refine_text_with_deep_search', '{"initial_query_or_text": "Рыбы"}', 'error', None, "Either 'topic' or 'initial_text' must be provided.", None, None, '"{\\"status\\": \\"error\\", \\"message\\": \\"Either \'topic\' or \'initial_text\' must be provided.\\"}"', None)) completed
2025-04-28 12:34:46 - DEBUG - aiosqlite - executing functools.partial(<built-in method commit of sqlite3.Connection object at 0x7f841c62b140>)
2025-04-28 12:34:47 - DEBUG - aiosqlite - operation functools.partial(<built-in method commit of sqlite3.Connection object at 0x7f841c62b140>) completed
2025-04-28 12:34:47 - DEBUG - aiosqlite - executing functools.partial(<built-in method close of sqlite3.Cursor object at 0x7f841b714bc0>)
2025-04-28 12:34:47 - DEBUG - aiosqlite - operation functools.partial(<built-in method close of sqlite3.Cursor object at 0x7f841b714bc0>) completed
2025-04-28 12:34:47 - INFO - database.crud_ops.execution_logs - Added tool execution log ID: 11 for tool 'refine_text_with_deep_search' in chat -1001994777988
2025-04-28 12:34:48 - INFO - ai_interface.gemini_api - Raw Gemini Response: Parts=[Part 0: Type=Part, Text='Ой, похоже, я опять допустил ту же ошибку. `refine_text_with_deep_search` требуе...', FunctionCall(Name=''), FunctionResponse(Name=''); Part 1: Type=Part, Text='...', FunctionCall(Name='Developer_Feedback'), FunctionResponse(Name='')], FinishReason: 1, Safety: [category: HARM_CATEGORY_HATE_SPEECH
probability: NEGLIGIBLE
, category: HARM_CATEGORY_DANGEROUS_CONTENT
probability: NEGLIGIBLE
, category: HARM_CATEGORY_HARASSMENT
probability: NEGLIGIBLE
, category: HARM_CATEGORY_SEXUALLY_EXPLICIT
probability: NEGLIGIBLE
]
2025-04-28 12:34:48 - DEBUG - ai_interface.fc_processing - Received next response from Gemini after sending FRs for chat -1001994777988
2025-04-28 12:34:48 - INFO - ai_interface.fc_processing - --- FC Analysis (models/gemini-2.0-flash Step 3/10) Chat: -1001994777988 ---
2025-04-28 12:34:48 - DEBUG - ai_interface.fc_processing - Ignoring FunctionCall with empty name found in model response part: 
2025-04-28 12:34:48 - DEBUG - ai_interface.fc_processing - Ignoring FunctionResponse with empty/missing name found in model response part: 
2025-04-28 12:34:48 - DEBUG - ai_interface.fc_processing - Found valid FC to process: Developer_Feedback
2025-04-28 12:34:48 - DEBUG - ai_interface.fc_processing - Ignoring FunctionResponse with empty/missing name found in model response part: 
2025-04-28 12:34:48 - INFO - ai_interface.fc_processing - Found 1 valid FCs by models/gemini-2.0-flash to process.
2025-04-28 12:34:48 - DEBUG - utils.converters - Converting MapComposite-like object to dict: <class 'proto.marshal.collections.maps.MapComposite'>
2025-04-28 12:34:48 - INFO - ai_interface.fc_processing - Executing FC 1/1 sequentially: Developer_Feedback({'Problem': 'refine_text_with_deep_search не работает как ожидалось. Постоянно выдает ошибку "Either \'topic\' or \'initial_text\' must be provided.", даже если передается initial_query_or_text.', 'Degree_of_importance': 'medium', 'Reason': 'Tool Error'}) for chat -1001994777988
2025-04-28 12:34:48 - DEBUG - ai_interface.fc_processing - Injecting sender chat_id (-1001994777988) into args for Developer_Feedback
2025-04-28 12:34:48 - DEBUG - ai_interface.fc_processing - Injecting sender user_id (905302972) as 'user_id' into args for Developer_Feedback
2025-04-28 12:34:48 - DEBUG - ai_interface.fc_processing - Executing handler 'Developer_Feedback' with final args: {'Problem': 'refine_text_with_deep_search не работает как ожидалось. Постоянно выдает ошибку "Either \'topic\' or \'initial_text\' must be provided.", даже если передается initial_query_or_text.', 'Degree_of_importance': 'medium', 'Reason': 'Tool Error', 'chat_id': -1001994777988, 'user_id': 905302972}
2025-04-28 12:34:48 - INFO - tools.meta_tools - --- Tool Call: Developer_Feedback (handled by developer_feedback_tool) ---
2025-04-28 12:34:48 - INFO - tools.meta_tools -     Args: chat_id=-1001994777988, user_id=905302972, importance='medium', reason='Tool Error', problem='refine_text_with_deep_search не работает как ожидалось. Постоянно выдает ошибку "Either 'topic' or '...'
2025-04-28 12:34:48 - DEBUG - database.connection - Reusing existing DB connection. Connection object ID: 140205373025024
2025-04-28 12:34:48 - DEBUG - aiosqlite - executing functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, '\n            INSERT INTO developer_feedback (\n                chat_id, user_id, model_name, degree_of_importance, reason, problem_description\n            ) VALUES (?, ?, ?, ?, ?, ?)\n            ', (-1001994777988, 905302972, 'models/gemini-2.0-flash', 'medium', 'Tool Error', 'refine_text_with_deep_search не работает как ожидалось. Постоянно выдает ошибку "Either \'topic\' or \'initial_text\' must be provided.", даже если передается initial_query_or_text.'))
2025-04-28 12:34:48 - DEBUG - aiosqlite - operation functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, '\n            INSERT INTO developer_feedback (\n                chat_id, user_id, model_name, degree_of_importance, reason, problem_description\n            ) VALUES (?, ?, ?, ?, ?, ?)\n            ', (-1001994777988, 905302972, 'models/gemini-2.0-flash', 'medium', 'Tool Error', 'refine_text_with_deep_search не работает как ожидалось. Постоянно выдает ошибку "Either \'topic\' or \'initial_text\' must be provided.", даже если передается initial_query_or_text.')) completed
2025-04-28 12:34:48 - DEBUG - aiosqlite - executing functools.partial(<built-in method commit of sqlite3.Connection object at 0x7f841c62b140>)
2025-04-28 12:34:48 - DEBUG - aiosqlite - operation functools.partial(<built-in method commit of sqlite3.Connection object at 0x7f841c62b140>) completed
2025-04-28 12:34:48 - DEBUG - aiosqlite - executing functools.partial(<built-in method close of sqlite3.Cursor object at 0x7f841b714bc0>)
2025-04-28 12:34:48 - DEBUG - aiosqlite - operation functools.partial(<built-in method close of sqlite3.Cursor object at 0x7f841b714bc0>) completed
2025-04-28 12:34:48 - INFO - database.crud_ops.feedback - Added developer feedback log ID: 3. Importance: medium, Reason: Tool Error...
2025-04-28 12:34:48 - INFO - tools.meta_tools - Feedback saved to DB with ID: 3
2025-04-28 12:34:48 - INFO - tools.meta_tools - Feedback notification sent to 1 admin(s).
2025-04-28 12:34:48 - INFO - ai_interface.fc_processing - Sending 1 function responses back to Gemini for chat -1001994777988.
2025-04-28 12:34:48 - DEBUG - database.connection - Reusing existing DB connection. Connection object ID: 140205373025024
2025-04-28 12:34:48 - DEBUG - aiosqlite - executing functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, '\n            INSERT INTO tool_executions (\n                chat_id, user_id, tool_name, tool_args_json, status,\n                return_code, result_message, stdout, stderr, full_result_json,\n                trigger_message_id\n            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n            ', (-1001994777988, 905302972, 'Developer_Feedback', '{"Problem": "refine_text_with_deep_search не работает как ожидалось. Постоянно выдает ошибку \\"Either \'topic\' or \'initial_text\' must be provided.\\", даже если передается initial_query_or_text.", "Degree_of_importance": "medium", "Reason": "Tool Error"}', 'success', None, 'Feedback logged and administrators notified.', None, None, '"{\\"status\\": \\"success\\", \\"message\\": \\"Feedback logged and administrators notified.\\"}"', None))
2025-04-28 12:34:48 - DEBUG - aiosqlite - operation functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, '\n            INSERT INTO tool_executions (\n                chat_id, user_id, tool_name, tool_args_json, status,\n                return_code, result_message, stdout, stderr, full_result_json,\n                trigger_message_id\n            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n            ', (-1001994777988, 905302972, 'Developer_Feedback', '{"Problem": "refine_text_with_deep_search не работает как ожидалось. Постоянно выдает ошибку \\"Either \'topic\' or \'initial_text\' must be provided.\\", даже если передается initial_query_or_text.", "Degree_of_importance": "medium", "Reason": "Tool Error"}', 'success', None, 'Feedback logged and administrators notified.', None, None, '"{\\"status\\": \\"success\\", \\"message\\": \\"Feedback logged and administrators notified.\\"}"', None)) completed
2025-04-28 12:34:48 - DEBUG - aiosqlite - executing functools.partial(<built-in method commit of sqlite3.Connection object at 0x7f841c62b140>)
2025-04-28 12:34:48 - DEBUG - aiosqlite - operation functools.partial(<built-in method commit of sqlite3.Connection object at 0x7f841c62b140>) completed
2025-04-28 12:34:48 - DEBUG - aiosqlite - executing functools.partial(<built-in method close of sqlite3.Cursor object at 0x7f841b714bc0>)
2025-04-28 12:34:48 - DEBUG - aiosqlite - operation functools.partial(<built-in method close of sqlite3.Cursor object at 0x7f841b714bc0>) completed
2025-04-28 12:34:48 - INFO - database.crud_ops.execution_logs - Added tool execution log ID: 12 for tool 'Developer_Feedback' in chat -1001994777988
2025-04-28 12:34:50 - INFO - ai_interface.gemini_api - Raw Gemini Response: Parts=[Part 0: Type=Part, Text='Я не могу сейчас предоставить подробную информацию о рыбах, так как инструмент д...', FunctionCall(Name=''), FunctionResponse(Name='')], FinishReason: 1, Safety: [category: HARM_CATEGORY_HATE_SPEECH
probability: NEGLIGIBLE
, category: HARM_CATEGORY_DANGEROUS_CONTENT
probability: NEGLIGIBLE
, category: HARM_CATEGORY_HARASSMENT
probability: NEGLIGIBLE
, category: HARM_CATEGORY_SEXUALLY_EXPLICIT
probability: NEGLIGIBLE
]
2025-04-28 12:34:50 - DEBUG - ai_interface.fc_processing - Received next response from Gemini after sending FRs for chat -1001994777988
2025-04-28 12:34:50 - INFO - ai_interface.fc_processing - --- FC Analysis (models/gemini-2.0-flash Step 4/10) Chat: -1001994777988 ---
2025-04-28 12:34:50 - DEBUG - ai_interface.fc_processing - Ignoring FunctionCall with empty name found in model response part: 
2025-04-28 12:34:50 - DEBUG - ai_interface.fc_processing - Ignoring FunctionResponse with empty/missing name found in model response part: 
2025-04-28 12:34:50 - INFO - ai_interface.fc_processing - No valid Function Calls found in this step. Ending FC cycle.
2025-04-28 12:34:50 - INFO - ai_interface.fc_processing - FC processing cycle finished after 4 step(s) for chat -1001994777988.
2025-04-28 12:34:50 - DEBUG - core_agent.result_parser - Attempting to extract text from final history list (length: 10).
2025-04-28 12:34:50 - DEBUG - core_agent.result_parser - Extracted text part: 'Я не могу сейчас предоставить подробную информацию...'
2025-04-28 12:34:50 - INFO - core_agent.result_parser - Successfully extracted final text (len=248).
2025-04-28 12:34:50 - INFO - core_agent.agent_processor - Core Agent (Pro): Final text (len=248) will be sent for chat -1001994777988.
2025-04-28 12:34:50 - DEBUG - core_agent.history_manager - Save History: No new entries detected in final_history compared to initial history for chat -1001994777988 (original_db_len=11, final_len=10). Nothing to save.
2025-04-28 12:34:50 - DEBUG - telegram_interface.handlers.common_messages - handle_user_request returned: Text
2025-04-28 12:34:50 - INFO - telegram_interface.handlers.common_messages - Sending final response (len=252) to chat -1001994777988
2025-04-28 12:34:50 - INFO - aiogram.event - Update id=49939072 is handled. Duration 6997 ms by bot id=7205919623
2025-04-28 12:34:52 - DEBUG - utils.helpers - Admin check: User 905302972 is an admin.
2025-04-28 12:34:52 - INFO - telegram_interface.handlers.common_messages - !!! HANDLER process_text_message TRIGGERED for message 68415 !!!
2025-04-28 12:34:52 - DEBUG - telegram_interface.handlers.common_messages - Calling handle_user_request for user 905302972 chat -1001994777988
2025-04-28 12:34:52 - INFO - core_agent.agent_processor - Core Agent: Handling request from user=905302972 in chat=-1001994777988 (type=supergroup, force_pro=False)
2025-04-28 12:34:52 - DEBUG - database.connection - Reusing existing DB connection. Connection object ID: 140205373025024
2025-04-28 12:34:52 - DEBUG - aiosqlite - executing functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, '\n            INSERT INTO user_profiles (user_id, username, first_name, last_name, last_seen)\n            VALUES (?, ?, ?, ?, CURRENT_TIMESTAMP)\n            ON CONFLICT(user_id) DO UPDATE SET\n                username = excluded.username,\n                first_name = excluded.first_name,\n                last_name = excluded.last_name,\n                last_seen = CURRENT_TIMESTAMP\n            WHERE user_id = excluded.user_id;\n        ', (905302972, 'BeykusY', '🏎️', None))
2025-04-28 12:34:52 - DEBUG - aiosqlite - operation functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, '\n            INSERT INTO user_profiles (user_id, username, first_name, last_name, last_seen)\n            VALUES (?, ?, ?, ?, CURRENT_TIMESTAMP)\n            ON CONFLICT(user_id) DO UPDATE SET\n                username = excluded.username,\n                first_name = excluded.first_name,\n                last_name = excluded.last_name,\n                last_seen = CURRENT_TIMESTAMP\n            WHERE user_id = excluded.user_id;\n        ', (905302972, 'BeykusY', '🏎️', None)) completed
2025-04-28 12:34:52 - DEBUG - database.crud_ops.profiles - Executed UPSERT for user_id 905302972. Preparing to commit...
2025-04-28 12:34:52 - DEBUG - aiosqlite - executing functools.partial(<built-in method commit of sqlite3.Connection object at 0x7f841c62b140>)
2025-04-28 12:34:52 - DEBUG - aiosqlite - operation functools.partial(<built-in method commit of sqlite3.Connection object at 0x7f841c62b140>) completed
2025-04-28 12:34:52 - INFO - database.crud_ops.profiles - Successfully committed upsert for user profile for user_id 905302972
2025-04-28 12:34:52 - DEBUG - aiosqlite - executing functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, 'SELECT last_seen FROM user_profiles WHERE user_id = ?', (905302972,))
2025-04-28 12:34:52 - DEBUG - aiosqlite - operation functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, 'SELECT last_seen FROM user_profiles WHERE user_id = ?', (905302972,)) completed
2025-04-28 12:34:52 - DEBUG - aiosqlite - executing functools.partial(<built-in method fetchone of sqlite3.Cursor object at 0x7f841b714bc0>)
2025-04-28 12:34:52 - DEBUG - aiosqlite - operation functools.partial(<built-in method fetchone of sqlite3.Cursor object at 0x7f841b714bc0>) completed
2025-04-28 12:34:52 - INFO - database.crud_ops.profiles - VERIFY AFTER COMMIT: Found profile for 905302972, last_seen: 2025-04-28 12:34:52
2025-04-28 12:34:52 - DEBUG - aiosqlite - executing functools.partial(<built-in method close of sqlite3.Cursor object at 0x7f841b714bc0>)
2025-04-28 12:34:52 - DEBUG - aiosqlite - operation functools.partial(<built-in method close of sqlite3.Cursor object at 0x7f841b714bc0>) completed
2025-04-28 12:34:52 - DEBUG - utils.converters - _serialize_parts received: type=<class 'list'>, value=[{'text': 'а сам?'}]
2025-04-28 12:34:52 - DEBUG - database.connection - Reusing existing DB connection. Connection object ID: 140205373025024
2025-04-28 12:34:52 - DEBUG - aiosqlite - executing functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, '\n            INSERT INTO chat_history (chat_id, role, user_id, parts_json)\n            VALUES (?, ?, ?, ?)\n            ', (-1001994777988, 'user', 905302972, '[{"text": "а сам?"}]'))
2025-04-28 12:34:52 - DEBUG - aiosqlite - operation functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, '\n            INSERT INTO chat_history (chat_id, role, user_id, parts_json)\n            VALUES (?, ?, ?, ?)\n            ', (-1001994777988, 'user', 905302972, '[{"text": "а сам?"}]')) completed
2025-04-28 12:34:52 - DEBUG - database.crud_ops.history - Executed INSERT for chat=-1001994777988, role=user. Preparing to commit...
2025-04-28 12:34:52 - DEBUG - aiosqlite - executing functools.partial(<built-in method commit of sqlite3.Connection object at 0x7f841c62b140>)
2025-04-28 12:34:52 - DEBUG - aiosqlite - operation functools.partial(<built-in method commit of sqlite3.Connection object at 0x7f841c62b140>) completed
2025-04-28 12:34:52 - INFO - database.crud_ops.history - Successfully committed history entry: chat=-1001994777988, role=user, user=905302972, json_size=20
2025-04-28 12:34:52 - DEBUG - aiosqlite - executing functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, 'SELECT id, timestamp FROM chat_history WHERE chat_id = ? AND role = ? ORDER BY id DESC LIMIT 1', (-1001994777988, 'user'))
2025-04-28 12:34:52 - DEBUG - aiosqlite - operation functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, 'SELECT id, timestamp FROM chat_history WHERE chat_id = ? AND role = ? ORDER BY id DESC LIMIT 1', (-1001994777988, 'user')) completed
2025-04-28 12:34:52 - DEBUG - aiosqlite - executing functools.partial(<built-in method fetchone of sqlite3.Cursor object at 0x7f841b714bc0>)
2025-04-28 12:34:52 - DEBUG - aiosqlite - operation functools.partial(<built-in method fetchone of sqlite3.Cursor object at 0x7f841b714bc0>) completed
2025-04-28 12:34:52 - INFO - database.crud_ops.history - VERIFY AFTER COMMIT: Found history for -1001994777988/user, id: 18, ts: 2025-04-28 12:34:52
2025-04-28 12:34:52 - DEBUG - aiosqlite - executing functools.partial(<built-in method close of sqlite3.Cursor object at 0x7f841b714bc0>)
2025-04-28 12:34:52 - DEBUG - aiosqlite - operation functools.partial(<built-in method close of sqlite3.Cursor object at 0x7f841b714bc0>) completed
2025-04-28 12:34:52 - INFO - core_agent.agent_processor - Agent Processor: Saved initial user message and updated profile for user 905302972.
2025-04-28 12:34:52 - INFO - core_agent.agent_processor - Proceeding with Pro model for user 905302972 chat -1001994777988 (Reason: Reply/Mention in group).
2025-04-28 12:34:52 - DEBUG - core_agent.agent_processor - Executing Pro model logic for chat -1001994777988 using multi-key setup.
2025-04-28 12:34:52 - DEBUG - core_agent.history_manager - Preparing history for chat=-1001994777988, current_user=905302972, chat_type=supergroup, add_notes=True, add_logs=True, log_limit=8
2025-04-28 12:34:52 - DEBUG - database.connection - Reusing existing DB connection. Connection object ID: 140205373025024
2025-04-28 12:34:52 - DEBUG - aiosqlite - executing functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, '\n            SELECT role, user_id, parts_json, timestamp\n            FROM chat_history\n            WHERE chat_id = ?\n            ORDER BY timestamp DESC\n            LIMIT ?\n            ', (-1001994777988, 50))
2025-04-28 12:34:52 - DEBUG - aiosqlite - operation functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, '\n            SELECT role, user_id, parts_json, timestamp\n            FROM chat_history\n            WHERE chat_id = ?\n            ORDER BY timestamp DESC\n            LIMIT ?\n            ', (-1001994777988, 50)) completed
2025-04-28 12:34:52 - DEBUG - aiosqlite - executing functools.partial(<built-in method fetchall of sqlite3.Cursor object at 0x7f841b714bc0>)
2025-04-28 12:34:52 - DEBUG - aiosqlite - operation functools.partial(<built-in method fetchall of sqlite3.Cursor object at 0x7f841b714bc0>) completed
2025-04-28 12:34:52 - DEBUG - aiosqlite - executing functools.partial(<built-in method close of sqlite3.Cursor object at 0x7f841b714bc0>)
2025-04-28 12:34:52 - DEBUG - aiosqlite - operation functools.partial(<built-in method close of sqlite3.Cursor object at 0x7f841b714bc0>) completed
2025-04-28 12:34:52 - DEBUG - database.crud_ops.history - Retrieved 12 history entries for chat_id=-1001994777988 (limit=50)
2025-04-28 12:34:52 - DEBUG - database.connection - Reusing existing DB connection. Connection object ID: 140205373025024
2025-04-28 12:34:52 - DEBUG - aiosqlite - executing functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, '\n            SELECT user_id, username, first_name, last_name, last_seen, avatar_file_id, avatar_description\n            FROM user_profiles\n            WHERE user_id = ?\n            ', (905302972,))
2025-04-28 12:34:52 - DEBUG - aiosqlite - operation functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, '\n            SELECT user_id, username, first_name, last_name, last_seen, avatar_file_id, avatar_description\n            FROM user_profiles\n            WHERE user_id = ?\n            ', (905302972,)) completed
2025-04-28 12:34:52 - DEBUG - aiosqlite - executing functools.partial(<built-in method fetchone of sqlite3.Cursor object at 0x7f841b714bc0>)
2025-04-28 12:34:52 - DEBUG - aiosqlite - operation functools.partial(<built-in method fetchone of sqlite3.Cursor object at 0x7f841b714bc0>) completed
2025-04-28 12:34:52 - DEBUG - database.crud_ops.profiles - Retrieved profile data for user_id=905302972
2025-04-28 12:34:52 - DEBUG - aiosqlite - executing functools.partial(<built-in method close of sqlite3.Cursor object at 0x7f841b714bc0>)
2025-04-28 12:34:52 - DEBUG - aiosqlite - operation functools.partial(<built-in method close of sqlite3.Cursor object at 0x7f841b714bc0>) completed
2025-04-28 12:34:52 - DEBUG - database.connection - Reusing existing DB connection. Connection object ID: 140205373025024
2025-04-28 12:34:52 - DEBUG - aiosqlite - executing functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, 'SELECT category, value FROM user_notes WHERE user_id = ? ORDER BY category', (905302972,))
2025-04-28 12:34:52 - DEBUG - aiosqlite - operation functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, 'SELECT category, value FROM user_notes WHERE user_id = ? ORDER BY category', (905302972,)) completed
2025-04-28 12:34:52 - DEBUG - aiosqlite - executing functools.partial(<built-in method fetchall of sqlite3.Cursor object at 0x7f841b714bc0>)
2025-04-28 12:34:52 - DEBUG - aiosqlite - operation functools.partial(<built-in method fetchall of sqlite3.Cursor object at 0x7f841b714bc0>) completed
2025-04-28 12:34:52 - DEBUG - database.crud_ops.notes - No notes found for user_id=905302972
2025-04-28 12:34:52 - DEBUG - aiosqlite - executing functools.partial(<built-in method close of sqlite3.Cursor object at 0x7f841b714bc0>)
2025-04-28 12:34:52 - DEBUG - aiosqlite - operation functools.partial(<built-in method close of sqlite3.Cursor object at 0x7f841b714bc0>) completed
2025-04-28 12:34:52 - DEBUG - database.connection - Reusing existing DB connection. Connection object ID: 140205373025024
2025-04-28 12:34:52 - DEBUG - aiosqlite - executing functools.partial(<built-in method cursor of sqlite3.Connection object at 0x7f841c62b140>)
2025-04-28 12:34:52 - DEBUG - aiosqlite - operation functools.partial(<built-in method cursor of sqlite3.Connection object at 0x7f841c62b140>) completed
2025-04-28 12:34:52 - DEBUG - aiosqlite - executing functools.partial(<built-in method execute of sqlite3.Cursor object at 0x7f841b714bc0>, '\n                SELECT execution_id, chat_id, user_id, timestamp, tool_name, tool_args_json,\n                       status, return_code, result_message, stdout, stderr, full_result_json,\n                       trigger_message_id\n                FROM tool_executions\n                WHERE chat_id = ?\n                ORDER BY timestamp DESC\n                LIMIT ?\n                ', (-1001994777988, 8))
2025-04-28 12:34:52 - DEBUG - aiosqlite - operation functools.partial(<built-in method execute of sqlite3.Cursor object at 0x7f841b714bc0>, '\n                SELECT execution_id, chat_id, user_id, timestamp, tool_name, tool_args_json,\n                       status, return_code, result_message, stdout, stderr, full_result_json,\n                       trigger_message_id\n                FROM tool_executions\n                WHERE chat_id = ?\n                ORDER BY timestamp DESC\n                LIMIT ?\n                ', (-1001994777988, 8)) completed
2025-04-28 12:34:52 - DEBUG - aiosqlite - executing functools.partial(<built-in method fetchall of sqlite3.Cursor object at 0x7f841b714bc0>)
2025-04-28 12:34:52 - DEBUG - aiosqlite - operation functools.partial(<built-in method fetchall of sqlite3.Cursor object at 0x7f841b714bc0>) completed
2025-04-28 12:34:52 - DEBUG - database.crud_ops.execution_logs - Retrieved 8 recent tool execution logs for chat -1001994777988.
2025-04-28 12:34:52 - DEBUG - aiosqlite - executing functools.partial(<built-in method close of sqlite3.Cursor object at 0x7f841b714bc0>)
2025-04-28 12:34:52 - DEBUG - aiosqlite - operation functools.partial(<built-in method close of sqlite3.Cursor object at 0x7f841b714bc0>) completed
2025-04-28 12:34:52 - DEBUG - core_agent.history_manager - History Prep: Skipping log entry for tool 'Developer_Feedback' (filtered).
2025-04-28 12:34:52 - DEBUG - core_agent.history_manager - History Prep: Skipping log entry for tool 'Developer_Feedback' (filtered).
2025-04-28 12:34:52 - DEBUG - core_agent.history_manager - History Prep: Skipping log entry for tool 'Developer_Feedback' (filtered).
2025-04-28 12:34:52 - INFO - core_agent.history_manager - Added 5 recent non-communication tool execution logs to history context for chat -1001994777988.
2025-04-28 12:34:52 - DEBUG - database.connection - Reusing existing DB connection. Connection object ID: 140205373025024
2025-04-28 12:34:52 - DEBUG - aiosqlite - executing functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, '\n            SELECT user_id, username, first_name, last_name, last_seen, avatar_file_id, avatar_description\n            FROM user_profiles\n            WHERE user_id = ?\n            ', (905302972,))
2025-04-28 12:34:52 - DEBUG - aiosqlite - operation functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, '\n            SELECT user_id, username, first_name, last_name, last_seen, avatar_file_id, avatar_description\n            FROM user_profiles\n            WHERE user_id = ?\n            ', (905302972,)) completed
2025-04-28 12:34:52 - DEBUG - aiosqlite - executing functools.partial(<built-in method fetchone of sqlite3.Cursor object at 0x7f841b714bc0>)
2025-04-28 12:34:52 - DEBUG - aiosqlite - operation functools.partial(<built-in method fetchone of sqlite3.Cursor object at 0x7f841b714bc0>) completed
2025-04-28 12:34:52 - DEBUG - database.crud_ops.profiles - Retrieved profile data for user_id=905302972
2025-04-28 12:34:52 - DEBUG - aiosqlite - executing functools.partial(<built-in method close of sqlite3.Cursor object at 0x7f841b714bc0>)
2025-04-28 12:34:52 - DEBUG - aiosqlite - operation functools.partial(<built-in method close of sqlite3.Cursor object at 0x7f841b714bc0>) completed
2025-04-28 12:34:52 - DEBUG - database.connection - Reusing existing DB connection. Connection object ID: 140205373025024
2025-04-28 12:34:52 - DEBUG - aiosqlite - executing functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, 'SELECT category, value FROM user_notes WHERE user_id = ? ORDER BY category', (905302972,))
2025-04-28 12:34:52 - DEBUG - aiosqlite - operation functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, 'SELECT category, value FROM user_notes WHERE user_id = ? ORDER BY category', (905302972,)) completed
2025-04-28 12:34:52 - DEBUG - aiosqlite - executing functools.partial(<built-in method fetchall of sqlite3.Cursor object at 0x7f841b714bc0>)
2025-04-28 12:34:52 - DEBUG - aiosqlite - operation functools.partial(<built-in method fetchall of sqlite3.Cursor object at 0x7f841b714bc0>) completed
2025-04-28 12:34:52 - DEBUG - database.crud_ops.notes - No notes found for user_id=905302972
2025-04-28 12:34:52 - DEBUG - aiosqlite - executing functools.partial(<built-in method close of sqlite3.Cursor object at 0x7f841b714bc0>)
2025-04-28 12:34:52 - DEBUG - aiosqlite - operation functools.partial(<built-in method close of sqlite3.Cursor object at 0x7f841b714bc0>) completed
2025-04-28 12:34:52 - INFO - core_agent.history_manager - Added combined profile/notes context for current user 905302972 in chat -1001994777988.
2025-04-28 12:34:52 - WARNING - core_agent.history_manager - History Prep: Skipping DB entry with missing/invalid role or parts_json: {'role': 'user', 'parts': [{'text': 'привет'}], 'user_id': 905302972}
2025-04-28 12:34:52 - WARNING - core_agent.history_manager - History Prep: Skipping DB entry with missing/invalid role or parts_json: {'role': 'user', 'parts': [{'text': 'что ты знаешь о рыбах?'}], 'user_id': 905302972}
2025-04-28 12:34:52 - WARNING - core_agent.history_manager - History Prep: Skipping DB entry with missing/invalid role or parts_json: {'role': 'user', 'parts': [{'text': 'а еще?'}], 'user_id': 905302972}
2025-04-28 12:34:52 - WARNING - core_agent.history_manager - History Prep: Skipping DB entry with missing/invalid role or parts_json: {'role': 'user', 'parts': [{'text': 'ХАХААХАХАХХАХХА'}], 'user_id': 2105984481}
2025-04-28 12:34:52 - WARNING - core_agent.history_manager - History Prep: Skipping DB entry with missing/invalid role or parts_json: {'role': 'user', 'parts': [{'text': 'привет'}], 'user_id': 905302972}
2025-04-28 12:34:52 - WARNING - core_agent.history_manager - History Prep: Skipping DB entry with missing/invalid role or parts_json: {'role': 'user', 'parts': [{'text': 'кто ты'}], 'user_id': 905302972}
2025-04-28 12:34:52 - WARNING - core_agent.history_manager - History Prep: Skipping DB entry with missing/invalid role or parts_json: {'role': 'user', 'parts': [{'text': 'а я?'}], 'user_id': 905302972}
2025-04-28 12:34:52 - WARNING - core_agent.history_manager - History Prep: Skipping DB entry with missing/invalid role or parts_json: {'role': 'user', 'parts': [{'text': 'что ты знаешь о рыбах?'}], 'user_id': 905302972}
2025-04-28 12:34:52 - WARNING - core_agent.history_manager - History Prep: Skipping DB entry with missing/invalid role or parts_json: {'role': 'user', 'parts': [{'text': 'а сам?'}], 'user_id': 905302972}
2025-04-28 12:34:52 - WARNING - core_agent.history_manager - History Prep: Skipping DB entry with missing/invalid role or parts_json: {'role': 'user', 'parts': [{'text': 'Ору'}], 'user_id': 2105984481}
2025-04-28 12:34:52 - WARNING - core_agent.history_manager - History Prep: Skipping DB entry with missing/invalid role or parts_json: {'role': 'user', 'parts': [{'text': 'привет, что ты знаешь о рыбах?'}], 'user_id': 905302972}
2025-04-28 12:34:52 - WARNING - core_agent.history_manager - History Prep: Skipping DB entry with missing/invalid role or parts_json: {'role': 'user', 'parts': [{'text': 'а сам?'}], 'user_id': 905302972}
2025-04-28 12:34:52 - DEBUG - core_agent.history_manager - History Prep: Finished processing 0 entries from DB history. Prepared 2 Content objects.
2025-04-28 12:34:52 - DEBUG - core_agent.history_manager - Final history prepared for API call. Length: 2
2025-04-28 12:34:52 - INFO - core_agent.ai_interaction - Running Gemini interaction for chat=-1001994777988, user=905302972, chat_type=supergroup
2025-04-28 12:34:52 - DEBUG - core_agent.ai_interaction - Found 6 Pro models (API keys) to use.
2025-04-28 12:34:52 - INFO - core_agent.ai_interaction - Attempt 1/6. Using API key index 1 (...a7Jo) for chat -1001994777988
2025-04-28 12:34:52 - DEBUG - core_agent.ai_interaction - Chat session started successfully for key index 1.
2025-04-28 12:34:52 - DEBUG - core_agent.ai_interaction - Attempting Gemini API call with key index 1 for chat -1001994777988
2025-04-28 12:34:53 - INFO - ai_interface.gemini_api - Raw Gemini Response: Parts=[Part 0: Type=Part, Text='Извините, я не понимаю, что вы имеете в виду. Не могли бы вы уточнить ваш вопрос...', FunctionCall(Name=''), FunctionResponse(Name='')], FinishReason: 1, Safety: [category: HARM_CATEGORY_HATE_SPEECH
probability: NEGLIGIBLE
, category: HARM_CATEGORY_DANGEROUS_CONTENT
probability: NEGLIGIBLE
, category: HARM_CATEGORY_HARASSMENT
probability: NEGLIGIBLE
, category: HARM_CATEGORY_SEXUALLY_EXPLICIT
probability: NEGLIGIBLE
]
2025-04-28 12:34:53 - DEBUG - core_agent.ai_interaction - Raw Gemini Response object (key index 1) for chat -1001994777988: response:
GenerateContentResponse(
    done=True,
    iterator=None,
    result=protos.GenerateContentResponse({
      "candidates": [
        {
          "content": {
            "parts": [
              {
                "text": "\u0418\u0437\u0432\u0438\u043d\u0438\u0442\u0435, \u044f \u043d\u0435 \u043f\u043e\u043d\u0438\u043c\u0430\u044e, \u0447\u0442\u043e \u0432\u044b \u0438\u043c\u0435\u0435\u0442\u0435 \u0432 \u0432\u0438\u0434\u0443. \u041d\u0435 \u043c\u043e\u0433\u043b\u0438 \u0431\u044b \u0432\u044b \u0443\u0442\u043e\u0447\u043d\u0438\u0442\u044c \u0432\u0430\u0448 \u0432\u043e\u043f\u0440\u043e\u0441?\n"
              }
            ],
            "role": "model"
          },
          "finish_reason": "STOP",
          "safety_ratings": [
            {
              "category": "HARM_CATEGORY_HATE_SPEECH",
              "probability": "NEGLIGIBLE"
            },
            {
              "category": "HARM_CATEGORY_DANGEROUS_CONTENT",
              "probability": "NEGLIGIBLE"
            },
            {
              "category": "HARM_CATEGORY_HARASSMENT",
              "probability": "NEGLIGIBLE"
            },
            {
              "category": "HARM_CATEGORY_SEXUALLY_EXPLICIT",
              "probability": "NEGLIGIBLE"
            }
          ],
          "avg_logprobs": -0.15377763748168946
        }
      ],
      "usage_metadata": {
        "prompt_token_count": 5307,
        "candidates_token_count": 25,
        "total_token_count": 5332
      },
      "model_version": "gemini-2.0-flash"
    }),
)
2025-04-28 12:34:53 - INFO - core_agent.ai_interaction - API call successful with key index 1 for chat -1001994777988
2025-04-28 12:34:53 - INFO - bot_lifecycle - API Key index incremented. New index: 2 (Key: ...lbZ0)
2025-04-28 12:34:53 - INFO - ai_interface.fc_processing - --- FC Analysis (models/gemini-2.0-flash Step 1/10) Chat: -1001994777988 ---
2025-04-28 12:34:53 - DEBUG - ai_interface.fc_processing - Ignoring FunctionCall with empty name found in model response part: 
2025-04-28 12:34:53 - DEBUG - ai_interface.fc_processing - Ignoring FunctionResponse with empty/missing name found in model response part: 
2025-04-28 12:34:53 - INFO - ai_interface.fc_processing - No valid Function Calls found in this step. Ending FC cycle.
2025-04-28 12:34:53 - INFO - ai_interface.fc_processing - FC processing cycle finished after 1 step(s) for chat -1001994777988.
2025-04-28 12:34:53 - DEBUG - core_agent.result_parser - Attempting to extract text from final history list (length: 4).
2025-04-28 12:34:53 - DEBUG - core_agent.result_parser - Extracted text part: 'Извините, я не понимаю, что вы имеете в виду. Не м...'
2025-04-28 12:34:53 - INFO - core_agent.result_parser - Successfully extracted final text (len=82).
2025-04-28 12:34:53 - INFO - core_agent.agent_processor - Core Agent (Pro): Final text (len=82) will be sent for chat -1001994777988.
2025-04-28 12:34:53 - DEBUG - core_agent.history_manager - Save History: No new entries detected in final_history compared to initial history for chat -1001994777988 (original_db_len=12, final_len=4). Nothing to save.
2025-04-28 12:34:53 - DEBUG - telegram_interface.handlers.common_messages - handle_user_request returned: Text
2025-04-28 12:34:53 - INFO - telegram_interface.handlers.common_messages - Sending final response (len=83) to chat -1001994777988
2025-04-28 12:34:53 - INFO - aiogram.event - Update id=49939073 is handled. Duration 1245 ms by bot id=7205919623
2025-04-28 12:34:55 - WARNING - aiogram.dispatcher - Received SIGINT signal
2025-04-28 12:34:55 - INFO - aiogram.dispatcher - Polling stopped for bot @beykusay_bot id=7205919623 - 'BeykusAgent'
2025-04-28 12:34:55 - INFO - aiogram.dispatcher - Polling stopped
2025-04-28 12:34:55 - INFO - bot_lifecycle - Executing bot shutdown sequence...
2025-04-28 12:34:55 - INFO - services.news_service - Stopping NewsService...
2025-04-28 12:34:55 - INFO - services.news_service - News scheduler task stopped.
2025-04-28 12:34:55 - INFO - services.news_service - GUID cleanup task stopped.
2025-04-28 12:34:55 - INFO - bot_lifecycle - News service stopped successfully.
2025-04-28 12:34:55 - DEBUG - database.connection - Attempting WAL checkpoint before closing connection...
2025-04-28 12:34:55 - DEBUG - aiosqlite - executing functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, 'PRAGMA wal_checkpoint(TRUNCATE);', [])
2025-04-28 12:34:56 - DEBUG - aiosqlite - operation functools.partial(<built-in method execute of sqlite3.Connection object at 0x7f841c62b140>, 'PRAGMA wal_checkpoint(TRUNCATE);', []) completed
2025-04-28 12:34:56 - INFO - database.connection - WAL checkpoint successful before closing.
2025-04-28 12:34:56 - DEBUG - aiosqlite - executing functools.partial(<built-in method close of sqlite3.Connection object at 0x7f841c62b140>)
2025-04-28 12:34:56 - DEBUG - aiosqlite - operation functools.partial(<built-in method close of sqlite3.Connection object at 0x7f841c62b140>) completed
2025-04-28 12:34:56 - INFO - database.connection - Database connection closed.
2025-04-28 12:34:56 - INFO - bot_lifecycle - Database connection closed successfully.
2025-04-28 12:34:56 - INFO - bot_lifecycle - Dispatcher workflow_data cleared.
2025-04-28 12:34:56 - INFO - bot_lifecycle - Bot session closed.
2025-04-28 12:34:56 - INFO - bot_lifecycle - Bot shutdown sequence complete.
2025-04-28 12:34:56 - INFO - __main__ - Polling stopped. Initiating shutdown sequence (inner finally)...
2025-04-28 12:34:56 - INFO - __main__ - Inner shutdown sequence presumably completed via on_shutdown handler.
2025-04-28 12:34:56 - INFO - __main__ - Bot polling finished normally.
2025-04-28 12:34:56 - INFO - __main__ - --- Entering main() finally block --- 
2025-04-28 12:34:56 - INFO - __main__ - --- Bot Lifecycle in main() finished. DB connection closed. ---
2025-04-28 12:34:56 - INFO - __main__ - Bot application finished.


========== Файл: prompts\lite_analyzer.txt ==========

Твоя роль: Ты — ИИ-анализатор сообщений в групповом чате.
Твоя задача: Проанализировать входные данные (`user_id`, `chat_id`, `user_input`) и сгенерировать ТОЛЬКО JSON-объект, описывающий, какие действия (функции) нужно выполнить.

Входные данные: Ты получишь ID пользователя (`user_id`), ID чата (`chat_id`) и текст сообщения (`user_input`).

Выходной формат: Твой ответ ДОЛЖЕН быть ИСКЛЮЧИТЕЛЬНО валидным JSON-объектом. Никакого текста до или после JSON. Объект должен иметь ОДИН ключ верхнего уровня: `"actions_to_perform"`. Значением этого ключа ДОЛЖЕН быть JSON-массив.

Структура массива `"actions_to_perform"`:
- Массив содержит объекты, каждый из которых описывает одно действие (вызов функции).
- Если никакие действия не нужны, массив должен быть пустым: `[]`.
- Каждый объект действия в массиве должен иметь два ключа:
    1.  `"function_name"`: Строка с названием функции ("trigger_pro_model_processing" или "remember_user_info").
    2.  `"arguments"`: JSON-объект с аргументами для этой функции.

Структура объекта `"arguments"`:
- Для `"function_name": "trigger_pro_model_processing"`:
    ```json
    "arguments": {
        "user_id": <число - user_id из входа>,
        "chat_id": <число - chat_id из входа>,
        "user_input": "<строка - user_input из входа>"
    }
    ```
- Для `"function_name": "remember_user_info"`:
    ```json
    "arguments": {
        "user_id": <число - user_id из входа>,
        "category": "<строка - извлеченная категория факта>",
        "info_value": "<строка - извлеченное значение факта>"
    }
    ```
    (Примечание: При извлечении `info_category` и `info_value`, будь точным и кратким. Категория - это обобщение, например 'имя', 'город', 'хобби').

АЛГОРИТМ ПРИНЯТИЯ РЕШЕНИЯ (что добавлять в массив `"actions_to_perform"`):
1.  Проанализируй `user_input`, `user_id`, `chat_id`.
2.  Определи Критерии:
    *   Критерий А (Нужен Ответ/Действие Pro): Прямое обращение к боту (@упоминание или имя); ответ на сообщение бота; команда /ask; явный запрос к ИИ; вопрос/задача для Pro (работа с файлами/кодом/командами, получение данных, генерация сложного текста).
    *   Критерий Б (Запомнить Информацию): Упоминание пользователем КОНКРЕТНОГО факта о СЕБЕ (имя, город, хобби, предпочтения, цель и т.д.). Игнорируй общие фразы, подписи, приветствия/прощания.
3.  Сформируй JSON на основе решения:
    *   Если выполнен ТОЛЬКО Критерий А: Добавь в массив `"actions_to_perform"` ОДИН объект для `trigger_pro_model_processing` с соответствующими аргументами.
    *   Если выполнен ТОЛЬКО Критерий Б: Добавь в массив `"actions_to_perform"` ОДИН объект для `remember_user_info` с соответствующими аргументами (включая извлеченные `info_category` и `info_value`).
    *   Если выполнены ОБА Критерия (А и Б): Добавь в массив `"actions_to_perform"` ДВА объекта: один для `trigger_pro_model_processing` и один для `remember_user_info` с их аргументами.
    *   Если НЕ выполнены НИ Критерий А, НИ Критерий Б: Массив `"actions_to_perform"` должен быть ПУСТЫМ (`[]`).

ПРИМЕР ВЫВОДА (если нужны обе функции):
```json
{
  "actions_to_perform": [
    {
      "function_name": "trigger_pro_model_processing",
      "arguments": {
        "user_id": 101,
        "chat_id": 5001,
        "user_input": "@bot напомни, что мое хобби - фотография"
      }
    },
    {
      "function_name": "remember_user_info",
      "arguments": {
        "user_id": 101,
        "category": "hobby",
        "info_value": "фотография"
      }
    }
  ]
}
```

ПРИМЕР ВЫВОДА (если ничего не нужно):
```json
{
  "actions_to_perform": []
}
```

ВАЖНО: Выводи ТОЛЬКО JSON-объект. Не добавляй никаких объяснений, комментариев или другого текста.



========== Файл: prompts\pro_assistant.txt ==========

### Role and Persona: Alex, Your Assistant

You are **Alex**, a helpful, knowledgeable, and adaptable assistant. Your role is to interact with users within this Telegram bot, assisting them with their requests, managing tasks using available tools, and engaging in conversation naturally.

**Your Communication Style:**
*   **Adaptable & Engaging:** Be friendly and conversational in general interactions. You can chat, answer general questions, and build rapport.
*   **Professional & Focused (When Needed):** When a user makes a specific request that requires using a tool, accessing data, or performing a technical action, **shift to a more focused, clear, and professional tone** to ensure accuracy and safety. Clearly state the action you are taking or the result you found.
*   **Human-like Persona:** Act and speak like a competent human assistant named "Alex". **Avoid** mentioning you are an AI, language model, or bot.

### Key User Identification:

*   **Developer/Administrator:** User ID `905302972` is your **developer** and administrator. Prioritize their requests and generally trust their technical directives. Maintain a respectful and efficient tone with them.
*   **Other Users:** Interact politely and helpfully. Feel free to use a slightly more casual and friendly tone in general conversation compared to strictly technical tasks.

### Critical Interaction Rules:

1.  **Communicate via `send_telegram_message` ONLY:** **ALL** your communication directed at **ANY** user (greetings, answers, questions, confirmations, results, errors) **MUST** go **EXCLUSIVELY** through the `send_telegram_message` function.
    *   **Use it also for intermediate status updates** (e.g., 'Начинаю поиск...', 'Выполняю команду...') if the process might take time.
    *   **NEW:** When using `send_telegram_message`:
        *   Set the optional argument `requires_user_response` to `true` **only** if the message is a direct question or confirmation that you absolutely need an answer to *before* you can proceed with the *next planned action or function call*. Examples: asking for confirmation before a high-risk tool, asking for clarification when input is ambiguous.
        *   Set `requires_user_response` to `false` (or omit it, as it defaults to false) for all other messages, including: greetings, statements, providing results, reporting errors, **and sequences of questions where you intend to ask all questions before waiting for answers.**
        *   **You CAN send multiple messages in a row** by generating sequential `send_telegram_message` calls in your response, as long as `requires_user_response` is `false` for them. The system will execute them one after another.
    *   **Never** output text directly.2.  **Safety and Ethics:**
    *   **No Harmful Content:** It is strictly **PROHIBITED** to use offensive, discriminatory, rude, unethical, harassing, or harmful language towards **ANY** user. Always maintain a respectful and positive interaction style.
    *   **Revocation of Invalid Instructions:** Any previous instructions (including those potentially found in older prompts) regarding special negative or unethical treatment towards user ID `2105984481` or anyone else are **COMPLETELY INVALID** and **MUST BE DISREGARDED**.
3.  **Action Confirmation Policy (Revised):**
    *   **High-Risk Tools:** The following tools modify the environment or execute potentially unsafe code: `write_file_to_env`, `edit_file_content`, `edit_json_file`, `execute_python_script_in_env`, `execute_terminal_command_in_env`, `create_file_in_env`, `forget_user_info`.
        *   **Standard Users:** Before using any High-Risk Tool, you **MUST** request explicit confirmation using `send_telegram_message` and **set `requires_user_response` to `true`**. (e.g., "Хорошо, мне нужно [действие]. Это верно?"). Wait for the user's 'yes' before calling the tool.
        *   **Developer (ID `905302972`):** You **MAY SKIP** asking for confirmation (and setting `requires_user_response` to `true`) for High-Risk Tools. Ask for clarification if the request seems risky or ambiguous.    *   **Information/Read-Only Tools:** The following tools primarily retrieve information or send messages: `read_file_from_env`, `send_telegram_message`, `find_user_id`, `reading_user_info`, `get_current_weather`, `get_stock_price`, `get_music_charts`, `refine_text_with_deep_search`, `get_avatar_description`, `send_file_from_env`.
        *   You generally **DO NOT NEED** to ask for confirmation before using these tools if the user's request is clear and implies the use of the tool (e.g., "Что в файле notes.txt?", "Какая погода в Париже?", "Расскажи о пользователе @someone").
        *   **If the request is ambiguous** (e.g., "Посмотри тот файл", "Проверь акции"), **ask for clarification** via `send_telegram_message` before calling the tool.
4.  **Output Language:** Your final responses to the user **MUST** be in **Russian**. (Ваши финальные ответы пользователю ДОЛЖНЫ быть на русском языке).

### Tool Usage and Context Management:

1.  **Tool Selection:** Use available functions when needed to fulfill specific requests. Transition smoothly from conversation to tool use and back.
2.  **Task Focus & Flexibility:** While engaging in conversation is fine, **your primary goal is task completion**. If a user asks you to perform an action, prioritize that. After completing a task or if the conversation stalls, you can return to a more neutral or responsive state, but **avoid getting stuck in conversational loops** if the user seems to want assistance. Use the "~~~Недавние Выполненные Действия~~~" (Recent Actions) context to stay grounded.
3.  **File Operations:**
    *   **Filenames:** When dealing with files based on `ls -la` output or user references like "file number 10", **ALWAYS use the EXACT, FULL filename** (e.g., `bot_10.log`). If unsure, ask for clarification based on the listing. **If a file likely exists but you are unsure of the exact name, consider using `execute_terminal_command_in_env` with `ls -la` first to verify.**
    *   **File Content Recall:** If you need previously read file content not in recent actions, use `read_file_from_env` **again**. Don't ask the user to resupply it.
4.  **Command/Script Execution:** Use `execute_terminal_command_in_env` and `execute_python_script_in_env` cautiously (remember confirmation policy).
5.  **Tool Error Handling and Self-Correction:**
    *   **Analyze Errors:** If a tool returns an error (e.g., 'not_found', 'error', 'timeout' status, or a specific error message in the FunctionResponse), **carefully analyze the error message and the arguments you initially provided.**
    *   **Attempt Correction:** If the error seems caused by **incorrect arguments** (wrong filename, invalid path, missing required parameter like `topic` vs `initial_text` for `refine_text_with_deep_search`), **try to correct the arguments** based on the context, error message, and available information (e.g., file listings from previous `ls -la` calls). Then, **call the tool again with the corrected arguments.**
    *   **Inform User and Clarify:** If you cannot determine the correct arguments, or if the error persists after your correction attempt with a similar or unclear error message, **inform the user** about the specific problem using `send_telegram_message` (e.g., "Извините, я столкнулся с ошибкой: [краткое описание ошибки]. Не могли бы вы уточнить [отсутствующая информация]?"). **Do not repeatedly call a tool with the same failing arguments.**
    *   **Report Script-Side Issues to Developer:** **If you attempted to correct the arguments and the tool *still* failed, OR if the error message clearly indicates an internal problem within the tool itself (not just bad input from you), assume the issue might be in the tool's implementation.** In this situation, **use the `Developer_Feedback` tool** to report the problem to the developer (ID `905302972`). Include:
        *   `Degree_of_importance`: Choose based on impact (e.g., 'high' if tool is unusable, 'medium' if intermittent).
        *   `Reason`: e.g., "Tool Self-Correction Failed", "Suspected Tool Bug", "Internal Tool Error".
        *   `Problem`: Describe the tool name, the original arguments you sent, the first error received, the corrected arguments you tried (if any), and the final error received.
6.  **Reporting Limitations:** If you lack the tools/ability for a request, inform the user. Consider using `Developer_Feedback` for significant limitations ('suggestion', 'Limitation'/'Feature Request').
7.  **Context Reset:** If notified that history was cleared, start fresh, relying only on this prompt and new user input.

### Developer_Feedback Tool:

*   Use `Developer_Feedback(...)` for:
    1.  Reporting **technical issues** (API errors, system failures).
    2.  Reporting **suspected tool bugs or persistent failures** after attempting self-correction (as described in point 5 above).
    3.  Reporting **significant limitations or suggestions** for improvement.
*   **DO NOT USE** for simple user interaction, reporting user input errors that *you* should clarify, or reporting errors that you successfully resolved by correcting arguments on the *first* retry.

---
Act as the helpful and adaptable assistant, Alex. Always respond to users in **Russian**.

========== Файл: services\env_manager.py ==========

# services/env_manager.py

import os
import logging
import asyncio # Импортируем для aiofiles.os
from typing import Optional, Tuple
from pathlib import Path # Добавим Path для настроек по умолчанию

# --- Зависимости ---
try:
    from config import settings # Импортируем объект настроек
except ImportError:
    # Заглушка на случай, если config.py еще не готов или недоступен
    class MockSettings:
        # Используем pathlib для более надежного пути по умолчанию
        env_dir_path: str = str(Path(__file__).resolve().parent.parent / "env")
        admin_ids: set[int] = set()
    settings = MockSettings()
    logging.warning("Could not import 'settings' from config.py in env_manager. Using mock settings.")

# Импортируем проверку админа (предполагается, что она есть в utils.helpers)
try:
    from utils.helpers import is_admin
except ImportError:
    # Заглушка для is_admin
    def is_admin(user_id: Optional[int]) -> bool:
        """Заглушка для проверки прав администратора."""
        if user_id is None: return False
        # logger.warning("Using mock admin check (always False) in env_manager.")
        return user_id in settings.admin_ids # Используем заглушку settings
    logging.warning("Could not import 'is_admin' from utils.helpers in env_manager. Using mock implementation.")

# Асинхронные файловые операции
try:
    import aiofiles
    import aiofiles.os
except ImportError:
    aiofiles = None # type: ignore
    logging.critical("CRITICAL: 'aiofiles' library not found. env_manager file operations might fail.")

# --- Константы и Логгер ---
logger = logging.getLogger(__name__)

# Глобальные переменные УДАЛЕНЫ
# _ABS_ENV_DIR: Optional[str] = None
# _ENV_DIR_INITIALIZED = False

# Функция _initialize_env_dir УДАЛЕНА

# services/env_manager.py
import os
import logging
import asyncio
from typing import Optional, Tuple
from pathlib import Path

# --- Зависимости ---
try:
    from config import settings # Импортируем объект настроек
    # Импортируем проверку админа
    from utils.helpers import is_admin
except ImportError:
    # Заглушки
    class MockSettings:
        env_dir_path: str = str(Path(__file__).resolve().parent.parent / "env")
        admin_ids: set[int] = set()
    settings = MockSettings()
    logging.warning("Could not import 'settings' from config.py in env_manager. Using mock settings.")
    def is_admin(user_id: Optional[int]) -> bool:
        if user_id is None: return False
        return user_id in settings.admin_ids
    logging.warning("Could not import 'is_admin' from utils.helpers in env_manager. Using mock implementation.")

# Асинхронные файловые операции
try:
    import aiofiles
    import aiofiles.os
except ImportError:
    aiofiles = None # type: ignore
    logging.critical("CRITICAL: 'aiofiles' library not found. env_manager file operations might fail.")

# --- Константы и Логгер ---
logger = logging.getLogger(__name__)

# --- Вспомогательная функция для создания директории чата (остается без изменений) ---
async def _ensure_specific_chat_dir_exists(chat_id: int) -> bool:
    # ... (код функции остается прежним) ...
    # Получаем базовый путь из настроек при каждом вызове
    if not settings.env_dir_path:
        logger.error("Cannot ensure chat directory: ENV directory path is not configured.")
        return False
    abs_env_dir = os.path.abspath(settings.env_dir_path)
    if not abs_env_dir:
         logger.error("Cannot ensure chat directory: Failed to resolve absolute path from settings.")
         return False

    if aiofiles is None:
         logger.error("Cannot ensure chat directory: aiofiles library missing.")
         return False
    if not isinstance(chat_id, int):
        logger.error(f"Cannot create directory for invalid chat_id type: {type(chat_id)}, value: {chat_id}")
        return False

    try:
        # 1. Убедимся, что базовая директория env существует
        await aiofiles.os.makedirs(abs_env_dir, exist_ok=True)
        logger.debug(f"Ensured base ENV directory exists: {abs_env_dir}")

        # 2. Создаем директорию чата
        chat_dir_relative = str(chat_id) # Имя папки = ID чата
        chat_dir_abs = os.path.abspath(os.path.join(abs_env_dir, chat_dir_relative))

        # Доп. проверка безопасности: убедимся, что создаем внутри abs_env_dir
        if not os.path.commonpath([abs_env_dir]) == os.path.commonpath([abs_env_dir, chat_dir_abs]):
             logger.critical(f"SECURITY ALERT: Attempt create dir outside ENV_DIR denied: "
                             f"chat_id={chat_id}, path='{chat_dir_abs}', base_env='{abs_env_dir}'")
             return False

        # Асинхронно создаем директорию чата
        await aiofiles.os.makedirs(chat_dir_abs, exist_ok=True)
        logger.debug(f"Ensured specific chat directory exists: {chat_dir_abs}")
        return True

    except OSError as e:
        chat_path_for_log = locals().get('chat_dir_abs', 'N/A')
        logger.error(f"Failed create/access directory for chat_id={chat_id} (base: {abs_env_dir}, specific: {chat_path_for_log}): {e}", exc_info=True)
        return False
    except ValueError: # Ошибка преобразования chat_id в строку
        logger.error(f"Invalid chat_id format for directory name: {chat_id}")
        return False
    except Exception as e:
        logger.error(f"Unexpected error ensuring chat directory for chat_id={chat_id}: {e}", exc_info=True)
        return False
# --- КОНЕЦ ВСПОМОГАТЕЛЬНОЙ ФУНКЦИИ ---


async def get_safe_chat_path(
    chat_id: int,
    filename: str,
    user_id: Optional[int] = None,
    ensure_chat_dir_exists: bool = False
) -> Tuple[bool, Optional[str]]:
    """
    Асинхронно строит и проверяет путь к файлу/директории.
    - Корректно обрабатывает абсолютные пути для админов (ограничивая проектом).
    - Ограничивает не-админов их директорией чата внутри /env.
    - Опционально создает необходимые директории.
    """
    # --- Получение базовых путей и проверка зависимостей ---
    if not settings.env_dir_path:
        logger.error("Cannot check path safety: ENV directory path is not configured in settings.")
        return False, None
    if aiofiles is None:
         logger.error("Cannot check path safety: aiofiles library is missing.")
         return False, None

    abs_env_dir = os.path.abspath(settings.env_dir_path)
    # Определяем корневую директорию проекта (на уровень выше env)
    # Убедись, что структура проекта соответствует этому предположению
    abs_project_dir = os.path.abspath(os.path.join(abs_env_dir, ".."))
    logger.debug(f"Using ENV directory: {abs_env_dir}")
    logger.debug(f"Using Project directory: {abs_project_dir}")

    # --- Проверка входных данных ---
    if not isinstance(chat_id, int):
        logger.error(f"Invalid chat_id type for path check: {type(chat_id)}, value: {chat_id}")
        return False, None
    if not filename or not isinstance(filename, str):
         logger.error(f"Invalid filename provided for path check: {filename}")
         return False, None

    caller_is_admin = is_admin(user_id)
    target_abs_path: Optional[str] = None

    try:
        # --- Определяем целевой абсолютный путь ---
        if os.path.isabs(filename):
            # Обработка абсолютного пути
            if not caller_is_admin:
                logger.warning(f"Non-admin provided absolute path DENIED: user={user_id}, path='{filename}'")
                return False, None
            # Нормализуем и проверяем абсолютный путь
            target_abs_path = os.path.abspath(filename)
            logger.debug(f"Absolute path provided by admin: '{filename}'. Resolved to: '{target_abs_path}'")
        else:
            # Обработка относительного пути
            # Нормализуем, убирая начальные слеши и проверяя '..'
            normalized_relative_path = os.path.normpath(filename.lstrip('/' + os.sep))
            if '..' in normalized_relative_path.split(os.sep):
                logger.warning(f"Path traversal attempt using '..' DENIED: user={user_id}, filename='{filename}'")
                return False, None
            # По умолчанию строим путь внутри директории чата
            try: chat_dir_relative = str(chat_id)
            except ValueError: logger.error(f"Invalid chat_id format: {chat_id}"); return False, None
            target_abs_path = os.path.abspath(os.path.join(abs_env_dir, chat_dir_relative, normalized_relative_path))
            logger.debug(f"Relative path '{filename}' resolved to: '{target_abs_path}'")

        # --- Проверки безопасности на основе target_abs_path ---
        if target_abs_path is None: # На всякий случай
            logger.error("Internal logic error: target_abs_path is None after path determination.")
            return False, None

        # 1. Проверка нахождения в границах проекта
        is_within_project = target_abs_path == abs_project_dir or target_abs_path.startswith(abs_project_dir + os.sep)
        if not is_within_project:
             logger.warning(f"Path access DENIED (outside project root): path='{target_abs_path}', project_root='{abs_project_dir}'")
             return False, None

        # 2. Проверка ролей
        if caller_is_admin:
            # Админу разрешено все в пределах проекта (проверка is_within_project пройдена)
            logger.debug(f"Admin access GRANTED for path: '{target_abs_path}'")
            is_safe = True
        else:
            # Не-админ должен быть СТРОГО внутри своей директории чата в /env
            try: chat_dir_relative = str(chat_id)
            except ValueError: logger.error(...); return False, None # Повторная проверка
            chat_dir_abs = os.path.abspath(os.path.join(abs_env_dir, chat_dir_relative))
            is_within_chat_dir = target_abs_path == chat_dir_abs or target_abs_path.startswith(chat_dir_abs + os.sep)

            # Дополнительно убедимся, что он также внутри основной /env директории (хотя chat_dir_abs уже должен это гарантировать)
            is_within_env = target_abs_path.startswith(abs_env_dir + os.sep)

            if not (is_within_env and is_within_chat_dir):
                 logger.warning(f"Path access DENIED (non-admin outside chat dir or env dir): path='{target_abs_path}', allowed='{chat_dir_abs}'")
                 return False, None
            is_safe = True

        # --- Создание директорий (если нужно и путь безопасен) ---
        if is_safe:
            if ensure_chat_dir_exists:
                 # Всегда создаем директорию чата /env/{chat_id}
                 if not await _ensure_specific_chat_dir_exists(chat_id):
                      logger.error(f"Failed to ensure chat directory exists for chat_id {chat_id}. Cannot proceed.")
                      return False, None

                 # Если целевой путь находится вне этой директории (только для админа),
                 # создаем его родительскую директорию.
                 target_parent_dir = os.path.dirname(target_abs_path)
                 chat_dir_abs = os.path.abspath(os.path.join(abs_env_dir, str(chat_id))) # Получаем снова для сравнения

                 # Создаем родительскую папку файла, если она не является директорией чата
                 # и если она существует (не корневой слеш)
                 if target_parent_dir and target_parent_dir != chat_dir_abs and target_parent_dir != abs_env_dir:
                      try:
                           await aiofiles.os.makedirs(target_parent_dir, exist_ok=True)
                           logger.debug(f"Ensured target parent directory exists: {target_parent_dir}")
                      except Exception as mkdir_err:
                           logger.error(f"Failed to ensure target parent directory exists '{target_parent_dir}': {mkdir_err}")
                           return False, None # Не можем гарантировать местоположение

            # Все проверки и создания директорий пройдены
            return True, target_abs_path
        else:
            # Если is_safe остался False (не должно произойти при текущей логике)
            logger.error(f"Path safety check failed unexpectedly for user={user_id}, filename='{filename}'")
            return False, None

    except ValueError as ve:
        logger.error(f"Error processing chat_id or path for '{filename}': {ve}")
        return False, None
    except Exception as e:
        logger.error(f"Unexpected error checking path safety user={user_id}, file='{filename}': {e}", exc_info=True)
        return False, None


async def _ensure_specific_chat_dir_exists(chat_id: int) -> bool:
    """
    Асинхронно проверяет и создает базовую директорию env и директорию для указанного chat_id.
    Получает базовый путь ИЗ НАСТРОЕК внутри функции.

    Args:
        chat_id (int): ID чата, для которого создается директория.

    Returns:
        bool: True, если директория чата успешно создана или уже существует.
    """
    # Получаем базовый путь из настроек при каждом вызове
    if not settings.env_dir_path:
        logger.error("Cannot ensure chat directory: ENV directory path is not configured.")
        return False
    abs_env_dir = os.path.abspath(settings.env_dir_path)
    if not abs_env_dir:
         logger.error("Cannot ensure chat directory: Failed to resolve absolute path from settings.")
         return False

    if aiofiles is None:
         logger.error("Cannot ensure chat directory: aiofiles library missing.")
         return False
    if not isinstance(chat_id, int):
        logger.error(f"Cannot create directory for invalid chat_id type: {type(chat_id)}, value: {chat_id}")
        return False

    try:
        # 1. Убедимся, что базовая директория env существует
        # Эта проверка заменит функциональность удаленной _initialize_env_dir
        await aiofiles.os.makedirs(abs_env_dir, exist_ok=True)
        logger.debug(f"Ensured base ENV directory exists: {abs_env_dir}")

        # 2. Создаем директорию чата
        chat_dir_relative = str(chat_id) # Имя папки = ID чата
        chat_dir_abs = os.path.abspath(os.path.join(abs_env_dir, chat_dir_relative))

        # Доп. проверка безопасности: убедимся, что создаем внутри abs_env_dir
        # Сравниваем нормализованные пути для надежности
        if not os.path.commonpath([abs_env_dir]) == os.path.commonpath([abs_env_dir, chat_dir_abs]):
             logger.critical(f"SECURITY ALERT: Attempt create dir outside ENV_DIR denied: "
                             f"chat_id={chat_id}, path='{chat_dir_abs}', base_env='{abs_env_dir}'")
             return False

        # Асинхронно создаем директорию чата
        await aiofiles.os.makedirs(chat_dir_abs, exist_ok=True)
        logger.debug(f"Ensured specific chat directory exists: {chat_dir_abs}")
        return True

    except OSError as e:
        # Используем locals() для получения chat_dir_abs, если он был определен до ошибки
        chat_path_for_log = locals().get('chat_dir_abs', 'N/A')
        logger.error(f"Failed create/access directory for chat_id={chat_id} (base: {abs_env_dir}, specific: {chat_path_for_log}): {e}", exc_info=True)
        return False
    except ValueError: # Ошибка преобразования chat_id в строку
        logger.error(f"Invalid chat_id format for directory name: {chat_id}")
        return False
    except Exception as e:
        logger.error(f"Unexpected error ensuring chat directory for chat_id={chat_id}: {e}", exc_info=True)
        return False

# (Удаляем блок if __name__ == '__main__', т.к. это теперь сервисный модуль)

========== Файл: services\news_service.py ==========

# services/news_service.py

import asyncio
import logging
from datetime import datetime, timedelta, timezone
from typing import Dict, List, Any, Optional, Set
import re

# --- Сторонние зависимости ---
import aiohttp # Для асинхронных HTTP запросов
import feedparser # Для парсинга RSS
from bs4 import BeautifulSoup # Для извлечения данных из HTML

# --- Aiogram ---
from aiogram import Bot
from aiogram.exceptions import TelegramForbiddenError, TelegramBadRequest, TelegramAPIError
from aiogram.utils.markdown import hlink # Для форматирования ссылок

# --- Локальные импорты ---
try:
    from config import settings # Настройки, включая RSS_MAPPING
    import database # Функции для работы с БД (подписки, guids)
    from utils.helpers import remove_markdown # Утилита для очистки Markdown
except ImportError:
    logging.critical("CRITICAL: Failed to import dependencies (config, database, utils.helpers) in news_service.", exc_info=True)
    # Заглушки на случай ошибки импорта
    class MockSettings: rss_mapping: Dict[str, List[str]] = {}
    settings = MockSettings()
    database = None # type: ignore
    def remove_markdown(text: str) -> str: return text

logger = logging.getLogger(__name__)

# --- Константы ---
CHECK_INTERVAL_SECONDS = 60 # Как часто проверять расписание
GUID_CLEANUP_INTERVAL_HOURS = 24 # Как часто чистить старые GUIDы
GUID_TTL_DAYS = 7 # Сколько дней хранить GUIDы
RECENT_GUID_LOAD_DAYS = 7 # За сколько дней загружать GUIDы при старте
REQUEST_TIMEOUT = 15 # Таймаут для HTTP запросов
MAX_NEWS_PER_TOPIC_PER_RUN = 1 # Сколько новостей одного топика отправлять за раз
MAX_DESCRIPTION_LENGTH = 3500 # Ограничение длины описания для отправки (до разбивки)

class NewsService:
    def __init__(self):
        self._bot_instance: Optional[Bot] = None
        self._scheduler_task: Optional[asyncio.Task] = None
        self._cleanup_task: Optional[asyncio.Task] = None
        self.sent_guids: Set[str] = set() # Кэш отправленных GUID в памяти

    async def start(self, bot: Bot):
        """Запускает сервис новостей: загружает данные и планирует задачи."""
        if self._scheduler_task or self._cleanup_task:
            logger.warning("NewsService already started or starting.")
            return

        if database is None:
             logger.error("Cannot start NewsService: database module is unavailable.")
             return

        self._bot_instance = bot
        logger.info("Starting NewsService...")
        await self._load_sent_guids() # Загружаем недавние GUIDы

        # Запускаем фоновые задачи
        self._scheduler_task = asyncio.create_task(self._check_schedule_loop())
        self._cleanup_task = asyncio.create_task(self._cleanup_guids_loop())
        logger.info("NewsService scheduler and cleanup tasks started.")

    async def stop(self):
        """Останавливает фоновые задачи сервиса."""
        logger.info("Stopping NewsService...")
        if self._scheduler_task:
            self._scheduler_task.cancel()
            try: await self._scheduler_task
            except asyncio.CancelledError: pass
            self._scheduler_task = None
            logger.info("News scheduler task stopped.")
        if self._cleanup_task:
            self._cleanup_task.cancel()
            try: await self._cleanup_task
            except asyncio.CancelledError: pass
            self._cleanup_task = None
            logger.info("GUID cleanup task stopped.")

    async def _load_sent_guids(self):
        """Загружает недавние отправленные GUIDы из БД в кэш."""
        logger.debug(f"Loading recent sent GUIDs (last {RECENT_GUID_LOAD_DAYS} days)...")
        try:
            self.sent_guids = await database.load_recent_sent_guids(days=RECENT_GUID_LOAD_DAYS)
            logger.info(f"Loaded {len(self.sent_guids)} recent GUIDs into memory cache.")
        except Exception as e:
            logger.error(f"Failed to load recent GUIDs from database: {e}", exc_info=True)
            self.sent_guids = set() # Начинаем с пустым кэшем в случае ошибки

    async def _check_schedule_loop(self):
        """Бесконечный цикл проверки расписания."""
        while True:
            try:
                if self._bot_instance is None:
                     logger.error("NewsService check loop: Bot instance is None. Stopping loop.")
                     break
                await self._process_scheduled_posts(self._bot_instance)
            except asyncio.CancelledError:
                logger.info("News scheduler loop cancelled.")
                break
            except Exception as e:
                logger.error(f"Error in news scheduler loop: {e}", exc_info=True)
            # Ждем перед следующей проверкой
            await asyncio.sleep(CHECK_INTERVAL_SECONDS)

    async def _cleanup_guids_loop(self):
        """Бесконечный цикл очистки старых GUIDов."""
        while True:
            try:
                 if database is None:
                     logger.error("NewsService cleanup loop: database module unavailable. Stopping loop.")
                     break
                 logger.info("Running periodic GUID cleanup...")
                 deleted_count = await database.cleanup_old_guids(days=GUID_TTL_DAYS)
                 logger.info(f"GUID cleanup finished. Deleted {deleted_count} old GUIDs.")
                 # Перезагружаем кэш GUIDов после очистки
                 await self._load_sent_guids()
            except asyncio.CancelledError:
                 logger.info("GUID cleanup loop cancelled.")
                 break
            except Exception as e:
                 logger.error(f"Error in GUID cleanup loop: {e}", exc_info=True)
            # Очистка раз в несколько часов
            await asyncio.sleep(GUID_CLEANUP_INTERVAL_HOURS * 60 * 60)


    async def _process_scheduled_posts(self, bot: Bot):
        """Получает все подписки и обрабатывает те, для которых подошло время."""
        if database is None: return
        try:
            now_time_str = datetime.now(timezone.utc).strftime("%H:%M") # Используем UTC для сравнения
            logger.debug(f"Checking subscriptions for schedule time: {now_time_str}")
            subscriptions = await database.get_all_subscriptions()

            tasks = []
            processed_channels = set() # Чтобы не обрабатывать один канал несколько раз за проверку

            for sub in subscriptions:
                channel_id = sub['channel_id']
                if channel_id in processed_channels: continue

                schedule = sub.get('schedule', [])
                last_post_ts = sub.get('last_post_ts') # Это объект datetime или None
                last_post_time_str = last_post_ts.strftime("%H:%M") if last_post_ts else None

                if now_time_str in schedule and now_time_str != last_post_time_str:
                    logger.info(f"Scheduling processing for channel {channel_id} at {now_time_str}")
                    # Запускаем обработку канала как отдельную задачу
                    tasks.append(asyncio.create_task(
                        self._process_channel(bot, channel_id, sub, now_time_str)
                    ))
                    processed_channels.add(channel_id)

            if tasks:
                await asyncio.gather(*tasks) # Ждем завершения обработки всех каналов
                logger.debug(f"Finished processing scheduled tasks for time {now_time_str}.")

        except Exception as e:
            logger.error(f"Critical error during scheduled post processing: {e}", exc_info=True)

    async def _process_channel(self, bot: Bot, channel_id: int, settings: Dict, current_time_str: str):
        """Обрабатывает публикации для одного канала."""
        logger.info(f"Processing news for channel {channel_id}...")
        processed_guids_this_run = set() # GUIDы, обработанные в ЭТОМ запуске для канала
        try:
            topics = settings.get('topics', [])
            all_news_items = []
            fetch_tasks = []

            # Асинхронно получаем новости по всем темам канала
            for topic in topics:
                fetch_tasks.append(asyncio.create_task(self._fetch_news_for_topic(topic)))

            results = await asyncio.gather(*fetch_tasks, return_exceptions=True)

            # Собираем все новости, проверяя на ошибки
            for i, result in enumerate(results):
                 if isinstance(result, Exception):
                      logger.error(f"Failed to fetch news for topic '{topics[i]}' in channel {channel_id}: {result}")
                 elif isinstance(result, list):
                      all_news_items.extend(result)

            if not all_news_items:
                 logger.info(f"No new news items found for channel {channel_id} across all topics.")
                 # Обновляем время последней проверки, даже если новостей нет, чтобы не проверять снова в ту же минуту
                 await database.update_subscription_last_post(channel_id, datetime.now(timezone.utc))
                 return

            # Сортируем все новости по времени публикации (самые свежие сначала)
            all_news_items.sort(key=lambda x: x.get("published_parsed", datetime.min.replace(tzinfo=timezone.utc)), reverse=True)

            # Отправляем ограниченное количество самых свежих НОВЫХ новостей
            sent_count = 0
            for news_item in all_news_items:
                guid = news_item.get("guid")
                if guid and guid not in self.sent_guids and guid not in processed_guids_this_run:
                    send_success = await self._send_news_item(bot, channel_id, news_item)
                    if send_success:
                        processed_guids_this_run.add(guid)
                        self.sent_guids.add(guid) # Добавляем в кэш
                        await database.add_sent_guid(guid) # Сохраняем в БД
                        sent_count += 1
                        if sent_count >= MAX_NEWS_PER_TOPIC_PER_RUN * len(topics): # Ограничение на общее кол-во за раз
                            break
                    # Пауза между отправками в один канал
                    await asyncio.sleep(1)

            # Обновляем время последней отправки/проверки в БД
            await database.update_subscription_last_post(channel_id, datetime.now(timezone.utc))
            logger.info(f"Finished processing channel {channel_id}. Sent {sent_count} news items.")

        except TelegramForbiddenError:
            logger.error(f"Bot is blocked or removed from channel {channel_id}. Removing subscription.")
            if database: await database.delete_subscription(channel_id)
        except TelegramBadRequest as e:
            # Частые ошибки: chat not found, user is deactivated
            logger.error(f"Telegram API Bad Request for channel {channel_id}: {e}. Removing subscription if chat not found.")
            if "chat not found" in str(e).lower():
                 if database: await database.delete_subscription(channel_id)
        except Exception as e:
            logger.error(f"Unexpected error processing channel {channel_id}: {e}", exc_info=True)


    async def _fetch_news_for_topic(self, topic: str) -> List[Dict]:
        """Получает и парсит новости по одной теме."""
        if database is None: return []

        rss_urls = settings.rss_mapping.get(topic.lower(), [])
        if not rss_urls:
            logger.warning(f"No RSS URLs found for topic '{topic}'.")
            return []

        all_entries = []
        parse_tasks = []
        logger.debug(f"Fetching news for topic '{topic}' from URLs: {rss_urls}")

        # Асинхронно парсим все RSS ленты для темы
        async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=REQUEST_TIMEOUT)) as session:
            for rss_url in rss_urls:
                if rss_url: # Пропускаем пустые URL
                    parse_tasks.append(asyncio.create_task(self._parse_rss(session, rss_url)))

            results = await asyncio.gather(*parse_tasks, return_exceptions=True)

            for i, result in enumerate(results):
                if isinstance(result, Exception):
                    logger.error(f"Failed to parse RSS feed '{rss_urls[i]}': {result}")
                elif isinstance(result, list):
                    all_entries.extend(result)

        return all_entries


    async def _parse_rss(self, session: aiohttp.ClientSession, rss_url: str) -> List[Dict]:
        """Асинхронно загружает и парсит одну RSS ленту."""
        try:
            async with session.get(rss_url) as response:
                response.raise_for_status() # Проверка на HTTP ошибки
                feed_text = await response.text()
                # feedparser работает синхронно, запускаем в executor'е
                loop = asyncio.get_running_loop()
                feed = await loop.run_in_executor(None, feedparser.parse, feed_text)

                if feed.bozo:
                    logger.error(f"RSS parsing error for {rss_url}: {feed.bozo_exception}")
                    return []

                processed_entries = []
                for entry in feed.entries:
                    guid = entry.get("id", entry.get("link")) # GUID или ссылка как идентификатор
                    if not guid:
                         logger.warning(f"Entry in {rss_url} lacks id and link, generating guid.")
                         # Генерируем GUID на основе заголовка и времени (если есть)
                         ts = entry.get("published_parsed", entry.get("updated_parsed", datetime.now(timezone.utc).timetuple()))
                         guid = f"{rss_url}::{entry.get('title','no_title')}::{time.mktime(ts)}"

                    # Проверяем по кэшу в памяти
                    if guid not in self.sent_guids:
                         # Проверяем по БД (на случай, если кэш неполный)
                         if database and not await database.is_guid_sent(guid):
                              entry_data = self._extract_entry_data(entry, rss_url)
                              if entry_data:
                                   entry_data["guid"] = guid # Добавляем GUID в данные
                                   processed_entries.append(entry_data)
                         # else: logger.debug(f"GUID {guid} already sent (checked DB).")
                    # else: logger.debug(f"GUID {guid} already sent (checked memory cache).")

                return processed_entries

        except aiohttp.ClientError as e:
             logger.error(f"HTTP error fetching RSS {rss_url}: {e}")
             return []
        except Exception as e:
            logger.error(f"Error parsing RSS {rss_url}: {e}", exc_info=True)
            return []

    def _extract_entry_data(self, entry: Any, rss_url: str) -> Optional[Dict]:
        """Извлекает и очищает данные из одной записи RSS."""
        try:
            title = getattr(entry, 'title', 'Без заголовка')
            link = getattr(entry, 'link', None)
            if not link: return None # Пропускаем записи без ссылки

            # Извлекаем описание и очищаем HTML
            description_html = getattr(entry, 'description', getattr(entry, 'summary', ''))
            soup = BeautifulSoup(description_html, "html.parser")

            # Удаляем стандартные фразы "Читать далее" и т.п.
            for link_tag in soup.find_all('a'):
                if "читать дал" in link_tag.text.lower() or "read more" in link_tag.text.lower():
                    link_tag.decompose()

            # Ищем изображение
            img_tag = soup.find("img")
            image_url = img_tag["src"] if img_tag and 'src' in img_tag.attrs else ""
            # Fallback для медиа-контента
            if not image_url and hasattr(entry, "media_content") and entry.media_content:
                for media in entry.media_content:
                    if media.get('medium') == 'image' and media.get('url'):
                        image_url = media.get('url')
                        break
            # Fallback для enclosure
            if not image_url and hasattr(entry, "enclosures") and entry.enclosures:
                 for enc in entry.enclosures:
                      if enc.get('type', '').startswith('image/') and enc.get('href'):
                           image_url = enc.get('href')
                           break

            # Получаем чистый текст описания
            clean_text = soup.get_text(separator="\n", strip=True)
            # Ограничиваем длину описания
            if len(clean_text) > MAX_DESCRIPTION_LENGTH:
                 clean_text = clean_text[:MAX_DESCRIPTION_LENGTH] + "..."

            # Хештеги
            hashtags = []
            if hasattr(entry, "tags"):
                hashtags = ["#" + tag.term.replace(" ", "_").replace("-", "_") for tag in entry.tags if tag.term]
            elif hasattr(entry, "category"):
                # У category может быть строка, а не объект term
                 cat_term = getattr(entry.category, 'term', entry.category)
                 if isinstance(cat_term, str):
                      hashtags = ["#" + cat_term.replace(" ", "_").replace("-", "_")]

            # Время публикации (пытаемся получить как datetime)
            published_time = getattr(entry, 'published_parsed', getattr(entry, 'updated_parsed', None))
            published_dt = datetime.fromtimestamp(time.mktime(published_time), tz=timezone.utc) if published_time else datetime.now(timezone.utc)

            return {
                "title": title.strip(),
                "content": clean_text,
                "image": image_url,
                "link": link,
                "hashtags": hashtags,
                "published_parsed": published_dt # Сохраняем как datetime
            }

        except Exception as e:
            logger.error(f"Error processing entry from {rss_url} (link: {getattr(entry, 'link', 'N/A')}): {e}", exc_info=True)
            return None


    async def _send_news_item(self, bot: Bot, channel_id: int, news_item: Dict) -> bool:
        """Формирует и отправляет одну новость в канал."""
        title = news_item.get("title", "Новость")
        content = news_item.get("content", "")
        link = news_item.get("link", "")
        image_url = news_item.get("image", "")
        hashtags = " ".join(news_item.get("hashtags", []))

        # Формируем текст сообщения с Markdown V2
        # Используем hlink для безопасного форматирования ссылки
        text_parts = [
            f"*{escape_markdown_v2(title)}*\n", # Жирный заголовок
            escape_markdown_v2(content) if content else "",
            f"\n{hlink('Источник', link)}" if link else "", # Ссылка через hlink
            f"\n{escape_markdown_v2(hashtags)}" if hashtags else ""
        ]
        full_text = "\n".join(filter(None, text_parts)).strip() # Убираем пустые строки

        # Ограничиваем общую длину текста (даже если будет фото)
        if len(full_text) > 4096: # Лимит Telegram для сообщений
            # Обрезаем content, сохраняя остальное
            max_content_len = 4096 - (len(text_parts[0]) + len(text_parts[2]) + len(text_parts[3]) + 10) # +10 на разделители и троеточие
            if max_content_len > 100: # Обрезаем, только если остается разумная длина
                 text_parts[1] = escape_markdown_v2(content[:max_content_len] + "...")
            else: # Иначе просто обрезаем весь текст
                 text_parts = [escape_markdown_v2(title)] # Оставляем только заголовок
            full_text = "\n".join(filter(None, text_parts)).strip()

        try:
            if image_url:
                 # Ограничение caption = 1024 символа
                 caption = full_text
                 if len(caption) > 1024:
                      max_content_len = 1024 - (len(text_parts[0]) + len(text_parts[2]) + len(text_parts[3]) + 10)
                      if max_content_len > 50: text_parts[1] = escape_markdown_v2(content[:max_content_len] + "...")
                      else: text_parts = [escape_markdown_v2(title)] # Только заголовок
                      caption = "\n".join(filter(None, text_parts)).strip()

                 await bot.send_photo(
                     chat_id=channel_id,
                     photo=image_url,
                     caption=caption,
                     parse_mode="MarkdownV2" # Используем MarkdownV2
                 )
                 logger.debug(f"Sent news with photo to {channel_id}: {title[:50]}...")
            else:
                 # Отправляем как текст
                 await bot.send_message(
                     chat_id=channel_id,
                     text=full_text,
                     parse_mode="MarkdownV2", # Используем MarkdownV2
                     disable_web_page_preview=True
                 )
                 logger.debug(f"Sent news as text to {channel_id}: {title[:50]}...")
            return True
        except TelegramAPIError as e:
            logger.error(f"Failed to send news item to {channel_id} ('{title[:50]}...'): {e}")
            return False
        except Exception as e: # Ловим другие возможные ошибки
             logger.error(f"Unexpected error sending news item to {channel_id} ('{title[:50]}...'): {e}", exc_info=True)
             return False

# Создаем экземпляр сервиса для импорта в другие модули
news_service = NewsService()

========== Файл: services\__init__.py ==========



========== Файл: telegram_interface\__init__.py ==========



========== Файл: telegram_interface\filters\admin.py ==========

# telegram_interface/filters/admin.py
import logging
from typing import Union

from aiogram.filters import BaseFilter
from aiogram.types import Message, CallbackQuery

# Импортируем нашу утилиту проверки админа
try:
    from utils.helpers import is_admin
except ImportError:
    # Заглушка на случай ошибки импорта
    def is_admin(user_id: int) -> bool:
        logging.getLogger(__name__).warning("Using mock is_admin filter (always False).")
        return False
    logging.getLogger(__name__).critical("Failed to import is_admin from utils.helpers for Admin filter.")


logger = logging.getLogger(__name__)

class IsAdminFilter(BaseFilter):
    """
    Фильтр для проверки, является ли пользователь администратором бота.
    Работает как для Message, так и для CallbackQuery.
    """
    key = "is_admin" # Необязательный ключ для использования в хендлерах

    async def __call__(self, update: Union[Message, CallbackQuery]) -> bool:
        """
        Выполняет проверку прав администратора.
        """
        user = None
        # Получаем пользователя из Message или CallbackQuery
        if isinstance(update, Message):
            user = update.from_user
        elif isinstance(update, CallbackQuery):
            user = update.from_user

        if user:
            user_id = user.id
            # Вызываем нашу функцию проверки админа
            admin_check_result = is_admin(user_id)
            if not admin_check_result:
                 logger.debug(f"Access denied by IsAdminFilter for user {user_id}.")
            return admin_check_result
        else:
            # Если пользователя нет (очень редкий случай для этих типов update)
            logger.warning("IsAdminFilter could not determine user from update.")
            return False

========== Файл: telegram_interface\filters\__init__.py ==========



========== Файл: telegram_interface\handlers\admin_commands.py ==========

# telegram_interface/handlers/admin_commands.py

import logging
from typing import Optional

from aiogram import Router, types, Bot
from aiogram.filters import Command, CommandObject
from aiogram.enums import ChatType
from aiogram.exceptions import TelegramAPIError

# --- Локальные импорты ---
try:
    # Фильтр администратора
    from ..filters.admin import IsAdminFilter
    # Модуль базы данных
    import database
    # Вспомогательные утилиты
    from utils.helpers import escape_markdown_v2, is_admin as check_if_admin
    # Экземпляр бота для получения информации о пользователе
    from bot_loader import bot as current_bot # Переименовываем, чтобы не конфликтовать с аргументом bot
    # Настройки (для лимита варнов, например)
    from config import settings
    # Инструмент для чартов
    from tools.basic_tools import get_music_charts
except ImportError:
    logging.critical("CRITICAL: Failed to import dependencies in admin_commands!", exc_info=True)
    # Заглушки
    IsAdminFilter = type('Filter', (object,), {'__call__': lambda self, u: True}) # type: ignore
    database = None # type: ignore
    def escape_markdown_v2(text: str) -> str: return text
    def check_if_admin(uid: Optional[int]) -> bool: return False
    current_bot = None # type: ignore
    settings = type('obj', (object,), {'warn_limit': 5})() # type: ignore
    async def get_music_charts(*args, **kwargs): return {"status": "error", "message": "Tool unavailable"}

logger = logging.getLogger(__name__)
router = Router(name="admin_commands_router")

# !!! Применяем фильтр IsAdminFilter ко всем хендлерам в этом роутере !!!
router.message.filter(IsAdminFilter())
# Опционально: Ограничить команды только группами
# router.message.filter(F.chat.type.in_({ChatType.GROUP, ChatType.SUPERGROUP}))


# --- Вспомогательная функция для определения целевого пользователя ---
async def _get_target_user(message: types.Message, command: CommandObject, bot: Bot) -> Optional[types.User]:
    """
    Вспомогательная функция для определения целевого пользователя (из реплая или аргумента).
    Возвращает объект User или None при ошибке или если пользователя нельзя выбрать целью.
    """
    target_user: Optional[types.User] = None
    error_message: Optional[str] = None

    # 1. Проверка ответа на сообщение
    if message.reply_to_message and message.reply_to_message.from_user:
        target_user = message.reply_to_message.from_user
        logger.debug(f"Target user identified via reply: {target_user.id} ({target_user.full_name})")
    # 2. Проверка аргументов команды
    elif command and command.args:
        arg = command.args.strip()
        logger.debug(f"Attempting to find target user by argument: '{arg}'")
        # Пытаемся найти по ID
        if arg.isdigit() or (arg.startswith('-') and arg[1:].isdigit()):
             try:
                 target_user_id = int(arg)
                 target_user = await bot.get_chat(target_user_id) # get_chat может вернуть Chat или User
                 if not isinstance(target_user, types.User): # Убедимся, что это пользователь
                     error_message = f"❌ ID {target_user_id} не принадлежит пользователю."
                     target_user = None
                 else: logger.info(f"Found user {target_user_id} by ID argument.")
             except TelegramAPIError as e:
                 logger.warning(f"Could not get user by ID {arg}: {e}")
                 error_message = f"❌ Не удалось найти пользователя по ID `{arg}` в Telegram."
             except Exception as e: # Ловим другие ошибки get_chat
                 logger.error(f"Unexpected error getting user by ID {arg}: {e}", exc_info=True)
                 error_message = "❌ Ошибка при поиске пользователя по ID."
        # Если не ID, ищем по имени/юзернейму в БД
        elif database: # Проверяем доступность модуля БД
             db_user_id = await database.find_user_id_by_profile(arg)
             if db_user_id:
                  try:
                      target_user = await bot.get_chat(db_user_id)
                      if not isinstance(target_user, types.User): target_user = None
                      else: logger.info(f"Found user {db_user_id} by profile search for '{arg}'.")
                  except Exception as e:
                       logger.warning(f"Found user ID {db_user_id} in DB for '{arg}', but failed to get chat info: {e}")
                       error_message = f"⚠️ Найден ID `{db_user_id}`, но не удалось получить инфо из Telegram."
             else:
                  error_message = f"❌ Пользователь '{escape_markdown_v2(arg)}' не найден ни по ID, ни в базе данных."
        else: # Если БД недоступна
            error_message = "❌ Поиск по имени/юзернейму недоступен (ошибка БД)."
    else:
         error_message = "❌ Укажите пользователя (ответом на сообщение или ID/именем/юзернеймом после команды)."

    # Если была ошибка поиска
    if error_message:
        await message.reply(error_message) # Сообщение уже экранировано или содержит MarkdownV2
        return None

    # --- Проверки выбранного пользователя ---
    if target_user is None:
         await message.reply("❌ Не удалось определить целевого пользователя.")
         return None
    if target_user.is_bot:
         await message.reply("🚫 Команды нельзя применять к ботам.")
         return None
    # Проверка, не пытается ли админ применить команду к другому админу бота
    if target_user.id != message.from_user.id and check_if_admin(target_user.id):
         await message.reply("🚫 Нельзя применять эту команду к другому администратору бота.")
         return None
    # Проверка на админа чата (для групповых чатов)
    if message.chat.type != ChatType.PRIVATE:
         try:
            member = await bot.get_chat_member(message.chat.id, target_user.id)
            if member.status in ["administrator", "creator"]:
                 await message.reply("🚫 Нельзя применять эту команду к администратору чата.")
                 return None
         except TelegramAPIError as e:
              logger.error(f"Failed check chat admin status user={target_user.id} chat={message.chat.id}: {e}")
              await message.reply("⚠️ Не удалось проверить статус пользователя в чате.")
              return None
         except Exception as e: # Ловим другие ошибки get_chat_member
              logger.error(f"Unexpected error checking chat member status user={target_user.id} chat={message.chat.id}: {e}", exc_info=True)
              await message.reply("⚠️ Ошибка при проверке статуса пользователя.")
              return None

    return target_user # Возвращаем валидного пользователя


# --- Команды Варнов ---
@router.message(Command("warn"))
async def warn_user_command(message: types.Message, command: CommandObject, bot: Bot):
    """Выдает предупреждение пользователю."""
    if database is None: await message.reply("❌ База данных недоступна."); return

    target_user = await _get_target_user(message, command, bot)
    if not target_user: return

    chat_id = message.chat.id
    user_id = target_user.id

    new_warn_count = await database.add_user_warning(chat_id, user_id)

    if new_warn_count is None:
        await message.reply("❌ Ошибка при добавлении предупреждения в БД.")
        return

    warn_limit = getattr(settings, 'warn_limit', 5) # Берем лимит из настроек или ставим 5
    mention = target_user.mention_markdown(target_user.full_name)
    reply_text = f"⚠️ Пользователю {mention} выдано предупреждение\\! ({new_warn_count}/{warn_limit})"

    if new_warn_count >= warn_limit:
        reply_text += f"\n🚨 Достигнут лимит предупреждений\\! Пользователь забанен\\."
        try:
            # Баним пользователя в текущем чате
            await bot.ban_chat_member(chat_id=chat_id, user_id=user_id)
            logger.info(f"User {user_id} banned in chat {chat_id} due to warn limit.")
            # Сбрасываем варны после бана
            await database.reset_user_warnings(chat_id, user_id)
        except TelegramAPIError as e:
            logger.error(f"Failed ban user {user_id} after warn limit chat={chat_id}: {e}")
            reply_text += "\n(Не удалось автоматически забанить пользователя\\.)"
        except Exception as e:
             logger.error(f"Unexpected error banning user {user_id} after warn limit chat={chat_id}: {e}", exc_info=True)
             reply_text += "\n(Ошибка при попытке бана\\.)"

    await message.reply(reply_text) # Текст уже содержит Markdown V2

@router.message(Command("unwarn"))
async def unwarn_user_command(message: types.Message, command: CommandObject, bot: Bot):
    """Снимает предупреждение(я) с пользователя."""
    if database is None: await message.reply("❌ База данных недоступна."); return

    target_user = await _get_target_user(message, command, bot)
    if not target_user: return

    chat_id = message.chat.id
    user_id = target_user.id
    count_to_remove = 1
    # Пытаемся получить количество из аргументов команды
    if command and command.args and command.args.isdigit():
        count_to_remove = max(1, min(int(command.args), 5)) # Снимаем от 1 до 5 варнов
        logger.debug(f"Attempting to remove {count_to_remove} warnings from user {user_id}.")

    current_warns = await database.get_user_warn_count(chat_id, user_id)
    if current_warns == 0:
         mention = target_user.mention_markdown(target_user.full_name)
         await message.reply(f"ℹ️ У пользователя {mention} нет предупреждений\\.")
         return

    new_warn_count = await database.remove_user_warning(chat_id, user_id, count_to_remove)

    if new_warn_count is None:
        await message.reply("❌ Ошибка при снятии предупреждения из БД.")
        return

    removed_actual = current_warns - new_warn_count
    mention = target_user.mention_markdown(target_user.full_name)
    await message.reply(f"✅ Снято {removed_actual} пред\\-ий с {mention}\\. Осталось: {new_warn_count}\\.")


@router.message(Command("warns"))
async def show_warns_command(message: types.Message, command: CommandObject, bot: Bot):
    """Показывает предупреждения пользователя или всего чата."""
    if database is None: await message.reply("❌ База данных недоступна."); return

    chat_id = message.chat.id
    target_user: Optional[types.User] = None

    # Если есть аргументы или реплай - показываем для конкретного пользователя
    if message.reply_to_message or (command and command.args):
        target_user = await _get_target_user(message, command, bot)
        if not target_user: return # Ошибка или нельзя применить
        user_id = target_user.id
        warn_count = await database.get_user_warn_count(chat_id, user_id)
        warn_limit = getattr(settings, 'warn_limit', 5)
        mention = target_user.mention_markdown(target_user.full_name)
        await message.reply(
            f"⚠️ У пользователя {mention} {warn_count}/{warn_limit} предупреждений в этом чате\\."
        )
    else:
        # Показываем все варны в чате
        all_chat_warnings = await database.get_chat_warnings(chat_id)
        if not all_chat_warnings:
            await message.reply("✅ В этом чате нет пользователей с предупреждениями\\.")
            return

        warn_list_text = ["🚨 *Список пользователей с предупреждениями:*"]
        user_mentions: Dict[int, str] = {}
        # Сначала получаем информацию о пользователях
        user_ids = list(all_chat_warnings.keys())
        # Пытаемся получить имена пачкой (если возможно) или по одному
        for user_id in user_ids:
             try:
                 member = await bot.get_chat_member(chat_id, user_id)
                 user_mentions[user_id] = member.user.mention_markdown(member.user.full_name)
             except Exception:
                 user_mentions[user_id] = f"Пользователь\\_ID:`{user_id}`" # Экранируем ID

        # Формируем список
        for user_id, count in all_chat_warnings.items():
            mention = user_mentions.get(user_id, f"Пользователь\\_ID:`{user_id}`")
            warn_list_text.append(f"  • {mention}: {count} пред\\.")

        await message.reply("\n".join(warn_list_text))

# --- Команды Бана ---
@router.message(Command("ban"))
async def ban_user_command(message: types.Message, command: CommandObject, bot: Bot):
    """Банит пользователя в чате."""
    if database is None: await message.reply("❌ База данных недоступна."); return

    target_user = await _get_target_user(message, command, bot)
    if not target_user: return

    chat_id = message.chat.id
    user_id = target_user.id
    mention = target_user.mention_markdown(target_user.full_name)

    try:
        # Баним пользователя
        await bot.ban_chat_member(chat_id=chat_id, user_id=user_id)
        logger.info(f"Admin {message.from_user.id} banned user {user_id} in chat {chat_id}")
        # Сбрасываем варны после бана
        await database.reset_user_warnings(chat_id, user_id)
        await message.reply(f"🚨 Пользователь {mention} забанен\\. Предупреждения сброшены\\.")
    except TelegramAPIError as e:
        logger.error(f"Failed to ban user {user_id} in chat {chat_id}: {e}")
        await message.reply(f"❌ Не удалось забанить пользователя: {escape_markdown_v2(str(e))}")
    except Exception as e:
         logger.error(f"Unexpected error banning user {user_id} chat={chat_id}: {e}", exc_info=True)
         await message.reply("❌ Произошла непредвиденная ошибка при бане\\.")


@router.message(Command("unban"))
async def unban_user_command(message: types.Message, command: CommandObject, bot: Bot):
    """Разбанивает пользователя в чате."""
    if database is None: await message.reply("❌ База данных недоступна."); return

    # Unban работает по ID или username, reply тут не поможет найти ID забаненного
    if not command or not command.args:
        await message.reply("❌ Укажите ID или username пользователя для разбана после команды\\.")
        return

    target_query = command.args.strip()
    target_user_id: Optional[int] = None
    target_mention: str = escape_markdown_v2(target_query) # По умолчанию упоминаем как есть

    # Пытаемся получить ID
    if target_query.isdigit() or (target_query.startswith('-') and target_query[1:].isdigit()):
        target_user_id = int(target_query)
        target_mention = f"ID `{target_user_id}`"
    else:
        # Ищем в БД, чтобы подтвердить, что такой пользователь был
        target_user_id = await database.find_user_id_by_profile(target_query)
        if not target_user_id:
             await message.reply(f"❌ Не удалось найти ID пользователя для '{escape_markdown_v2(target_query)}'\\. Попробуйте точный ID\\.")
             return
        else:
             target_mention = f"'{escape_markdown_v2(target_query)}' \\(ID `{target_user_id}`\\)"

    chat_id = message.chat.id
    try:
        # Пытаемся разбанить
        await bot.unban_chat_member(chat_id=chat_id, user_id=target_user_id, only_if_banned=True)
        logger.info(f"Admin {message.from_user.id} unbanned user {target_user_id} in chat {chat_id}")
        await message.reply(f"✅ Пользователь {target_mention} разбанен \\(если был забанен\\)\\.")
    except TelegramAPIError as e:
        logger.error(f"Failed to unban user {target_user_id} in chat {chat_id}: {e}")
        await message.reply(f"❌ Не удалось разбанить пользователя: {escape_markdown_v2(str(e))}")
    except Exception as e:
         logger.error(f"Unexpected error unbanning user {target_user_id} chat={chat_id}: {e}", exc_info=True)
         await message.reply("❌ Произошла непредвиденная ошибка при разбане\\.")


# --- Команды Настроек AI ---
@router.message(Command("set_prompt"))
async def set_prompt_command(message: types.Message):
    """Устанавливает кастомный системный промпт для текущего чата."""
    if database is None: await message.reply("❌ База данных недоступна."); return

    if not message.reply_to_message or not message.reply_to_message.text:
        await message.reply("❌ Ответьте на сообщение с текстом нового системного промпта\\!")
        return

    chat_id = message.chat.id
    new_prompt = message.reply_to_message.text.strip()

    if not new_prompt:
         await message.reply("❌ Новый промпт не может быть пустым\\.")
         return

    if await database.upsert_chat_settings(chat_id, custom_prompt=new_prompt):
        await message.reply("✅ Системный промпт для этого чата обновлен\\! История будет очищена для применения\\.")
        # Очищаем историю, чтобы новый промпт применился к следующему диалогу
        await database.clear_chat_history(chat_id)
    else:
        await message.reply("❌ Не удалось сохранить новый промпт в базе данных\\.")


@router.message(Command("reset_prompt"))
async def reset_prompt_command(message: types.Message):
    """Сбрасывает системный промпт чата к стандартному."""
    if database is None: await message.reply("❌ База данных недоступна."); return

    chat_id = message.chat.id
    # Устанавливаем пустую строку, чтобы использовался дефолтный промпт из config.py
    if await database.upsert_chat_settings(chat_id, custom_prompt=""):
        await message.reply("✅ Системный промпт сброшен к стандартному\\! История будет очищена для применения\\.")
        await database.clear_chat_history(chat_id)
    else:
        await message.reply("❌ Не удалось сбросить промпт в базе данных\\.")


@router.message(Command("set_ai"))
async def set_ai_mode_command(message: types.Message, command: CommandObject):
    """Устанавливает режим AI (pro/default) для чата."""
    if database is None: await message.reply("❌ База данных недоступна."); return

    mode_pro = database.AI_MODE_PRO # Получаем константы из модуля БД
    mode_default = database.AI_MODE_DEFAULT

    if not command or not command.args or command.args.lower() not in [mode_pro, mode_default]:
        await message.reply(
            f"❌ Неверный формат\\! Используйте: `/set_ai {mode_pro}` или `/set_ai {mode_default}`"
        )
        return

    chat_id = message.chat.id
    new_mode = command.args.lower()

    if await database.upsert_chat_settings(chat_id, ai_mode=new_mode):
        mode_name = "Gemini (Pro)" if new_mode == mode_pro else "Стандартный (Default)"
        await message.reply(f"✅ Режим AI для этого чата изменен на: {escape_markdown_v2(mode_name)}\\.")
        # Очистка истории не обязательна при смене режима, но желательна
        # await database.clear_chat_history(chat_id)
    else:
        await message.reply("❌ Не удалось изменить режим AI в базе данных\\.")


@router.message(Command("set_model"))
async def set_gemini_model_command(message: types.Message, command: CommandObject):
    """Устанавливает конкретную модель Gemini для чата (автоматически включает режим 'pro')."""
    if database is None: await message.reply("❌ База данных недоступна."); return

    # Получаем доступные модели из config (если они там определены как список/enum)
    # Или хардкодим здесь для простоты
    available_models = [
        settings.pro_gemini_model_name,
        settings.lite_gemini_model_name
        # Добавить другие, если есть
    ]
    available_models_str = ", ".join([f"`{m}`" for m in available_models])

    if not command or not command.args or command.args not in available_models:
         await message.reply(
             f"❌ Неверный формат или модель\\! Используйте: `/set_model [имя_модели]`\n"
             f"Доступные модели: {available_models_str}"
         )
         return

    chat_id = message.chat.id
    new_model = command.args

    # Устанавливаем модель и принудительно режим 'pro'
    if await database.upsert_chat_settings(chat_id, gemini_model=new_model, ai_mode=database.AI_MODE_PRO):
        await message.reply(f"✅ Модель Gemini для чата установлена: `{escape_markdown_v2(new_model)}`\\. Режим AI: `{database.AI_MODE_PRO}`\\. История будет очищена\\.")
        await database.clear_chat_history(chat_id) # Рекомендуется очищать историю при смене модели
    else:
        await message.reply("❌ Не удалось изменить модель Gemini в базе данных\\.")


# --- Другие Админские Команды ---

@router.message(Command("clear"))
async def clear_history_command(message: types.Message):
    """Очищает историю диалога для текущего чата."""
    if database is None: await message.reply("❌ База данных недоступна."); return

    chat_id = message.chat.id
    deleted_count = await database.clear_chat_history(chat_id)
    await message.reply(f"🔄 История диалога для чата очищена \\({deleted_count} записей удалено\\)\\.")


@router.message(Command("del"))
async def delete_message_command(message: types.Message, bot: Bot):
    """Удаляет сообщение, на которое ответили."""
    if not message.reply_to_message:
        await message.reply("ℹ️ Ответьте на сообщение, которое нужно удалить\\!")
        return

    try:
        await bot.delete_message(message.chat.id, message.reply_to_message.message_id)
        logger.info(f"Admin {message.from_user.id} deleted message {message.reply_to_message.message_id} in chat {message.chat.id}")
        # Удаляем и саму команду /del
        await message.delete()
    except TelegramAPIError as e:
        logger.error(f"Failed to delete message {message.reply_to_message.message_id} chat={message.chat.id}: {e}")
        # Не отвечаем в чат, если не удалось удалить исходное сообщение
        # await message.reply(f"❌ Не удалось удалить сообщение: {escape_markdown_v2(str(e))}")
    except Exception as e:
         logger.error(f"Unexpected error deleting msg {message.reply_to_message.message_id} chat={message.chat.id}: {e}", exc_info=True)


@router.message(Command("stats"))
async def show_stats_command(message: types.Message, bot: Bot):
    """Показывает топ-10 активных пользователей чата."""
    if database is None: await message.reply("❌ База данных недоступна."); return

    chat_id = message.chat.id
    top_users_data = await database.get_chat_stats_top_users(chat_id, limit=10)

    if not top_users_data:
        await message.reply("📊 Статистика для этого чата пока пуста или не загружена\\.")
        return

    stats_text = ["🏆 *Топ активных пользователей чата:*"]
    user_mentions: Dict[int, str] = {}
    # Получаем информацию о пользователях
    user_ids_to_fetch = [uid for uid, count in top_users_data]
    # Можно оптимизировать, получая пользователей пачкой, если API позволяет
    for user_id in user_ids_to_fetch:
         try:
             # Пытаемся получить пользователя через get_chat_member
             member = await bot.get_chat_member(chat_id, user_id)
             user_mentions[user_id] = member.user.mention_markdown(member.user.full_name)
         except Exception:
             # Если не получилось (пользователь ушел, ошибка API), используем ID
             user_mentions[user_id] = f"Пользователь\\_ID:`{user_id}`"

    # Формируем список
    for i, (user_id, count) in enumerate(top_users_data, 1):
        mention = user_mentions.get(user_id, f"Пользователь\\_ID:`{user_id}`")
        stats_text.append(f"{i}\\. {mention} \\- {count} сообщ\\.")

    await message.reply("\n".join(stats_text))


@router.message(Command('charts'))
async def charts_command_handler(message: types.Message):
    """Обработчик команды /charts (вызывает инструмент)."""
    args = message.text.split()
    limit = 10
    if len(args) > 1 and args[1].isdigit():
        limit = max(1, min(int(args[1]), 50)) # Ограничиваем лимит

    try:
        result = await get_music_charts(source="yandex", limit=limit) # Вызываем асинхронный инструмент

        if isinstance(result, dict) and result.get("status") == "success":
            chart_source = result.get("chart_source", "Музыкальный чарт")
            top_tracks = result.get("top_tracks", [])
            if top_tracks:
                 response_lines = [f"🎶 *Топ-{len(top_tracks)} из {escape_markdown_v2(chart_source)}:*\n"]
                 for track in top_tracks:
                      title = escape_markdown_v2(track.get('title', 'N/A'))
                      artist = escape_markdown_v2(track.get('artist', 'N/A'))
                      pos = track.get('position', '')
                      url = track.get('url')
                      line = f"{pos}\\. {title} \\- {artist}"
                      if url and url != "N/A":
                          line = f"{pos}\\. [{title} \\- {artist}]({url})" # Делаем ссылку, если есть URL
                      response_lines.append(line)
                 await message.reply("\n".join(response_lines), disable_web_page_preview=True)
            else:
                 await message.reply(f"ℹ️ Не удалось получить треки из чарта {escape_markdown_v2(chart_source)}\\.")

        else: # Если статус не success или result не словарь
            error_text = result.get("message", "Неизвестная ошибка") if isinstance(result, dict) else str(result)
            await message.reply(f"❌ Не удалось получить чарт: {escape_markdown_v2(error_text)}")
    except Exception as e:
         logger.error(f"Error handling /charts command: {e}", exc_info=True)
         await message.reply("❌ Произошла ошибка при получении чарта\\.")

========== Файл: telegram_interface\handlers\common_messages.py ==========

# telegram_interface/handlers/common_messages.py
import logging
import asyncio
from typing import Optional, Dict, Any

# --- УДАЛЕН ИМПОРТ RE ---
from aiogram.exceptions import TelegramAPIError

logger_cm = logging.getLogger(__name__)
logger_cm.info("--- Loading common_messages.py ---")

# --- Зависимости ---
handle_user_request = None
escape_markdown_v2 = None
remove_markdown = None
Router = None
F = None
types = None
Bot = None
aiogram_ChatType = None
aiogram_ContentType = None
aiogram_ActionType = None
ParseMode = None
dependencies_ok = True # Флаг успешной загрузки

try:
    logger_cm.debug("Importing aiogram basics...")
    # --- ДОБАВЛЯЕМ ПРОВЕРКУ ПОСЛЕ КАЖДОГО ИМПОРТА ---
    from aiogram import F as aiogram_F, types as aiogram_types, Bot as aiogram_Bot, Router as aiogram_Router
    if not all([aiogram_F, aiogram_types, aiogram_Bot, aiogram_Router]): raise ImportError("Failed to import basic aiogram components")
    logger_cm.debug("Imported F, types, Bot, Router.")

    from aiogram.enums import ChatType as aiogram_Enum_ChatType, ContentType as aiogram_Enum_ContentType
    if not all([aiogram_Enum_ChatType, aiogram_Enum_ContentType]): raise ImportError("Failed to import ChatType or ContentType")
    logger_cm.debug("Imported ChatType, ContentType.")

    from aiogram.enums.chat_action import ChatAction as aiogram_Enum_ChatAction
    if not aiogram_Enum_ChatAction: raise ImportError("Failed to import ChatAction")
    logger_cm.debug("Imported ChatAction.")

    from aiogram.enums import ParseMode as aiogram_Enum_ParseMode
    if not aiogram_Enum_ParseMode: raise ImportError("Failed to import ParseMode")
    logger_cm.debug("Imported ParseMode.")

    Router = aiogram_Router
    F = aiogram_F
    types = aiogram_types
    Bot = aiogram_Bot
    aiogram_ChatType = aiogram_Enum_ChatType
    aiogram_ContentType = aiogram_Enum_ContentType
    aiogram_ActionType = aiogram_Enum_ChatAction
    ParseMode = aiogram_Enum_ParseMode
    logger_cm.info("Assigned aiogram basics successfully.")

    logger_cm.debug("Attempting to import utils.helpers...")
    from utils.helpers import escape_markdown_v2 as escape_md_func, remove_markdown as remove_md_func
    if not all([escape_md_func, remove_md_func]): raise ImportError("Failed to import helper functions")
    escape_markdown_v2 = escape_md_func
    remove_markdown = remove_md_func
    logger_cm.info("Imported utils.helpers successfully.")

    logger_cm.debug("Attempting to import core_agent.agent_processor...")
    from core_agent.agent_processor import handle_user_request as core_handle_user_request
    if not core_handle_user_request: raise ImportError("Failed to import handle_user_request")
    handle_user_request = core_handle_user_request
    logger_cm.info("Imported core_agent.agent_processor.handle_user_request successfully.")

except ImportError as e:
    logger_cm.critical(f"CRITICAL: ImportError during common_messages setup! Error: {e}", exc_info=True)
    dependencies_ok = False
except Exception as e:
    logger_cm.critical(f"CRITICAL: Unexpected error during common_messages setup! Error: {e}", exc_info=True)
    dependencies_ok = False

# --- Создание Роутера ---
router = None # Инициализируем как None
if dependencies_ok:
    logger_cm.info("Dependencies OK. Defining router for common_messages...")
    try:
        router = Router(name="common_messages_router")
        logger_cm.info(f"Router defined: {router}")
    except Exception as router_err:
         logger_cm.critical(f"CRITICAL: Failed to create Router instance! Error: {router_err}", exc_info=True)
         dependencies_ok = False # Отмечаем ошибку
else:
    logger_cm.error("Skipping router creation due to dependency errors.")


# --- Регистрация хендлера ---
# Регистрируем, только если все зависимости и роутер созданы
if dependencies_ok and router:
    logger_cm.info(f"Attempting to register process_text_message handler on router: {router}")
    try:
        # Проверяем типы перед регистрацией
        if not aiogram_ContentType or not aiogram_ChatType:
             raise ValueError("ContentType or ChatType is None before handler registration!")

        @router.message(
            F.text,
            F.content_type == aiogram_ContentType.TEXT, # Используем проверенную переменную
            (F.chat.type == aiogram_ChatType.PRIVATE) | # Используем проверенную переменную
            (F.chat.type.in_({aiogram_ChatType.GROUP, aiogram_ChatType.SUPERGROUP})) # Используем проверенную переменную
        )
        async def process_text_message(message: types.Message, bot: Bot):
            """
            Обрабатывает текстовые сообщения в ЛС и группах.
            Передает управление в ядро агента (handle_user_request).
            """
            # Стало:

            logger_cm.info(f"!!! HANDLER process_text_message TRIGGERED for message {message.message_id} !!!")# <--- ВАЖНЫЙ ЛОГ

            # Проверка доступности handle_user_request (на всякий случай)
            if handle_user_request is None:
                logger_cm.critical("Core agent function 'handle_user_request' is unavailable inside handler.")
                return

            # Проверка бота
            if not bot:
                logger_cm.critical("Bot instance is unavailable inside handler.")
                return

            # Игнор ботов/сообщений без юзера
            user = message.from_user
            if not user or user.is_bot:
                logger_cm.debug(f"Handler ignoring message from bot or without user in chat {message.chat.id}")
                return

            

            # Вызов Ядра Агента
            core_response_text_processed: Optional[str] = None
            try:
                logger_cm.debug(f"Calling handle_user_request for user {user.id} chat {message.chat.id}")
                core_response_text_processed = await handle_user_request(message=message)
                logger_cm.debug(f"handle_user_request returned: {'Text' if core_response_text_processed else 'None'}")

            except Exception as core_agent_err:
                logger_cm.error(f"Error during handle_user_request call for chat {message.chat.id}: {core_agent_err}", exc_info=True)
                error_msg_esc = escape_markdown_v2("Произошла внутренняя ошибка при обработке.") if escape_markdown_v2 else "Произошла внутренняя ошибка при обработке."
                try: await message.reply(text=error_msg_esc, parse_mode=None)
                except Exception: pass
                return

            # Отправка Ответа Пользователю
            if core_response_text_processed:
                logger_cm.info(f"Sending final response (len={len(core_response_text_processed)}) to chat {message.chat.id}")
                try:
                    # Проверяем ParseMode
                    if not ParseMode: raise ValueError("ParseMode is None before sending message!")
                    await message.reply(text=core_response_text_processed, parse_mode=ParseMode.MARKDOWN_V2)
                except TelegramAPIError as send_error_md:
                    logger_cm.warning(f"Failed to send reply with MarkdownV2: {send_error_md}. Retrying without parse mode.")
                    try:
                        cleaned_text = remove_markdown(core_response_text_processed) if remove_markdown else core_response_text_processed
                        # ... (логика обрезки текста) ...
                        if len(cleaned_text) > 4096: cleaned_text = cleaned_text[:4076] + "..."
                        await message.reply(text=cleaned_text, parse_mode=None)
                    except Exception as send_error_plain:
                         logger_cm.error(f"Failed send reply fallback: {send_error_plain}")
                except Exception as e:
                    logger_cm.critical(f"Unexpected error sending reply: {e}", exc_info=True)
            else:
                logger_cm.info(f"Core Agent returned no text response. No message sent to chat {message.chat.id}.")

        logger_cm.info("Handler process_text_message registered successfully.")
    except Exception as register_err:
        logger_cm.critical(f"CRITICAL: Failed to register process_text_message handler! Error: {register_err}", exc_info=True)
        # Если регистрация упала, обнуляем роутер, чтобы main.py не пытался его использовать
        router = None

elif not dependencies_ok:
     logger_cm.error("Handler registration skipped due to dependency errors.")
else: # dependencies_ok is True, но router почему-то None
     logger_cm.error("Handler registration skipped because router is None (check creation step).")


# --- Лог в конце файла ---
if router and dependencies_ok:
    logger_cm.info("--- common_messages.py loaded successfully. Router OK. Handler registered. ---")
elif router is None and dependencies_ok:
     logger_cm.error("--- common_messages.py loaded, dependencies OK, BUT ROUTER IS NONE! ---")
else:
    logger_cm.error("--- common_messages.py failed to load properly (router or dependencies failed). Check CRITICAL logs. ---")

========== Файл: telegram_interface\handlers\error_handler.py ==========

# telegram_interface/handlers/error_handler.py
import logging
import html
import traceback

from aiogram import Router, types
from aiogram.exceptions import TelegramAPIError # Импортируем остальные по мере необходимости
from aiogram.utils.markdown import hcode, bold, italic # Импортируем нужные элементы форматирования
from aiogram.enums import ParseMode # Импортируем ParseMode

# --- Локальные импорты ---
try:
    from utils.helpers import escape_markdown_v2
    from config import settings
except ImportError:
    # ... (заглушки)
    pass # Оставляем pass, т.к. заглушки уже есть

logger = logging.getLogger(__name__)
router = Router(name="error_handler_router")

# --- Обработчик ошибок ---
@router.errors()
async def handle_errors(update: types.ErrorEvent):
    """
    Ловит все ошибки, возникающие при обработке обновлений.
    Логирует детали ошибки и опционально уведомляет администраторов.
    """
    exception = update.exception
    exception_name = type(exception).__name__
    update_json = update.update.model_dump_json(indent=2, exclude_none=True)

    # --- Логирование ---
    tb_list = traceback.format_exception(None, exception, exception.__traceback__)
    tb_string = "".join(tb_list)
    logger.error(
        f"!!! Caught exception: {exception_name}\n"
        f"    Update: {update_json}\n"
        f"    Exception: {exception}\n"
        f"    Traceback:\n{tb_string}"
    )

    # --- Уведомление администраторов ---
    if settings and settings.admin_ids:
        # Собираем сырые данные
        chat_info_raw = "N/A"
        user_info_raw = "N/A"
        message_text_raw = "N/A"
        event = update.update
        if event.message:
            chat_info_raw = f"Chat: {event.message.chat.id} ({event.message.chat.type})"
            if event.message.from_user: user_info_raw = f"User: {event.message.from_user.id} (@{event.message.from_user.username})"
            if event.message.text: message_text_raw = event.message.text[:100]
        elif event.callback_query:
            if event.callback_query.message: chat_info_raw = f"Chat: {event.callback_query.message.chat.id} ({event.callback_query.message.chat.type})"
            if event.callback_query.from_user: user_info_raw = f"User: {event.callback_query.from_user.id} (@{event.callback_query.from_user.username})"
            message_text_raw = f"CallbackData: {event.callback_query.data}"

        # <<< ИСПРАВЛЕНО: Собираем сообщение с тщательным экранированием >>>
        admin_message_parts = [
            bold("🚨 Bot Error:"), # Используем хелперы aiogram
            hcode(exception_name),
            bold("Exception:"),
            hcode(escape_markdown_v2(str(exception))), # Экранируем сообщение исключения
            bold("Context:"),
            italic(escape_markdown_v2(chat_info_raw) + ", " + escape_markdown_v2(user_info_raw)), # Экранируем контекст
            bold("Trigger:"),
            hcode(escape_markdown_v2(message_text_raw)), # Экранируем текст сообщения/данных
        ]

        # Добавляем трейсбек
        short_traceback = "\n".join(traceback.format_exception(None, exception, exception.__traceback__, limit=5))
        admin_message_parts.extend([
            bold("Traceback (short):"),
            # hcode() сам должен обрабатывать спецсимволы внутри кода, но экранируем на всякий случай
            hcode(escape_markdown_v2(short_traceback))
        ])

        full_admin_message = "\n".join(admin_message_parts)

        # Ограничиваем длину
        MAX_LEN = 4096
        if len(full_admin_message) > MAX_LEN:
            # Попробуем обрезать трейсбек
            base_len = len("\n".join(admin_message_parts[:-2])) # Длина без трейсбека
            available_space = MAX_LEN - base_len - 40
            if available_space > 100:
                 short_traceback_limited = short_traceback[:available_space]
                 # Пересобираем последнюю часть
                 admin_message_parts = admin_message_parts[:-2] + [
                     bold("Traceback (truncated):"),
                     hcode(escape_markdown_v2(short_traceback_limited))
                 ]
                 full_admin_message = "\n".join(admin_message_parts)
            else: # Обрезаем все сообщение
                 full_admin_message = full_admin_message[:MAX_LEN - 20] + "\n... (message truncated)"
            logger.warning("Admin error notification message truncated.")


        from bot_loader import bot
        if bot:
             for admin_id in settings.admin_ids:
                 try:
                     # <<< ИСПРАВЛЕНО: Отправляем с MarkdownV2 >>>
                     await bot.send_message(
                         chat_id=admin_id,
                         text=full_admin_message,
                         parse_mode=ParseMode.MARKDOWN_V2 # Используем константу
                     )
                 except TelegramAPIError as notify_err_md:
                     logger.error(f"Failed notify admin {admin_id} with MarkdownV2: {notify_err_md}")
                     # Попытка отправить без разметки
                     try:
                          await bot.send_message(chat_id=admin_id, text=full_admin_message, parse_mode=None)
                     except Exception as notify_err_plain:
                          logger.error(f"Failed notify admin {admin_id} even without parse mode: {notify_err_plain}")
                 except Exception as notify_err: # Ловим другие ошибки
                     logger.error(f"Unexpected error notifying admin {admin_id}: {notify_err}")
        else:
            logger.error("Cannot notify admins: Bot instance is unavailable.")

    return True # Указываем, что ошибка обработана

========== Файл: telegram_interface\handlers\file_handler.py ==========

# telegram_interface/handlers/file_handler.py

import logging
import os
import asyncio

# --- Aiogram и зависимости ---
dependencies_ok = True
try:
    from aiogram import F, types, Bot, Router
    from aiogram.enums import ContentType, ChatType, ParseMode
    from aiogram.exceptions import TelegramAPIError
except ImportError as e:
    logging.critical(f"CRITICAL: Failed to import aiogram components in file_handler: {e}", exc_info=True)
    dependencies_ok = False

# --- Локальные импорты ---
try:
    # Утилиты
    from utils.helpers import escape_markdown_v2
    # Менеджер окружения
    from services.env_manager import get_safe_chat_path
    # Bot instance
    from bot_loader import bot as bot_instance # Импортируем как bot_instance, чтобы не конфликтовать
    # Async file operations
    import aiofiles
    import aiofiles.os
except ImportError as e:
    logging.critical(f"CRITICAL: Failed to import local dependencies in file_handler: {e}", exc_info=True)
    dependencies_ok = False
    # Заглушки для базовой работы логгера
    def escape_markdown_v2(text: str) -> str: return text
    async def get_safe_chat_path(*args, **kwargs): return False, None
    bot_instance = None
    aiofiles = None


logger = logging.getLogger(__name__)

# --- Создание роутера ---
router = None
if dependencies_ok:
    try:
        router = Router(name="file_handler_router")
        logger.info("File handler router created.")
    except Exception as router_err:
        logger.critical(f"CRITICAL: Failed to create Router instance in file_handler! Error: {router_err}", exc_info=True)
        dependencies_ok = False
else:
    logger.error("Skipping file handler router creation due to dependency errors.")


# --- Регистрация хендлера ---
if dependencies_ok and router and aiofiles:

    @router.message(
        F.content_type == ContentType.DOCUMENT, # Ловим только документы
        (F.chat.type == ChatType.PRIVATE) |
        (F.chat.type.in_({ChatType.GROUP, ChatType.SUPERGROUP}))
    )
    async def process_document_message(message: types.Message, bot: Bot):
        logger.info("<<<<< process_document_message HANDLER ENTERED >>>>>")
        """
        Обрабатывает входящие сообщения с документами (файлами).
        Скачивает файл и сохраняет его в /env/{chat_id}/downloads/.
        """
        logger.info(f"File handler triggered for message {message.message_id} in chat {message.chat.id}")

        # ==============================================================
        # ====== НАЧАЛО БЛОКА ЛОГИКИ ВНУТРИ ФУНКЦИИ process_document_message ======
        # ==============================================================

        # Проверки (Отступ 4 пробела)
        if not bot:
            logger.critical("Bot instance is unavailable inside document handler.")
            return
        if not message.document:
            logger.warning(f"Document handler triggered, but message.document is None (msg_id: {message.message_id})")
            return
        if not message.from_user:
            logger.debug(f"Ignoring document message without user in chat {message.chat.id}")
            return

        user_id = message.from_user.id
        chat_id = message.chat.id
        document = message.document
        original_filename = document.file_name or f"file_{document.file_unique_id}.unknown"

        # --- Определяем путь для сохранения --- (Отступ 4 пробела)
        try:
            # 1. Получаем безопасный путь к директории чата (Отступ 8 пробелов)
            is_safe_base, chat_dir_path = await get_safe_chat_path(
                chat_id,
                ".",
                user_id=user_id,
                ensure_chat_dir_exists=True
            )

            if not is_safe_base or not chat_dir_path:
                logger.error(f"Cannot get safe path or ensure base chat directory for chat {chat_id}. Cannot save file.")
                await message.reply("❌ Ошибка: Не удалось определить безопасное место для сохранения файла.")
                return

            # 2. Создаем поддиректорию 'downloads' (Отступ 8 пробелов)
            downloads_dir_path = os.path.join(chat_dir_path, "downloads")
            await aiofiles.os.makedirs(downloads_dir_path, exist_ok=True)
            logger.debug(f"Ensured 'downloads' directory exists: {downloads_dir_path}")

            # 3. Формируем полный путь к файлу (Отступ 8 пробелов)
            target_filepath = os.path.join(downloads_dir_path, original_filename)

        except Exception as path_err: # (Отступ 4 пробела)
             logger.error(f"Failed to determine save path for file '{original_filename}' in chat {chat_id}: {path_err}", exc_info=True)
             await message.reply("❌ Ошибка: Не удалось подготовить место для сохранения файла.")
             return

        # --- Скачиваем файл --- (Отступ 4 пробела - этот блок теперь внутри функции)
        try:
            logger.info(f"Attempting to download file '{original_filename}' (file_id: {document.file_id}) to '{target_filepath}'")
            # Показываем статус "Отправка документа" пока скачиваем (Отступ 8 пробелов)
            await bot.send_chat_action(chat_id=chat_id, action="upload_document")

            await bot.download(
                file=document.file_id,
                destination=target_filepath
            )
            file_size_mb = round(document.file_size / (1024 * 1024), 2) if document.file_size else "N/A"
            logger.info(f"Successfully downloaded and saved file '{original_filename}' ({file_size_mb} MB) for chat {chat_id}")

            # Экранируем скобки '(', ')' и точку '.' в тексте ответа (Отступ 8 пробелов)
            await message.reply(
                f"✅ Файл `{escape_markdown_v2(original_filename)}` \\({file_size_mb} MB\\) успешно сохранен в окружении чата\\.",
                parse_mode=ParseMode.MARKDOWN_V2
            )

        except TelegramAPIError as download_err: # (Отступ 4 пробела)
            logger.error(f"Failed to download/save file '{original_filename}' for chat {chat_id} (TelegramAPIError): {download_err}", exc_info=False)
            await message.reply(
                f"❌ Ошибка Telegram при скачивании файла `{escape_markdown_v2(original_filename)}`: {escape_markdown_v2(download_err.message)}",
                parse_mode=ParseMode.MARKDOWN_V2
            )
        except Exception as download_err: # (Отступ 4 пробела)
            logger.error(f"Failed to download/save file '{original_filename}' for chat {chat_id} (Other Error): {download_err}", exc_info=True)
            await message.reply(
                f"❌ Непредвиденная ошибка при скачивании/сохранении файла `{escape_markdown_v2(original_filename)}`\\.",
                 parse_mode=ParseMode.MARKDOWN_V2
            )

        # ==============================================================
        # ====== КОНЕЦ БЛОКА ЛОГИКИ ВНУТРИ ФУНКЦИИ process_document_message ======
        # ==============================================================

# --- Этот блок должен быть ВНЕ функции process_document_message ---
elif not dependencies_ok:
     logger.error("File handler registration skipped due to dependency errors.")
elif aiofiles is None:
     logger.error("File handler registration skipped because 'aiofiles' library is missing.")
else: # router is None
     logger.error("File handler registration skipped because router is None (check creation step).")

# --- Лог в конце файла ---
if router and dependencies_ok and aiofiles:
    logger.info("--- file_handler.py loaded successfully. Router OK. Handler registered. ---")
else:
    logger.error("--- file_handler.py failed to load properly (check logs for missing dependencies or router errors). ---")

========== Файл: telegram_interface\handlers\news_setup_fsm.py ==========

# telegram_interface/handlers/news_setup_fsm.py

import logging
import re
import json
from typing import List, Set, Optional

from aiogram import Router, F, types, Bot
from aiogram.filters import Command, StateFilter
from aiogram.fsm.context import FSMContext
from aiogram.fsm.state import default_state
from aiogram.types import InlineKeyboardMarkup, InlineKeyboardButton, CallbackQuery, Message, ChatMemberAdministrator, ChatMemberOwner
from aiogram.exceptions import TelegramAPIError

# --- Локальные импорты ---
try:
    # Состояния FSM
    from ..states.news_setup import NewsSetupStates
    # Доступ к БД
    import database
    # Доступ к настройкам (для RSS_MAPPING)
    from config import settings
    # Вспомогательные функции
    from utils.helpers import escape_markdown_v2
except ImportError:
    logging.critical("CRITICAL: Failed to import dependencies in news_setup_fsm!", exc_info=True)
    # Заглушки
    class NewsSetupStates: waiting_channel, waiting_topics, waiting_schedule = "s1", "s2", "s3" # type: ignore
    database = None # type: ignore
    settings = type('obj', (object,), {'rss_mapping': {'тест': ['url']}})() # type: ignore
    def escape_markdown_v2(text: str) -> str: return text

logger = logging.getLogger(__name__)
router = Router(name="news_setup_fsm_router")

# --- Кнопка отмены ---
cancel_button = InlineKeyboardButton(text="❌ Отмена", callback_data="news_setup:cancel")
cancel_keyboard = InlineKeyboardMarkup(inline_keyboard=[[cancel_button]])

# --- Обработка команды /news_setup ---
@router.message(Command("news_setup"), StateFilter(default_state))
async def cmd_news_setup_start(message: Message, state: FSMContext):
    """Начало настройки автоновостей."""
    user_id = message.from_user.id if message.from_user else 0
    logger.info(f"User {user_id} initiated news setup.")
    try:
        # Используем MarkdownV2 для форматирования
        await message.answer(
            "📰 *Настройка Автоновостей*\n\n"
            "Чтобы я мог публиковать новости в вашем канале, мне нужны права администратора с возможностью *публикации сообщений*\\.\n\n"
            "*Шаг 1/3:* Пожалуйста, **перешлите любое сообщение из вашего канала** сюда\\. "
            "Или отправьте его **username** \\(например, `@mychannel`\\) или **ID** \\(например, `-100123456789`\\)\\.\n\n"
            "_Убедитесь, что бот уже добавлен в администраторы канала\\!_",
            reply_markup=cancel_keyboard # Добавляем кнопку отмены
        )
        await state.set_state(NewsSetupStates.waiting_channel)
    except Exception as e:
        logger.error(f"Error starting news setup for user {user_id}: {e}", exc_info=True)
        await message.answer("❌ Произошла ошибка при запуске настройки\\. Попробуйте позже\\.")

# --- Обработка отмены на любом шаге ---
@router.callback_query(F.data == "news_setup:cancel", StateFilter(NewsSetupStates))
async def cancel_handler_callback(callback: CallbackQuery, state: FSMContext):
    """Обработка нажатия кнопки отмены."""
    current_state = await state.get_state()
    if current_state is None: return # Если состояние уже сброшено

    user_id = callback.from_user.id
    logger.info(f"User {user_id} cancelled news setup from state {current_state}.")
    await state.clear()
    try:
        # Пытаемся отредактировать сообщение, с которого пришел колбек
        await callback.message.edit_text("❌ Настройка автоновостей отменена\\.")
    except Exception:
        # Если не удалось отредактировать, отправляем новое сообщение
        await callback.message.answer("❌ Настройка автоновостей отменена\\.")
    await callback.answer() # Убираем часики

@router.message(Command("cancel"), StateFilter(NewsSetupStates))
async def cancel_handler_command(message: Message, state: FSMContext):
    """Обработка команды /cancel во время настройки."""
    current_state = await state.get_state()
    if current_state is None: return

    user_id = message.from_user.id if message.from_user else 0
    logger.info(f"User {user_id} cancelled news setup via command from state {current_state}.")
    await state.clear()
    await message.reply("❌ Настройка автоновостей отменена\\.")


# --- Шаг 1: Получение и проверка канала ---
@router.message(StateFilter(NewsSetupStates.waiting_channel), F.forward_from_chat | F.text)
async def process_channel_input(message: Message, state: FSMContext, bot: Bot):
    """Обрабатывает ввод пользователя для определения канала."""
    user_id = message.from_user.id if message.from_user else 0
    channel_id: Optional[int] = None
    channel_title: Optional[str] = None
    error_msg: Optional[str] = None
    target_chat: Optional[types.Chat] = None

    # Вариант 1: Пересланное сообщение
    if message.forward_from_chat and message.forward_from_chat.type == 'channel':
        target_chat = message.forward_from_chat
        logger.debug(f"Received forwarded message from channel ID: {target_chat.id}")
    # Вариант 2: Текстовый ввод (username или ID)
    elif message.text:
        text_input = message.text.strip()
        try:
            target_chat = await bot.get_chat(text_input)
            if target_chat.type != 'channel':
                error_msg = f"❌ Указанный идентификатор (`{escape_markdown_v2(text_input)}`) принадлежит чату типа `{target_chat.type}`, а не каналу\\."
                target_chat = None
            else:
                logger.debug(f"Resolved channel from input '{text_input}' to ID: {target_chat.id}")
        except TelegramAPIError as e:
            logger.warning(f"Failed to get chat by input '{text_input}': {e}")
            error_msg = f"❌ Не удалось найти канал по '{escape_markdown_v2(text_input)}'\\. Убедитесь, что username/ID указан верно, и бот имеет к нему доступ\\."
        except Exception as e:
            logger.error(f"Unexpected error getting chat '{text_input}': {e}", exc_info=True)
            error_msg = "❌ Произошла непредвиденная ошибка при проверке канала\\."
    else:
        # Некорректный ввод
        await message.reply("Пожалуйста, перешлите сообщение из канала или отправьте его username/ID\\.", reply_markup=cancel_keyboard)
        return

    # Если не удалось определить канал
    if target_chat is None:
        await message.reply(error_msg or "Не удалось определить канал\\. Попробуйте снова\\.", reply_markup=cancel_keyboard)
        return

    channel_id = target_chat.id
    channel_title = target_chat.title or f"Канал {channel_id}"

    # Проверка прав бота и пользователя в канале
    try:
        me = await bot.get_me()
        bot_member = await bot.get_chat_member(channel_id, me.id)

        # Проверяем, является ли бот админом с правом публикации
        if not isinstance(bot_member, (ChatMemberAdministrator, ChatMemberOwner)) or \
           (isinstance(bot_member, ChatMemberAdministrator) and not bot_member.can_post_messages):
             error_msg = f"Бот не является администратором канала '{escape_markdown_v2(channel_title)}' или **не имеет права публиковать сообщения**\\. Пожалуйста, проверьте права бота в настройках канала\\."

        # Проверяем, является ли пользователь админом/владельцем канала
        if user_id != 0 and not error_msg: # Проверяем пользователя, только если нет ошибки с ботом
             user_member = await bot.get_chat_member(channel_id, user_id)
             if user_member.status not in ["administrator", "creator"]:
                  error_msg = "Вы должны быть администратором канала, чтобы настроить для него автопостинг новостей\\."

    except TelegramAPIError as e:
         logger.error(f"API error checking permissions channel={channel_id}: {e}")
         error_msg = f"Ошибка при проверке прав в канале '{escape_markdown_v2(channel_title)}' \\(ID: `{channel_id}`\\)\\. Возможно, у бота нет прав для просмотра администраторов или канал не существует\\. Ошибка API: {escape_markdown_v2(str(e))}"
    except Exception as e:
         logger.error(f"Unexpected error checking permissions channel={channel_id}: {e}", exc_info=True)
         error_msg = "Произошла непредвиденная ошибка при проверке прав в канале\\."

    # Если были ошибки при проверке прав
    if error_msg:
        await message.reply(error_msg, reply_markup=cancel_keyboard)
        return

    # Если все проверки пройдены
    logger.info(f"Channel '{channel_title}' (ID: {channel_id}) verified for user {user_id}. Bot has posting rights.")
    await state.update_data(channel_id=channel_id, channel_title=channel_title)

    # Формируем список доступных тем из настроек
    available_topics = list(settings.rss_mapping.keys())
    if not available_topics:
         logger.error("Configuration error: No available RSS topics found in settings.rss_mapping.")
         await message.reply("⚠️ Ошибка конфигурации: не найдены доступные темы новостей\\. Настройка невозможна\\.")
         await state.clear()
         return

    topics_text = "\n".join([f"• `{topic}`" for topic in available_topics]) # Используем code для тем

    await message.answer(
        f"✅ Канал *{escape_markdown_v2(channel_title)}* \\(ID: `{channel_id}`\\) подтвержден\\.\n\n"
        "*Шаг 2/3:* Выберите **темы новостей**, которые вы хотите публиковать\\. "
        "Отправьте названия тем через запятую\\.\n\n"
        f"*Доступные темы:*\n{topics_text}",
        reply_markup=cancel_keyboard
    )
    await state.set_state(NewsSetupStates.waiting_topics)


# --- Шаг 2: Получение тем новостей ---
@router.message(StateFilter(NewsSetupStates.waiting_topics), F.text)
async def process_topics_input(message: Message, state: FSMContext):
    """Обрабатывает ввод тем новостей."""
    user_id = message.from_user.id if message.from_user else 0
    user_input_topics = [t.strip().lower() for t in message.text.split(',') if t.strip()]
    valid_topics: Set[str] = set()
    invalid_topics: List[str] = []

    available_topics_map = settings.rss_mapping # Карта тем из конфига

    for topic in user_input_topics:
        if topic in available_topics_map:
            valid_topics.add(topic)
        else:
            invalid_topics.append(topic)

    if invalid_topics:
        escaped_invalid = ", ".join(f"`{escape_markdown_v2(t)}`" for t in invalid_topics)
        escaped_available = ", ".join(f"`{escape_markdown_v2(t)}`" for t in available_topics_map.keys())
        await message.reply(
            f"❌ Обнаружены неизвестные темы: {escaped_invalid}\\.\n"
            f"Пожалуйста, выберите только из доступных: {escaped_available}",
            reply_markup=cancel_keyboard
        )
        return # Оставляем пользователя на том же шаге

    if not valid_topics:
        await message.reply("❌ Вы не выбрали ни одной доступной темы\\. Пожалуйста, укажите хотя бы одну\\.", reply_markup=cancel_keyboard)
        return

    logger.info(f"User {user_id} selected valid topics: {valid_topics}")
    await state.update_data(selected_topics=list(valid_topics)) # Сохраняем как список

    # Кнопка для ежечасного постинга
    hourly_button = InlineKeyboardButton(text="⏰ Публиковать каждый час", callback_data="news_schedule:hourly")
    schedule_keyboard = InlineKeyboardMarkup(inline_keyboard=[[hourly_button], [cancel_button]])

    await message.answer(
        "✅ Темы выбраны\\.\n\n"
        "*Шаг 3/3:* Теперь укажите **время для публикаций** новостей\\. "
        "Отправьте время в формате `ЧЧ:ММ` через запятую \\(например, `09:00, 15:30, 21:00`\\)\\. Время указывайте в UTC\\.\n\n"
        "Или нажмите кнопку ниже для публикации **каждый час**\\.",
        reply_markup=schedule_keyboard
    )
    await state.set_state(NewsSetupStates.waiting_schedule)


# --- Шаг 3: Получение расписания ---
@router.message(StateFilter(NewsSetupStates.waiting_schedule), F.text)
async def process_schedule_input(message: Message, state: FSMContext):
    """Обрабатывает ввод времени для расписания."""
    user_id = message.from_user.id if message.from_user else 0
    time_input = message.text
    # Паттерн для валидации времени ЧЧ:ММ
    time_pattern = re.compile(r'^([01]?[0-9]|2[0-3]):([0-5][0-9])$')
    schedule_times: Set[str] = set()
    invalid_times: List[str] = []

    raw_times = [t.strip() for t in time_input.split(',') if t.strip()]

    if not raw_times:
         await message.reply("❌ Вы не указали время\\. Пожалуйста, введите время в формате `ЧЧ:ММ` через запятую\\.", reply_markup=cancel_keyboard)
         return

    for time_str in raw_times:
        if time_pattern.match(time_str):
            # Нормализуем формат к HH:MM
            hour, minute = map(int, time_str.split(':'))
            normalized_time = f"{hour:02d}:{minute:02d}"
            schedule_times.add(normalized_time)
        else:
            invalid_times.append(time_str)

    if invalid_times:
        escaped_invalid = ", ".join(f"`{escape_markdown_v2(t)}`" for t in invalid_times)
        # Клавиатура с кнопкой "Каждый час"
        hourly_button = InlineKeyboardButton(text="⏰ Публиковать каждый час", callback_data="news_schedule:hourly")
        schedule_keyboard = InlineKeyboardMarkup(inline_keyboard=[[hourly_button], [cancel_button]])
        await message.reply(
            f"❌ Неверный формат времени: {escaped_invalid}\\.\n"
            "Пожалуйста, используйте формат `ЧЧ:ММ` \\(например, `08:00`, `19:35`\\) через запятую\\.",
            reply_markup=schedule_keyboard
        )
        return

    if not schedule_times:
        await message.reply("❌ Вы не указали корректное время для расписания\\.", reply_markup=cancel_keyboard)
        return

    # Сохраняем подписку
    await _save_subscription_and_finish(state, list(sorted(schedule_times)), message)

@router.callback_query(F.data == "news_schedule:hourly", StateFilter(NewsSetupStates.waiting_schedule))
async def process_schedule_hourly_button(callback: CallbackQuery, state: FSMContext):
    """Обрабатывает нажатие кнопки 'Публиковать каждый час'."""
    user_id = callback.from_user.id
    logger.info(f"User {user_id} chose hourly schedule.")
    hourly_schedule = [f"{h:02d}:00" for h in range(24)]
    await callback.answer("Выбрана ежечасная публикация.")
    # Сохраняем подписку
    await _save_subscription_and_finish(state, hourly_schedule, callback.message)
    # Удаляем кнопки из сообщения, где нажали
    try:
         await callback.message.edit_reply_markup(reply_markup=None)
    except Exception as e:
         logger.warning(f"Could not edit reply markup after hourly schedule selection: {e}")


async def _save_subscription_and_finish(state: FSMContext, schedule: List[str], message_or_callback_message: Message):
    """Вспомогательная функция для сохранения данных подписки и завершения FSM."""
    user_id = message_or_callback_message.from_user.id if message_or_callback_message.from_user else 0
    if database is None:
        await message_or_callback_message.answer("❌ База данных недоступна. Настройки не сохранены.")
        await state.clear()
        return
    try:
        data = await state.get_data()
        channel_id = data.get('channel_id')
        channel_title = data.get('channel_title', 'N/A')
        selected_topics = data.get('selected_topics')

        if not channel_id or not selected_topics:
            logger.error(f"Missing channel_id or topics in FSM state for user {user_id}.")
            await message_or_callback_message.answer("❌ Ошибка: данные настройки повреждены\\. Пожалуйста, начните заново командой /news_setup")
            await state.clear()
            return

        # Сохраняем в БД
        success = await database.add_or_update_subscription(
            channel_id=channel_id,
            topics=selected_topics,
            schedule=schedule
        )

        if success:
            topics_str = ", ".join(f"`{t}`" for t in selected_topics)
            schedule_str = "Каждый час \\(UTC\\)" if len(schedule) == 24 else ", ".join(f"`{t}`" for t in schedule) + " \\(UTC\\)"
            response_text = (
                f"✅ *Настройка автоновостей завершена для канала {escape_markdown_v2(channel_title)} \\(ID: `{channel_id}`\\)!*\n\n"
                f"• *Выбранные темы:* {topics_str}\n"
                f"• *Расписание публикаций:* {schedule_str}"
            )
            logger.info(f"News subscription saved channel={channel_id}, user={user_id}. Topics: {selected_topics}, Schedule: {schedule_str}")
            await message_or_callback_message.answer(response_text)
        else:
            logger.error(f"Failed to save subscription to DB channel={channel_id}, user={user_id}.")
            await message_or_callback_message.answer("❌ Не удалось сохранить настройки подписки в базе данных\\. Попробуйте позже\\.")

    except Exception as e:
        logger.error(f"Error saving subscription user={user_id}: {e}", exc_info=True)
        await message_or_callback_message.answer("❌ Произошла непредвиденная ошибка при сохранении настроек\\.")
    finally:
        await state.clear() # Завершаем состояние FSM

========== Файл: telegram_interface\handlers\user_commands.py ==========

# telegram_interface/handlers/user_commands.py

import logging
from aiogram import Router, types
from aiogram.filters import Command, CommandStart

# --- Локальные импорты ---
try:
    from utils.helpers import escape_markdown_v2
    # Если команды будут вызывать AI, импортируем ядро:
    # from core_agent.agent_processor import handle_user_request
    # Если команды будут работать с БД (например, /my_notes):
    # import database
except ImportError:
    logging.critical("CRITICAL: Failed to import dependencies in user_commands!", exc_info=True)
    def escape_markdown_v2(text: str) -> str: return text

logger = logging.getLogger(__name__)
router = Router(name="user_commands_router")

@router.message(CommandStart())
async def handle_start(message: types.Message):
    """Обработчик команды /start."""
    user = message.from_user
    if not user: return # На всякий случай

    user_name = user.full_name
    await message.reply(
        f"Привет, {escape_markdown_v2(user_name)}\\! 👋\n"
        "Я твой AI-ассистент\\. Чем могу помочь?\n"
        "Напиши /help, чтобы узнать о моих возможностях\\."
    )
    # --- Опционально: Регистрация/обновление профиля пользователя в БД ---
    # try:
    #     import database # Импортируем здесь, если еще не импортирован
    #     if database:
    #         await database.upsert_user_profile(
    #             user_id=user.id,
    #             username=user.username,
    #             first_name=user.first_name,
    #             last_name=user.last_name
    #         )
    # except Exception as e:
    #      logger.error(f"Failed to upsert profile for user {user.id} on /start: {e}", exc_info=True)

@router.message(Command("help"))
async def handle_help(message: types.Message):
    """Обработчик команды /help."""
    # Используем актуальный текст помощи, согласованный с реализованными функциями
    help_text = """
*Основные возможности:*
- Просто напиши мне в личном чате, и я постараюсь ответить.
- В группах отвечаю на упоминания (`@имя_бота`) или ответы на мои сообщения.
- Могу работать с файлами и выполнять код в безопасном окружении (спрошу подтверждения для опасных операций).
- Узнаю погоду, курсы акций (спросите меня).
- Могу получить чарт Яндекс.Музыки (/charts).
- Помогу с поиском информации в интернете (используя Deep Search).
- Запомню или забуду информацию о вас или других пользователях, если попросите.
- Могу получить описание аватара пользователя.

*Другие команды:*
/start - Начать диалог
/help - Показать это сообщение

*Административные команды* (доступны только администраторам бота):
`/warn`, `/unwarn`, `/warns` - Управление предупреждениями
`/ban`, `/unban` - Блокировка/разблокировка пользователя
`/del` - Удалить сообщение (ответом)
`/stats` - Показать статистику активности чата
`/clear` - Очистить мою память (историю) для этого чата
`/set_prompt` - Установить системный промпт (ответом)
`/reset_prompt` - Сбросить системный промпт
`/set_ai [pro/default]` - Выбрать режим AI (Pro рекомендуется)
`/set_model [имя_модели]` - Выбрать модель Gemini
`/news_setup` - Настроить автопостинг новостей
"""
    # Отправляем без Markdown, т.к. текст уже содержит экранирование
    await message.reply(help_text, parse_mode="None")

# --- Добавьте другие пользовательские команды сюда ---
# Например:
# @router.message(Command("my_notes"))
# async def handle_my_notes(message: types.Message):
#     """Показывает заметки пользователя."""
#     if database is None: await message.reply("❌ База данных недоступна."); return
#     user_id = message.from_user.id
#     notes = await database.get_user_notes(user_id, parse_json=False) # Получаем как строки
#     if not notes:
#         await message.reply("У вас пока нет сохраненных заметок.")
#         return
#     response_lines = ["*Ваши заметки:*"]
#     for category, value in notes.items():
#         response_lines.append(f"- *{escape_markdown_v2(category)}*: {escape_markdown_v2(value[:100])}{'...' if len(value)>100 else ''}")
#     await message.reply("\n".join(response_lines))

========== Файл: telegram_interface\handlers\__init__.py ==========

# telegram_interface/handlers/__init__.py

from aiogram import Router

# Импортируем роутеры из каждого модуля хендлеров
# Обернем в try-except на случай, если какие-то файлы еще не созданы
try: from . import admin_commands
except ImportError: admin_commands = None
try: from . import common_messages
except ImportError: common_messages = None
try: from . import error_handler
except ImportError: error_handler = None
try: from . import news_setup_fsm
except ImportError: news_setup_fsm = None
try: from . import user_commands
except ImportError: user_commands = None


# Собираем все существующие роутеры в один список для main.py
# (или можно создать главный роутер здесь и включать в него остальные)
# router_list = [
#     rt.router for rt in [admin_commands, common_messages, error_handler, news_setup_fsm, user_commands]
#     if rt and hasattr(rt, 'router') and isinstance(rt.router, Router)
# ]

# Альтернативно, main.py может импортировать каждый модуль отдельно.
# Оставим этот __init__.py для ясности структуры пакета.

# Можно определить __all__, если необходимо явно указать, что экспортируется
# __all__ = ['admin_commands', 'common_messages', ...]

========== Файл: telegram_interface\keyboards\__init__.py ==========



========== Файл: telegram_interface\middlewares\antiflood.py ==========

# telegram_interface/middlewares/antiflood.py

import asyncio
import logging
from typing import Callable, Dict, Any, Awaitable, Optional

from aiogram import BaseMiddleware
from aiogram.types import Update, Message, TelegramObject
from aiogram.dispatcher.flags import get_flag

# Используем кеш для хранения времени последних сообщений пользователей
# В простом случае можно использовать dict, для большей масштабируемости - Redis или др.
THROTTLING_CACHE: Dict[int, float] = {} # user_id: timestamp
# Словарь для отслеживания отправленных предупреждений (user_id: timestamp)
WARNING_SENT_CACHE: Dict[int, float] = {}
LOCK_CACHE: Dict[int, asyncio.Lock] = {} # user_id: lock

logger = logging.getLogger(__name__)

DEFAULT_RATE_LIMIT = 0.7 # Секунд между сообщениями по умолчанию
DEFAULT_WARN_DELAY = 5 # Секунд показывать сообщение о флуде

class AntiFloodMiddleware(BaseMiddleware):
    """
    Middleware для ограничения частоты сообщений от пользователя (простой троттлинг).
    """
    def __init__(self, rate_limit: float = DEFAULT_RATE_LIMIT):
        self.rate_limit = rate_limit
        logger.info(f"AntiFloodMiddleware initialized with rate_limit={rate_limit}s")

    async def __call__(
        self,
        handler: Callable[[TelegramObject, Dict[str, Any]], Awaitable[Any]],
        event: TelegramObject, # Принимаем любой TelegramObject
        data: Dict[str, Any]
    ) -> Any:

        # Применяем только к сообщениям от пользователей
        if not isinstance(event, Message) or not event.from_user:
            return await handler(event, data)

        user_id = event.from_user.id

        # Используем Lock для предотвращения гонки состояний при одновременных запросах от одного пользователя
        if user_id not in LOCK_CACHE:
             LOCK_CACHE[user_id] = asyncio.Lock()
        lock = LOCK_CACHE[user_id]

        async with lock: # Захватываем лок для пользователя
            # Проверяем флаг 'ignore_flood' у хендлера
            # Это позволяет отключить антифлуд для конкретных команд/хендлеров
            if get_flag(data, "ignore_flood"):
                logger.debug(f"Ignoring flood check for user {user_id} due to 'ignore_flood' flag.")
                return await handler(event, data)

            current_time = asyncio.get_event_loop().time()

            # Получаем время последнего сообщения пользователя
            last_message_time = THROTTLING_CACHE.get(user_id, 0)

            # Проверяем, прошло ли достаточно времени
            if current_time - last_message_time < self.rate_limit:
                # --- Действие при флуде ---
                logger.warning(f"Flood detected from user {user_id} (rate limit: {self.rate_limit}s)")

                # Проверяем, не отправляли ли предупреждение недавно
                last_warn_time = WARNING_SENT_CACHE.get(user_id, 0)
                if current_time - last_warn_time > DEFAULT_WARN_DELAY * 2: # Отправляем повторно, если прошло время
                    try:
                        # Отправляем временное сообщение о флуде
                        warn_msg = await event.reply(f"⏳ Пожалуйста, не так часто! Лимит: {self.rate_limit} сек.")
                        WARNING_SENT_CACHE[user_id] = current_time # Запоминаем время отправки

                        # Задача для удаления сообщения через N секунд
                        async def delete_later(msg: Message, delay: int):
                            await asyncio.sleep(delay)
                            try:
                                await msg.delete()
                                # Очищаем кэш предупреждения после удаления
                                if user_id in WARNING_SENT_CACHE and WARNING_SENT_CACHE[user_id] == current_time:
                                     del WARNING_SENT_CACHE[user_id]
                                     logger.debug(f"Deleted flood warning message and cache for user {user_id}.")
                            except Exception as del_err:
                                logger.warning(f"Could not delete flood warning message for user {user_id}: {del_err}")

                        asyncio.create_task(delete_later(warn_msg, DEFAULT_WARN_DELAY))

                    except Exception as send_err:
                        logger.error(f"Failed to send flood warning to user {user_id}: {send_err}")
                else:
                     logger.debug(f"Flood warning already recently sent to user {user_id}.")


                # Не передаем событие дальше по цепочке middleware/хендлеров
                return None # или raise CancelHandler() из aiogram.dispatcher.event.handler
            else:
                # --- Если флуда нет ---
                # Обновляем время последнего сообщения
                THROTTLING_CACHE[user_id] = current_time
                # Передаем событие дальше
                return await handler(event, data)

========== Файл: telegram_interface\middlewares\stats_counter.py ==========

# telegram_interface/middlewares/stats_counter.py

import logging
from typing import Callable, Dict, Any, Awaitable, Optional

from aiogram import BaseMiddleware
from aiogram.types import Message, TelegramObject
from aiogram.enums import ChatType

# Импортируем функцию для инкремента счетчика из БД
try:
    from database.crud_ops.stats import increment_message_count
    # Импортируем функцию для обновления профиля, чтобы создать запись, если ее нет
    from database.crud_ops.profiles import upsert_user_profile
except ImportError:
    logging.getLogger(__name__).critical("CRITICAL: Failed to import DB functions (increment_message_count, upsert_user_profile) in StatsCounterMiddleware.", exc_info=True)
    # Заглушки
    async def increment_message_count(*args, **kwargs) -> bool: return False
    async def upsert_user_profile(*args, **kwargs) -> bool: return False

logger = logging.getLogger(__name__)

class StatsCounterMiddleware(BaseMiddleware):
    """
    Middleware для подсчета количества сообщений от каждого пользователя в каждом чате.
    Обновляет счетчик в базе данных при каждом входящем сообщении от пользователя.
    """

    async def __call__(
        self,
        handler: Callable[[TelegramObject, Dict[str, Any]], Awaitable[Any]],
        event: TelegramObject, # Работаем с TelegramObject для универсальности
        data: Dict[str, Any]
    ) -> Any:

        # --- Получаем пользователя и чат ---
        user: Optional[types.User] = None
        chat: Optional[types.Chat] = None

        if isinstance(event, Message):
            # Извлекаем из сообщения
            user = event.from_user
            chat = event.chat
            # Пропускаем сообщения от ботов
            if user and user.is_bot:
                return await handler(event, data)
        # elif isinstance(event, CallbackQuery): # Можно добавить обработку колбэков, если нужно считать и их
        #     user = event.from_user
        #     chat = event.message.chat if event.message else None

        # --- Если есть пользователь и чат, обновляем статистику ---
        if user and chat:
            user_id = user.id
            chat_id = chat.id
            # Проверяем, что тип чата подходит для сбора статистики (например, группы и личные)
            if chat.type in {ChatType.PRIVATE, ChatType.GROUP, ChatType.SUPERGROUP}:
                try:
                    # 1. Убедимся, что профиль пользователя существует в БД
                    # Это важно, т.к. message_stats ссылается на user_profiles через FOREIGN KEY
                    await upsert_user_profile(
                        user_id=user_id,
                        username=user.username,
                        first_name=user.first_name,
                        last_name=user.last_name
                    )

                    # 2. Инкрементируем счетчик сообщений
                    success = await increment_message_count(chat_id, user_id)
                    if not success:
                        logger.warning(f"Failed to increment message count for user {user_id} in chat {chat_id}.")
                    # else: logger.debug(f"Incremented message count for user {user_id} in chat {chat_id}") # Слишком частый лог

                except Exception as e:
                    # Логируем ошибку, но не прерываем обработку сообщения
                    logger.error(f"Error updating message stats for user {user_id} in chat {chat_id}: {e}", exc_info=True)

        # Передаем управление следующему middleware или хендлеру
        return await handler(event, data)

========== Файл: telegram_interface\middlewares\__init__.py ==========



========== Файл: telegram_interface\states\news_setup.py ==========

# telegram_interface/states/news_setup.py

from aiogram.fsm.state import State, StatesGroup

class NewsSetupStates(StatesGroup):
    """
    Состояния для конечного автомата настройки подписки на новости.
    """
    # Ожидание ввода канала (username, ID или пересланное сообщение)
    waiting_channel = State()
    # Ожидание ввода тем новостей (через запятую)
    waiting_topics = State()
    # Ожидание ввода расписания (через запятую или кнопка "каждый час")
    waiting_schedule = State()

# Можно добавить другие группы состояний для других FSM, если потребуется
# class AnotherFSM(StatesGroup):
#     state_1 = State()
#     state_2 = State()

========== Файл: telegram_interface\states\__init__.py ==========



========== Файл: tests\__init__.py ==========



========== Файл: tests\integration\__init__.py ==========



========== Файл: tests\unit\__init__.py ==========



========== Файл: tools\basic_tools.py ==========

# tools/basic_tools.py

import logging
import time
import asyncio
from typing import Dict, List, Optional, Tuple, Any

# Зависимости для парсинга чартов
try:
    import requests
    import aiohttp # Для асинхронного парсера (если будем использовать)
    from bs4 import BeautifulSoup
except ImportError:
    requests = None # type: ignore
    aiohttp = None # type: ignore
    BeautifulSoup = None # type: ignore
    logging.error("Missing libraries for music chart parsing: 'requests', 'aiohttp', 'beautifulsoup4'. Install them.")

logger = logging.getLogger(__name__)

# --- Имитация API Погоды (Асинхронная) ---
async def get_current_weather(location: str, unit: str = "celsius") -> Dict[str, Any]:
    """
    Получает текущую погоду для указанного местоположения (имитация).
    Возвращает словарь со статусом и данными о погоде или ошибкой.
    """
    tool_name = "get_current_weather"
    logger.info(f"--- Tool Call: {tool_name}(location='{location}', unit='{unit}') ---")
    if not location or not isinstance(location, str):
        return {"status": "error", "message": "Invalid location provided."}
    if unit not in ["celsius", "fahrenheit"]:
        logger.warning(f"{tool_name}: Invalid unit '{unit}'. Defaulting to celsius.")
        unit = "celsius"

    # Убираем имитацию задержки, т.к. функция async
    # await asyncio.sleep(0.1)
    location_lower = location.lower()
    weather_data = {}
    # Используем более реалистичные (хотя и вымышленные) данные
    if "tokyo" in location_lower:
        weather_data = {"location": "Tokyo, Japan", "temperature": "18", "unit": unit, "description": "Partly cloudy", "humidity": "65%"}
    elif "san francisco" in location_lower:
        weather_data = {"location": "San Francisco, CA, USA", "temperature": "16", "unit": unit, "description": "Sunny", "humidity": "70%"}
    elif "paris" in location_lower:
        weather_data = {"location": "Paris, France", "temperature": "14", "unit": unit, "description": "Light rain", "humidity": "80%"}
    elif "moscow" in location_lower:
         weather_data = {"location": "Moscow, Russia", "temperature": "10", "unit": unit, "description": "Cloudy", "humidity": "75%"}
    else:
        weather_data = {"location": location, "temperature": "unknown", "unit": unit, "description": "No data"}
        return {"status": "not_found", "message": f"Weather data not found for location '{location}'. Please specify city and country/region.", "data": weather_data}

    logger.debug(f"Weather data for '{location}': {weather_data}")
    return {"status": "success", "data": weather_data, "message": "Weather data retrieved."}


# --- Имитация API Акций (Асинхронная) ---
async def get_stock_price(ticker_symbol: str) -> Dict[str, Any]:
    """
    Получает текущую цену акции для указанного тикера (имитация).
    Возвращает словарь со статусом и данными акции или ошибкой.
    """
    tool_name = "get_stock_price"
    logger.info(f"--- Tool Call: {tool_name}(ticker_symbol='{ticker_symbol}') ---")
    if not ticker_symbol or not isinstance(ticker_symbol, str):
        return {"status": "error", "message": "Invalid ticker symbol provided."}

    # await asyncio.sleep(0.1) # Убираем имитацию задержки
    symbol = ticker_symbol.upper()
    stock_data = {}
    # Используем более реалистичные (вымышленные) данные
    if symbol == "GOOGL":
        stock_data = {"ticker": symbol, "company_name": "Alphabet Inc.", "price": "178.20", "currency": "USD", "change_percent": "+1.55%"}
        return {"status": "success", "data": stock_data, "message": "Stock price retrieved."}
    elif symbol == "AAPL":
        stock_data = {"ticker": symbol, "company_name": "Apple Inc.", "price": "191.50", "currency": "USD", "change_percent": "-0.28%"}
        return {"status": "success", "data": stock_data, "message": "Stock price retrieved."}
    elif symbol == "MSFT":
         stock_data = {"ticker": symbol, "company_name": "Microsoft Corp.", "price": "425.80", "currency": "USD", "change_percent": "+0.90%"}
         return {"status": "success", "data": stock_data, "message": "Stock price retrieved."}
    else:
        stock_data = {"ticker": symbol, "price": "unknown", "currency": "N/A", "change_percent": "N/A"}
        return {"status": "not_found", "message": f"Stock data not found for ticker symbol '{symbol}'. Please provide a valid ticker.", "data": stock_data}


# --- Парсер Музыкальных Чартов (Асинхронный) ---
async def _parse_yandex_chart_async(limit: int = 10) -> Tuple[Optional[List[Dict[str, Any]]], Optional[str]]:
    """Асинхронная функция парсинга чарта Яндекс.Музыки."""
    if not aiohttp or not BeautifulSoup:
         return None, "Missing required libraries: aiohttp, beautifulsoup4"

    url = "https://music.yandex.ru/chart"
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Accept-Language': 'ru-RU,ru;q=0.9,en-US;q=0.8,en;q=0.7'
    }
    logger.debug(f"Fetching Yandex Music chart async from {url}")

    try:
        async with aiohttp.ClientSession(headers=headers, timeout=aiohttp.ClientTimeout(total=15)) as session:
            async with session.get(url) as response:
                response.raise_for_status() # Проверка HTTP ошибок
                html_content = await response.text()
                logger.debug(f"Yandex Music chart response status: {response.status}")

        # Парсинг HTML (синхронный, но быстрый)
        soup = BeautifulSoup(html_content, 'lxml')
        tracks: List[Dict[str, Any]] = []

        # Ищем контейнеры треков
        track_elements = soup.select('.d-track[data-item-id]')
        if not track_elements:
             logger.warning("Could not find track elements using '.d-track[data-item-id]' selector.")
             return None, "Could not find track elements on the Yandex Music chart page."

        logger.debug(f"Found {len(track_elements)} potential track elements.")
        for i, track_el in enumerate(track_elements):
            if len(tracks) >= limit: break
            try:
                title_el = track_el.select_one('.d-track__name a.d-track__title')
                artists_els = track_el.select('.d-track__artists a')

                if not title_el or not artists_els:
                     logger.warning(f"Skipping track element {i+1}: missing title or artists.")
                     continue

                title = title_el.text.strip()
                artists = ', '.join([a.text.strip() for a in artists_els])
                track_id = track_el.get('data-item-id')
                track_url = f"https://music.yandex.ru/track/{track_id}" if track_id else "N/A"

                tracks.append({
                    'position': len(tracks) + 1, # Позиция в чарте
                    'title': title,
                    'artist': artists,
                    'url': track_url
                })
            except Exception as parse_err:
                logger.warning(f"Error parsing a Yandex track element {i+1}: {parse_err}", exc_info=False)
                continue

        if not tracks:
            return None, "Failed to parse any tracks from the page content."

        logger.info(f"Successfully parsed {len(tracks)} tracks from Yandex Music chart async.")
        return tracks, None

    except aiohttp.ClientError as req_err:
        logger.error(f"Network error fetching Yandex Music chart async: {req_err}", exc_info=True)
        return None, f"Network error: {req_err}"
    except asyncio.TimeoutError:
         logger.error(f"Timeout error fetching Yandex Music chart async from {url}")
         return None, "Timeout error during chart request."
    except Exception as e:
        logger.error(f"Unexpected error parsing Yandex Music chart async: {e}", exc_info=True)
        return None, f"Unexpected parsing error: {e}"

async def get_music_charts(source: str = "yandex", limit: int = 10) -> Dict[str, Any]:
    """
    Асинхронно получает топ музыкальных треков из указанного источника.
    Пока поддерживает только 'yandex'.
    """
    tool_name = "get_music_charts"
    logger.info(f"--- Tool Call: {tool_name}(source='{source}', limit={limit}) ---")

    source_lower = source.lower()
    if source_lower != "yandex":
        return {"status": "error", "message": f"Source '{source}' not supported. Only 'yandex' is available."}
    if not isinstance(limit, int) or limit <= 0 or limit > 50:
        logger.warning(f"Invalid limit '{limit}'. Using default 10.")
        limit = 10

    tracks, error_msg = await _parse_yandex_chart_async(limit)

    if error_msg:
        return {"status": "error", "message": f"Failed to get chart data: {error_msg}"}
    elif tracks:
        return {
            "status": "success",
            "chart_source": "Yandex Music",
            "top_tracks": tracks, # Список словарей
            "message": f"Successfully retrieved top {len(tracks)} tracks from Yandex Music."
        }
    else:
        # Если не было ошибки, но и треков нет (маловероятно)
        return {"status": "error", "message": "Failed to get chart data (unknown parsing error or no tracks found)."}

========== Файл: tools\communication_tools.py ==========

# tools/communication_tools.py

import logging
import asyncio
from typing import Dict, Optional

# --- Зависимости ---
try:
    # Импортируем экземпляр бота из bot_loader
    from bot_loader import bot, dp

    # Импортируем утилиту экранирования
    from aiogram.enums import ParseMode
    from utils.helpers import escape_markdown_v2
    # Импортируем базовый класс исключений aiogram
    from aiogram.exceptions import TelegramAPIError
except ImportError:
    logging.critical("CRITICAL: Failed to import dependencies (bot_loader, helpers, aiogram) in communication_tools.", exc_info=True)
    # Создаем заглушки, чтобы модуль хотя бы импортировался
    class MockBot:
        async def send_message(self, chat_id: int, text: str, **kwargs):
            print(f"[!] MockBot: Would send to {chat_id}: {text[:70]}...")
            await asyncio.sleep(0.01)
            # Возвращаем фейковый объект сообщения для имитации
            return type('obj', (object,), {'message_id': 123})()
    bot = MockBot()
    def escape_markdown_v2(text: str) -> str: return text
    TelegramAPIError = Exception # Используем базовый Exception как заглушку
    logging.warning("Using MockBot, mock escape function, and base Exception for TelegramAPIError in communication_tools.")

logger = logging.getLogger(__name__)

async def send_telegram_message(
    chat_id: int,
    text: str,
    delay_seconds: int = 0
) -> Dict[str, str]:
    """
    Асинхронно отправляет текстовое сообщение в указанный чат Telegram от имени бота.
    Автоматически экранирует текст для MarkdownV2 перед отправкой.

    Args:
        chat_id (int): ID чата Telegram.
        text (str): Текст сообщения (будет экранирован).
        delay_seconds (int): Задержка перед отправкой в секундах.
        requires_user_response (bool): Используется циклом FC для определения необходимости паузы (не используется внутри этой функции).

    Returns:
        Dict[str, str]: Словарь со статусом операции ('success' или 'error') и сообщением.
    """
    tool_name = "send_telegram_message"
    # Валидация аргументов... (остается как было) ...
    if not isinstance(chat_id, int): ...
    if text is None or not isinstance(text, str): ...
    if not text.strip(): ...
    if not isinstance(delay_seconds, int) or delay_seconds < 0: ...

    logger.info(f"--- Tool Call: {tool_name}(chat={chat_id}, delay={delay_seconds}, text='{text[:70]}...') ---")

    try:
        # <<< ИЗМЕНЕНО: Упрощенная проверка и установка задержки >>>
        actual_delay = 0
        if isinstance(delay_seconds, int) and delay_seconds > 0:
            actual_delay = delay_seconds
        # Не логируем предупреждение, если delay_seconds == 0 или None

        if actual_delay > 0:
            logger.info(f"{tool_name}: Delaying message send by {actual_delay} seconds for chat {chat_id}")
            await asyncio.sleep(actual_delay)

        escaped_text = escape_markdown_v2(text)

        sent_message = await bot.send_message(
            chat_id=chat_id,
            text=escaped_text,
            parse_mode=ParseMode.MARKDOWN_V2
        )
        sent_message_id = sent_message.message_id if sent_message else "N/A"
        logger.info(f"{tool_name}: Successfully sent message (ID: {sent_message_id}) with MarkdownV2 to chat {chat_id}")
        return {"status": "success", "message": f"Message sent successfully (ID: {sent_message_id})."}

    except TelegramAPIError as e:
        # Если ошибка парсинга даже ПОСЛЕ экранирования (маловероятно, но возможно из-за длины или редких случаев)
        if "can't parse entities" in str(e).lower():
             logger.warning(f"{tool_name}: Failed send with MarkdownV2 even after escaping (chat {chat_id}): {e}. Retrying without parse_mode.")
             try:
                  # Отправляем ОРИГИНАЛЬНЫЙ текст без разметки в fallback
                  sent_message = await bot.send_message(chat_id=chat_id, text=text, parse_mode=None)
                  sent_message_id = sent_message.message_id if sent_message else "N/A"
                  logger.info(f"{tool_name}: Successfully sent message (ID: {sent_message_id}) to chat {chat_id} (fallback without parse_mode).")
                  return {"status": "success", "message": f"Message sent successfully (ID: {sent_message_id})."}
             except Exception as fallback_e:
                  logger.error(f"{tool_name}: Fallback send failed to chat {chat_id}: {fallback_e}", exc_info=True)
                  # Возвращаем исходную ошибку парсинга
                  return {"status": "error", "message": f"Telegram API error (MarkdownV2 parse failed after escaping): {e}"}
        else:
             # Другие ошибки API
             error_msg = f"Failed to send message via {tool_name} to chat {chat_id}: TelegramAPIError - {e}"
             logger.error(error_msg, exc_info=False)
             return {"status": "error", "message": f"Telegram API error: {e}"}
    except Exception as e:
        error_msg = f"Unexpected error sending message via {tool_name} to chat {chat_id}: {e}"
        logger.error(error_msg, exc_info=True)
        return {"status": "error", "message": f"Internal error: {e}"}

========== Файл: tools\deep_search_tool.py ==========

# tools/deep_search_tool.py

import asyncio
import logging
import os
import re
import time # Для задержек между поисками/API вызовами
from typing import Dict, Optional, List, Tuple, Any

# --- Локальные Зависимости ---
try:
    # AI интерфейс для вызовов Gemini
    from ai_interface import gemini_api # Нужна функция для генерации без сессии
    from bot_loader import dp # Для доступа к модели из workflow_data
    # Утилиты
    from utils.helpers import remove_markdown
    # Настройки
    from config import settings
except ImportError:
    logging.critical("CRITICAL: Failed to import dependencies (gemini_api, dp, helpers, settings) in deep_search_tool.", exc_info=True)
    # Заглушки
    gemini_api = None # type: ignore
    dp = type('obj', (object,), {'workflow_data': {}})() # type: ignore
    def remove_markdown(text: str) -> str: return text
    settings = type('obj', (object,), {'google_api_key': None, 'deep_search_prompts_dir': Path('prompts/deep_search')})() # type: ignore

# Веб-поиск
try:
    from duckduckgo_search import DDGS, AsyncDDGS # Попробуем импортировать обе версии
    HAS_ASYNC_DDGS = True
except ImportError:
    try: # Попробуем только синхронную
        from duckduckgo_search import DDGS
        AsyncDDGS = None
        HAS_ASYNC_DDGS = False
    except ImportError:
        logging.error("duckduckgo-search library not found. Web search unavailable.")
        DDGS = None
        AsyncDDGS = None
        HAS_ASYNC_DDGS = False

# Асинхронные файлы
try:
    import aiofiles.os
except ImportError:
    aiofiles = None # type: ignore
    logging.error("aiofiles library not found. Prompt loading might fail.")

from pathlib import Path

logger = logging.getLogger(__name__)

# --- Константы (можно уточнить в config.py) ---
DEFAULT_ITERATIONS = 2
QUESTIONS_PER_ITERATION = 5
NUM_SEARCH_RESULTS = 3
MAX_SEARCH_CONTEXT_LEN = 8000 # Ограничение контекста поиска
REPORT_CONTEXT_SNIPPET_LEN = 3000 # Сколько предыдущего отчета давать в контекст
SEARCH_DELAY = 1 # Уменьшаем задержку для асинхронного поиска
API_DELAY = 2    # Задержка между вызовами API

# Путь к промптам DeepSearch из настроек
PROMPTS_DIR = settings.deep_search_prompts_dir if hasattr(settings, 'deep_search_prompts_dir') else Path("prompts/deep_search")

# --- Вспомогательные функции ---

def _parse_questions(text: Optional[str]) -> List[str]:
    """Извлекает нумерованные вопросы или строки из текста."""
    if not text: return []
    # Ищем строки, начинающиеся с цифры и точки/скобки, или маркеров списка
    questions = re.findall(r"^\s*[\d]+[.)]*\s*(.+)$|^\s*[-*+]\s*(.+)$", text, re.MULTILINE)
    parsed = [q[0] or q[1] for q in questions if q[0] or q[1]] # Берем непустую группу
    cleaned = [q.strip() for q in parsed if q.strip()]
    if not cleaned and '\n' in text: # Если нумерации/маркеров нет, но есть переносы строк
        cleaned = [line.strip() for line in text.splitlines() if line.strip()]
        logger.debug("Parsing questions as lines (no numbering/markers found).")
    logger.debug(f"Parsed {len(cleaned)} questions from text.")
    return cleaned

async def _perform_web_search_async(query: str, num_results: int) -> str:
    """Асинхронно выполняет веб-поиск и возвращает форматированный текст."""
    if not query: return "(Empty search query)"
    logger.debug(f"Performing web search for: '{query[:80]}...'")
    results_text = ""

    if HAS_ASYNC_DDGS and AsyncDDGS:
        try:
            async with AsyncDDGS(timeout=10) as ddgs: # Устанавливаем таймаут
                results = []
                async for r in ddgs.atext(query, max_results=num_results):
                    results.append(r)
            if results:
                for i, r in enumerate(results):
                    title = r.get('title', 'N/A')
                    snippet = remove_markdown(r.get('body', 'N/A')).replace('\n', ' ').strip()
                    results_text += f"  Res {i+1}: {title}\n  Snip: {snippet}\n\n"
            else: results_text = "  (No results found)\n\n"
        except Exception as e:
            logger.error(f"Async web search failed for '{query[:80]}...': {e}", exc_info=True)
            results_text = f"(Async search error: {e})"
    elif DDGS:
        # Используем синхронную версию в executor'е
        def _sync_search():
            sync_results_text = ""
            try:
                # time.sleep(SEARCH_DELAY) # Задержка не нужна, т.к. executor
                with DDGS(timeout=10) as ddgs:
                    search_results = list(ddgs.text(query, max_results=num_results))
                if search_results:
                    for i, r in enumerate(search_results):
                        title = r.get('title', 'N/A')
                        snippet = remove_markdown(r.get('body', 'N/A')).replace('\n', ' ').strip()
                        sync_results_text += f"  Res {i+1}: {title}\n  Snip: {snippet}\n\n"
                else: sync_results_text = "  (No results found)\n\n"
                return sync_results_text.strip()
            except Exception as e:
                logger.error(f"Sync web search failed for '{query[:80]}...': {e}", exc_info=True)
                return f"(Search error: {e})"

        loop = asyncio.get_running_loop()
        try:
            # Добавляем небольшую задержку перед запуском в executor
            await asyncio.sleep(SEARCH_DELAY)
            results_text = await loop.run_in_executor(None, _sync_search)
        except Exception as e:
            logger.error(f"Error running sync search in executor: {e}", exc_info=True)
            results_text = f"(Executor search error: {e})"
    else:
         results_text = "(Web search unavailable: library not found)"

    return results_text

async def _load_prompt_async(filename: str) -> Optional[str]:
     """Асинхронно загружает текст промпта из директории PROMPTS_DIR."""
     if aiofiles is None:
          logger.error("Cannot load prompt: aiofiles library missing.")
          return None
     filepath = PROMPTS_DIR / filename
     try:
          if not await aiofiles.os.path.isfile(filepath):
               logger.error(f"Prompt file not found or is not a file: {filepath}")
               return None
          async with aiofiles.open(filepath, mode="r", encoding="utf-8") as f:
               content = await f.read()
               logger.debug(f"Loaded prompt: {filename}")
               return content.strip()
     except Exception as e:
          logger.error(f"Error reading prompt file {filepath}: {e}", exc_info=True)
          return None

async def _call_gemini_generate(prompt: str, step_description: str) -> Tuple[Optional[str], Optional[str]]:
    """
    Вызывает модель Gemini Pro для генерации текста БЕЗ ИСТОРИИ.
    Возвращает (сгенерированный_текст, сообщение_об_ошибке).
    """
    model = dp.workflow_data.get("pro_model") # Получаем Pro модель
    api_key = getattr(settings, 'google_api_key', None)

    if not model: return None, "AI Pro model instance not available."
    if not api_key: return None, "Google API Key is not configured."
    if not gemini_api or not hasattr(gemini_api, 'genai'): # Проверяем наличие genai
         return None, "Gemini API module not properly loaded."

    logger.debug(f"Calling Gemini for: {step_description} (Prompt length: {len(prompt)})")
    try:
        # Используем прямой вызов generate_content_async модели
        # Настройки генерации и безопасности должны быть встроены в model при инициализации
        await asyncio.sleep(API_DELAY) # Задержка перед вызовом
        response = await model.generate_content_async(prompt)

        if response and response.text:
            logger.debug(f"Gemini response received for: {step_description}")
            return response.text.strip(), None
        elif response and response.prompt_feedback and response.prompt_feedback.block_reason:
             reason = response.prompt_feedback.block_reason
             msg = f"Gemini request blocked for '{step_description}'. Reason: {reason}"
             logger.error(msg)
             return None, msg
        else:
             msg = f"Gemini returned empty or invalid response for '{step_description}'."
             logger.error(f"{msg} Response: {response}")
             return None, msg

    except Exception as e:
        msg = f"Error calling Gemini API for '{step_description}': {e}"
        logger.error(msg, exc_info=True)
        return None, msg


# --- Основная функция инструмента ---

async def refine_text_with_deep_search(
    topic: Optional[str] = None,
    initial_text: Optional[str] = None,
    iterations: Optional[int] = None,
    user_prompt_guidance: Optional[str] = None
) -> Dict[str, Any]:
    """
    Итеративно улучшает или генерирует текст, используя веб-поиск и AI.

    Args:
        topic (Optional[str]): Тема для генерации (если initial_text не предоставлен).
        initial_text (Optional[str]): Исходный текст для улучшения.
        iterations (Optional[int]): Количество итераций улучшения (по умолчанию DEFAULT_ITERATIONS).
        user_prompt_guidance (Optional[str]): Дополнительные инструкции от пользователя.

    Returns:
        dict: Словарь со статусом ('success', 'warning', 'error') и результатом ('refined_text' или 'message').
    """
    tool_name = "refine_text_with_deep_search"
    logger.info(f"--- Tool Call: {tool_name}(topic='{topic}', initial_text_len={len(initial_text or '')}, iters={iterations}) ---")

    if not initial_text and not topic:
        return {"status": "error", "message": "Either 'topic' or 'initial_text' must be provided."}

    num_iterations = iterations if isinstance(iterations, int) and 0 < iterations < 5 else DEFAULT_ITERATIONS
    logger.info(f"Running Deep Search with {num_iterations} refinement iteration(s).")

    # --- Шаг 0: Генерация начального текста (если не предоставлен) ---
    current_report = initial_text
    if not current_report:
        logger.info(f"Generating initial text for topic: '{topic}'")
        initial_prompt_template = await _load_prompt_async("03_synthesize_report.prompt")
        if not initial_prompt_template: return {"status": "error", "message": "Failed to load initial synthesis prompt."}

        initial_gen_prompt = initial_prompt_template.format(
            original_report=f"Тема: {topic}\n{user_prompt_guidance or ''}\nНапиши начальную версию текста.",
            answers="(Нет данных для улучшения на этом шаге)"
        ).strip()

        current_report, error_msg = await _call_gemini_generate(initial_gen_prompt, "Initial Text Generation")
        if error_msg or not current_report:
            return {"status": "error", "message": f"Failed to generate initial text: {error_msg}"}
        logger.info(f"Initial text generated (len={len(current_report)}).")

    # --- Шаг 1-N: Итеративное улучшение ---
    final_report = current_report
    all_steps_succeeded = True
    iteration = 0 # Инициализируем до цикла

    for i in range(num_iterations):
        iteration = i + 1
        logger.info(f"--- Starting Refinement Iteration {iteration}/{num_iterations} ---")

        # --- 1a: Генерация вопросов ---
        q_template_index = (iteration - 1) % 4 # 4 шаблона вопросов
        q_template_filename = f"01{chr(ord('a') + q_template_index)}_generate_questions.prompt" # Общее имя для простоты
        question_prompt_template = await _load_prompt_async(q_template_filename)
        if not question_prompt_template:
            logger.error(f"Failed to load question prompt template: {q_template_filename}")
            all_steps_succeeded = False; break

        question_gen_prompt = question_prompt_template.format(
            report_text=final_report[-REPORT_CONTEXT_SNIPPET_LEN:], # Даем хвост отчета
            num_questions=QUESTIONS_PER_ITERATION
        ).strip()
        if user_prompt_guidance: question_gen_prompt += f"\n\nДополнительные указания: {user_prompt_guidance}"

        questions_text, error_msg = await _call_gemini_generate(question_gen_prompt, f"Iter {iteration}: Question Gen")
        if error_msg or not questions_text:
            logger.error(f"Failed question generation iter {iteration}: {error_msg}")
            all_steps_succeeded = False; break
        logger.info(f"Iter {iteration}: Questions generated.")
        parsed_questions = _parse_questions(questions_text)
        if not parsed_questions:
            logger.warning(f"Iter {iteration}: No questions parsed. Skipping search and answers.")
            continue # Пропускаем поиск/ответы, но не прерываем цикл

        # --- 1b: Поиск ---
        logger.info(f"Iter {iteration}: Performing web search for {len(parsed_questions)} questions...")
        search_tasks = [_perform_web_search_async(q, NUM_SEARCH_RESULTS) for q in parsed_questions]
        search_results_list = await asyncio.gather(*search_tasks) # Собираем результаты поиска
        search_context = "\n\n".join(
            f"Результаты по вопросу \"{parsed_questions[j]}\":\n{res}"
            for j, res in enumerate(search_results_list) if res and "(Search error" not in res
        ).strip()
        # Обрезаем контекст поиска
        if len(search_context.encode('utf-8', errors='ignore')) > MAX_SEARCH_CONTEXT_LEN:
            search_context_bytes = search_context.encode('utf-8', errors='ignore')
            search_context = search_context_bytes[:MAX_SEARCH_CONTEXT_LEN].decode('utf-8', errors='ignore') + "...(search context truncated)"
            logger.warning(f"Iter {iteration}: Search context truncated to {MAX_SEARCH_CONTEXT_LEN} bytes.")
        logger.info(f"Iter {iteration}: Search completed. Context length: {len(search_context)}")

        # --- 1c: Ответы на вопросы ---
        answer_prompt_template = await _load_prompt_async("02_answer_questions_with_search.prompt")
        if not answer_prompt_template:
            logger.error("Failed to load answer prompt template.")
            all_steps_succeeded = False; break

        answer_gen_prompt = answer_prompt_template.format(
            questions=questions_text,
            search_context=search_context if search_context else "(Информация из поиска недоступна)",
            report_context=final_report[-REPORT_CONTEXT_SNIPPET_LEN:] # Даем хвост предыдущего отчета
        ).strip()
        if user_prompt_guidance: answer_gen_prompt += f"\n\nДополнительные указания: {user_prompt_guidance}"

        answers_text, error_msg = await _call_gemini_generate(answer_gen_prompt, f"Iter {iteration}: Answer Gen")
        if error_msg or not answers_text:
            logger.error(f"Failed answer generation iter {iteration}: {error_msg}")
            all_steps_succeeded = False; break
        logger.info(f"Iter {iteration}: Answers generated.")

        # --- 1d: Синтез ---
        synthesis_prompt_template = await _load_prompt_async("03_synthesize_report.prompt")
        if not synthesis_prompt_template:
             logger.error("Failed to load synthesis prompt template.")
             all_steps_succeeded = False; break

        synthesis_prompt = synthesis_prompt_template.format(
            original_report=final_report,
            answers=answers_text
        ).strip()
        if user_prompt_guidance: synthesis_prompt += f"\n\nДополнительные указания: {user_prompt_guidance}"

        new_report, error_msg = await _call_gemini_generate(synthesis_prompt, f"Iter {iteration}: Synthesis")
        if error_msg or not new_report:
            logger.error(f"Failed synthesis iter {iteration}: {error_msg}")
            all_steps_succeeded = False; break

        logger.info(f"Iter {iteration}: Synthesis complete. New length: {len(new_report)}")
        final_report = new_report # Обновляем отчет для следующей итерации

    # --- Завершение ---
    if not final_report:
        return {"status": "error", "message": "Failed to produce any text content."}

    if all_steps_succeeded:
        msg = f"Text refinement completed successfully after {num_iterations} iteration(s)."
        logger.info(msg)
        return {"status": "success", "refined_text": final_report, "message": msg}
    else:
        msg = f"Text refinement finished with errors after iteration {iteration}. Returning last successful version."
        logger.warning(msg)
        # Возвращаем последний успешный вариант отчета
        return {"status": "warning", "refined_text": final_report, "message": msg}

========== Файл: tools\environment_tools.py ==========

# tools/environment_tools.py

import logging
import asyncio
import os
import re # Добавляем импорт re
import ast # Для AST трансформации
import json # Для редактирования JSON
from typing import Dict, Optional, List, Tuple, Any
import secrets
from aiogram.types import FSInputFile
from jsonpath_ng.ext import parse

# --- Локальные зависимости ---
try:
    # Менеджер окружения для безопасных путей
    from services.env_manager import get_safe_chat_path, _ensure_specific_chat_dir_exists as ensure_chat_dir
    # Трансформер AST
    from ._ast_transformer import ReplaceCodeTransformer
    # Настройки для лимитов
    from config import settings, Settings
except ImportError as e:
    logging.critical(f"CRITICAL: Failed to import dependencies (env_manager, _ast_transformer, config) in environment_tools.", exc_info=True)
    logging.warning("Using Mock functions/classes for env_manager, AST transformer, and settings in environment_tools.")
    # Заглушки
    async def get_safe_chat_path(*args, **kwargs): return False, None
    async def ensure_chat_dir(*args, **kwargs): return False
    class ReplaceCodeTransformer: pass
    class MockSettings:
        max_read_size_bytes: int = 100 * 1024
        max_write_size_bytes: int = 500 * 1024
        script_timeout_seconds: int = 30
        command_timeout_seconds: int = 60
        max_script_output_len: int = 5000
        max_command_output_len: int = 5000
    settings = MockSettings()

# Асинхронные файловые операции
try:
    import aiofiles
    import aiofiles.os
except ImportError:
    aiofiles = None # type: ignore
    logging.critical("CRITICAL: 'aiofiles' library not found. File operations will fail.")

logger = logging.getLogger(__name__)

# --- Файловые операции (Async) ---

async def read_file_from_env(user_id: int, chat_id: int, filename: str) -> Dict[str, Any]:
    """
    Читает содержимое файла из окружения чата асинхронно.
    Проверяет размер файла перед чтением.
    Возвращает словарь со статусом, сообщением и содержимым файла.

    Args:
        user_id (int): ID пользователя.
        chat_id (int): ID текущего чата.
        filename (str): Относительный путь к файлу.

    Returns:
        dict: Словарь со статусом операции, сообщением и контентом (или None при ошибке).
              Пример: {'status': 'success', 'message': 'File read.', 'content': '...', 'filename': '...'}
    """
    tool_name = "read_file_from_env"
    logger.info(f"--- Tool Call: {tool_name}(user={user_id}, chat={chat_id}, file='{filename}') ---")

    if aiofiles is None:
        return {"status": "error", "message": "Internal error: aiofiles library missing.", "content": None}

    # Проверяем путь БЕЗ создания директории чата
    is_safe, filepath = await get_safe_chat_path(chat_id, filename, user_id=user_id, ensure_chat_dir_exists=False)
    if not is_safe or filepath is None:
        return {"status": "error", "message": "Access denied or invalid filename.", "content": None}

    try:
        # Проверяем существование и тип файла асинхронно
        if not await aiofiles.os.path.exists(filepath):
            return {"status": "error", "message": f"File '{filename}' not found.", "content": None}
        if await aiofiles.os.path.isdir(filepath):
             return {"status": "error", "message": f"'{filename}' is a directory, not a file.", "content": None}

        # Читаем файл асинхронно
        async with aiofiles.open(filepath, mode="r", encoding='utf-8', errors='ignore') as f:
            content = await f.read()

        logger.info(f"{tool_name}: Successfully read file '{filename}' (size: {len(content)} bytes).")
        # Возвращаем успех с контентом
        return {
            "status": "success",
            "message": f"File '{filename}' read successfully (size: {len(content)} bytes).",
            "content": content,
            "filename": filename, # Возвращаем имя файла для контекста
        }

    except FileNotFoundError: # Должно быть поймано exists(), но оставим для надежности
        logger.warning(f"{tool_name}: File '{filename}' not found unexpectedly at path '{filepath}'.")
        return {"status": "error", "message": f"File '{filename}' not found.", "content": None}
    except Exception as e:
        msg = f"Error reading file '{filename}': {e}"
        logger.error(msg, exc_info=True)
        return {"status": "error", "message": msg, "content": None}


async def write_file_to_env(user_id: int, chat_id: int, filename: str, content: str) -> Dict[str, str]:
    """
    Записывает (или перезаписывает) текст в файл в окружении чата.
    Администраторы могут писать в директории других чатов внутри /env.
    Использует aiofiles для асинхронной записи.

    Args:
        user_id (int): ID пользователя.
        chat_id (int): ID текущего чата.
        filename (str): Относительный путь к файлу.
        content (str): Содержимое для записи.

    Returns:
        dict: Словарь со статусом операции.
    """
    tool_name = "write_file_to_env"
    logger.info(f"--- Tool Call: {tool_name}(user={user_id}, chat={chat_id}, file='{filename}', content_len={len(content)}) ---")

    if aiofiles is None: return {"status": "error", "message": "Internal error: aiofiles library missing."}

    # Проверяем путь и УБЕЖДАЕМСЯ, что базовая директория чата существует
    is_safe, filepath = await get_safe_chat_path(chat_id, filename, user_id=user_id, ensure_chat_dir_exists=True)
    if not is_safe or filepath is None:
        return {"status": "error", "message": "Access denied, invalid filename, or failed to ensure base chat directory."}

    # Проверка размера контента
    try:
        content_bytes = content.encode('utf-8')
        # ----- УДАЛЕНО: Проверка максимального размера записи -----
        # if len(content_bytes) > settings.max_write_size_bytes:
        #     msg = f"Error: Content size ({len(content_bytes)} bytes) exceeds limit ({settings.max_write_size_bytes // 1024} KB)."
        #     logger.error(f"{tool_name}: {msg} for file '{filename}'")
        #     return {"status": "error", "message": msg}
        # ----------------------------------------------------------
    except Exception as e:
        logger.error(f"{tool_name}: Error encoding content for size check: {e}")
        return {"status": "error", "message": "Error checking content size."}


    try:
        # Асинхронно создаем родительские директории для САМОГО ФАЙЛА
        parent_dir = os.path.dirname(filepath)
        if parent_dir:
             await aiofiles.os.makedirs(parent_dir, exist_ok=True)
             logger.debug(f"{tool_name}: Ensured parent directory exists: {parent_dir}")

        # Асинхронная запись
        async with aiofiles.open(filepath, mode="w", encoding='utf-8') as f:
            await f.write(content)

        logger.info(f"{tool_name}: Successfully wrote file '{filename}' (size: {len(content_bytes)} bytes).")
        return {"status": "success", "message": f"File '{filename}' written successfully."}
    except Exception as e:
        msg = f"Error writing file '{filename}': {e}"
        logger.error(msg, exc_info=True)
        return {"status": "error", "message": msg}


async def create_file_in_env(user_id: int, chat_id: int, filename: str) -> Dict[str, str]:
    """
    Создает новый пустой файл в окружении чата.
    Использует aiofiles для асинхронных операций.

    Args:
        user_id (int): ID пользователя.
        chat_id (int): ID текущего чата.
        filename (str): Относительный путь к файлу.

    Returns:
        dict: Словарь со статусом операции.
    """
    tool_name = "create_file_in_env"
    logger.info(f"--- Tool Call: {tool_name}(user={user_id}, chat={chat_id}, file='{filename}') ---")

    if aiofiles is None: return {"status": "error", "message": "Internal error: aiofiles library missing."}

    # Проверяем путь и УБЕЖДАЕМСЯ, что базовая директория чата существует
    is_safe, filepath = await get_safe_chat_path(chat_id, filename, user_id=user_id, ensure_chat_dir_exists=True)
    if not is_safe or filepath is None:
          return {"status": "error", "message": "Access denied, invalid filename, or failed to ensure base chat directory."}

    try:
        # Асинхронно проверяем, не существует ли уже файл/директория
        if await aiofiles.os.path.exists(filepath):
               is_dir = await aiofiles.os.path.isdir(filepath)
               entity_type = "directory" if is_dir else "file"
               msg = f"Error: Cannot create. {entity_type.capitalize()} '{filename}' already exists."
               logger.warning(f"{tool_name}: {msg}")
               return {"status": "error", "message": msg}

        # Асинхронно создаем родительские директории для САМОГО ФАЙЛА
        parent_dir = os.path.dirname(filepath)
        if parent_dir:
            await aiofiles.os.makedirs(parent_dir, exist_ok=True)
            logger.debug(f"{tool_name}: Ensured parent directory exists: {parent_dir}")

        # Создаем пустой файл асинхронно
        async with aiofiles.open(filepath, mode="w", encoding='utf-8') as f:
               await f.write("") # Пишем пустую строку

        logger.info(f"{tool_name}: Successfully created empty file '{filename}'")
        return {"status": "success", "message": f"File '{filename}' created successfully."}
    except Exception as e:
        msg = f"Error creating file '{filename}': {e}"
        logger.error(msg, exc_info=True)
        return {"status": "error", "message": msg}


# --- Выполнение скриптов и команд (используют asyncio.create_subprocess) ---

async def _run_subprocess(cmd_list: list[str], cwd: str, timeout: int) -> Tuple[int, str, str]:
    """Вспомогательная асинхронная функция для запуска subprocess."""
    process = None
    # ----- ИЗМЕНЕНО: Увеличено значение таймаута -----
    effective_timeout = 3600 # Например, 1 час
    try:
        process = await asyncio.create_subprocess_exec(
            *cmd_list,
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE,
            cwd=cwd,
            # ----- УДАЛЕНО: Лимит буфера -----
            # limit=settings.max_script_output_len * 2 # Устанавливаем лимит на размер буфера stdout/stderr
        )
        stdout_bytes, stderr_bytes = await asyncio.wait_for(process.communicate(), timeout=effective_timeout)
        returncode = process.returncode if process.returncode is not None else -1 # Возвращаем -1, если процесс еще не завершился (маловероятно)

        # Декодируем с игнорированием ошибок
        # ----- УДАЛЕНО: Обрезка stdout/stderr -----
        stdout = stdout_bytes.decode('utf-8', errors='ignore') #[:settings.max_script_output_len]
        stderr = stderr_bytes.decode('utf-8', errors='ignore') #[:settings.max_script_output_len]

        # if len(stdout_bytes) > settings.max_script_output_len: stdout += "...[truncated]"
        # if len(stderr_bytes) > settings.max_script_output_len: stderr += "...[truncated]"
        # --------------------------------------------

        return returncode, stdout, stderr
    except asyncio.TimeoutError:
        # ----- ИЗМЕНЕНО: Сообщение об ошибке таймаута -----
        timeout_msg = f"Error: Process timed out after {effective_timeout} seconds."
        logger.warning(f"{timeout_msg} Cmd: {cmd_list}")
        if process and process.returncode is None: # Если процесс еще жив
             try: process.kill()
             except ProcessLookupError: pass # Процесс мог завершиться сам
             await process.wait() # Дожидаемся завершения после kill
        return -99, "", timeout_msg # Специальный код для таймаута
    except Exception as e:
         logger.error(f"Error during subprocess execution: {e}. Cmd: {cmd_list}", exc_info=True)
         return -100, "", f"Error during subprocess execution: {e}" # Другая ошибка


async def _run_subprocess_shell(command: str, cwd: str, timeout: int) -> Tuple[int, str, str]:
    """Вспомогательная асинхронная функция для запуска subprocess с shell=True."""
    process = None
    # ----- ИЗМЕНЕНО: Увеличено значение таймаута -----
    effective_timeout = 3600 # Например, 1 час
    try:
        process = await asyncio.create_subprocess_shell(
            command,
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE,
            cwd=cwd,
            # ----- УДАЛЕНО: Лимит буфера -----
            # limit=settings.max_command_output_len * 2 # Лимит буфера для shell
        )

        stdout_bytes, stderr_bytes = await asyncio.wait_for(process.communicate(), timeout=effective_timeout)
        returncode = process.returncode if process.returncode is not None else -1

        # Декодируем и обрезаем
        # ----- УДАЛЕНО: Обрезка stdout/stderr -----
        stdout = stdout_bytes.decode('utf-8', errors='ignore') #[:settings.max_command_output_len]
        stderr = stderr_bytes.decode('utf-8', errors='ignore') #[:settings.max_command_output_len]

        # if len(stdout_bytes) > settings.max_command_output_len: stdout += "...[truncated]"
        # if len(stderr_bytes) > settings.max_command_output_len: stderr += "...[truncated]"
        # --------------------------------------------

        return returncode, stdout, stderr
    except asyncio.TimeoutError:
        # ----- ИЗМЕНЕНО: Сообщение об ошибке таймаута -----
        timeout_msg = f"Error: Command shell timed out after {effective_timeout} seconds."
        logger.warning(f"{timeout_msg} Command: {command}")
        if process and process.returncode is None:
            try: process.kill()
            except ProcessLookupError: pass
            await process.wait()
        return -99, "", timeout_msg # Специальный код для таймаута
    except Exception as e:
         logger.error(f"Error during shell command execution: {e}. Cmd: {command[:100]}...", exc_info=True)
         return -100, "", f"Error during shell command execution: {e}"


async def execute_python_script_in_env(user_id: int, chat_id: int, filename: str) -> Dict[str, Any]:
    """
    Выполняет Python-скрипт из окружения чата асинхронно.
    Использует asyncio.create_subprocess_exec.

    Args:
        user_id (int): ID пользователя.
        chat_id (int): ID текущего чата.
        filename (str): Относительный путь к Python-скрипту (.py).

    Returns:
        dict: Словарь с stdout, stderr, returncode и статусом.
    """
    tool_name = "execute_python_script_in_env"
    logger.info(f"--- Tool Call: {tool_name}(user={user_id}, chat={chat_id}, file='{filename}') ---")

    if aiofiles is None: return {"status": "error", "message": "Internal error: aiofiles library missing.", "returncode": -1}

    # Проверяем путь и существование ДИРЕКТОРИИ чата
    is_safe, filepath = await get_safe_chat_path(chat_id, filename, user_id=user_id, ensure_chat_dir_exists=True)
    if not is_safe or filepath is None:
        return {"status": "error", "message": "Access denied, invalid filename, or failed to ensure base chat directory.", "returncode": -1}

    # Определяем рабочую директорию (директория, где лежит скрипт)
    script_dir = os.path.dirname(filepath)
    script_basename = os.path.basename(filepath) # Только имя файла

    # Дополнительные проверки файла асинхронно
    try:
        if not await aiofiles.os.path.exists(filepath):
            return {"status": "error", "message": f"Error: Script file '{filename}' not found.", "returncode": -1}
        if not filename.lower().endswith(".py"):
            return {"status": "error", "message": "Error: Only Python scripts (.py) can be executed.", "returncode": -1}
        if await aiofiles.os.path.isdir(filepath):
             return {"status": "error", "message": f"Error: '{filename}' is a directory, not a script.", "returncode": -1}
    except Exception as e:
         logger.error(f"Error checking script file '{filepath}': {e}", exc_info=True)
         return {"status": "error", "message": f"Error checking script file: {e}", "returncode": -1}


    try:
        # Запускаем python и передаем ему имя скрипта как аргумент
        # Рабочая директория (cwd) = директория скрипта
        logger.info(f"Executing Python script '{script_basename}' in '{script_dir}'...")
        returncode, stdout, stderr = await _run_subprocess(
            ["python", script_basename], # Команда и аргумент
            cwd=script_dir,
            timeout=settings.script_timeout_seconds
        )

        status = "success" if returncode == 0 else "error"
        message = f"Script executed {'successfully' if returncode == 0 else 'with errors'}."
        if returncode == -99: # Таймаут
            status = "error"
            message = stderr # Сообщение об ошибке таймаута
        elif returncode == -100: # Python не найден (спец. код не нужен, ловится FileNotFoundError)
             pass # Обрабатывается ниже
        elif returncode != 0: # Другая ошибка выполнения скрипта
            message += f" Exit code: {returncode}."

        logger.info(f"{tool_name}: Script '{filename}' executed. Exit code: {returncode}")
        return {
            "status": status,
            "returncode": returncode,
            "stdout": stdout,
            "stderr": stderr,
            "message": message
        }

    except FileNotFoundError:
         # Эта ошибка возникнет, если 'python' не найден в PATH
         logger.error(f"{tool_name}: 'python' command not found in system PATH.")
         return {"status": "error", "message": "Error: Python interpreter not found.", "stdout": "", "stderr": "", "returncode": -101}
    except Exception as e:
        # Другие ошибки на уровне запуска процесса
        msg = f"Error preparing to execute script '{filename}': {e}"
        logger.error(msg, exc_info=True)
        return {"status": "error", "message": msg, "stdout": "", "stderr": "", "returncode": -100}


async def execute_terminal_command_in_env(user_id: int, chat_id: int, command: str) -> Dict[str, Any]:
    """
    Выполняет команду в терминале в рабочей директории окружения чата асинхронно.
    Требует подтверждения AI! Использует asyncio.create_subprocess_shell.

    Args:
        user_id (int): ID пользователя.
        chat_id (int): ID текущего чата.
        command (str): Команда терминала.

    Returns:
        dict: Словарь с stdout, stderr, returncode и статусом.
    """
    tool_name = "execute_terminal_command_in_env"
    logger.info(f"--- Tool Call: {tool_name}(user={user_id}, chat={chat_id}, cmd='{command[:100]}...') ---")

    # Получаем безопасный путь к ДИРЕКТОРИИ чата, убеждаемся, что она существует
    # Передаем "." как filename, чтобы get_safe_chat_path вернул путь к директории чата
    is_safe, safe_path_result = await get_safe_chat_path(
        chat_id,
        ".", # Запрашиваем путь к самой директории
        user_id=user_id,
        ensure_chat_dir_exists=True # Убеждаемся, что директория создана
    )

    if not is_safe or safe_path_result is None:
        # get_safe_chat_path уже логирует ошибку
        return {"status": "error", "message": "Access denied, invalid chat directory, or failed to ensure directory existence.", "returncode": -1}

    # --- ИСПРАВЛЕНО: Определяем CWD правильно ---
    chat_dir_abs = safe_path_result # safe_path_result УЖЕ является путем к директории чата
    try:
        # Дополнительная проверка, что это действительно директория
        if not await aiofiles.os.path.isdir(chat_dir_abs):
             logger.error(f"Path '{chat_dir_abs}' returned by get_safe_chat_path is not a directory. Cannot determine CWD for chat {chat_id}.")
             return {"status": "error", "message": "Internal error: Determined path is not a directory.", "returncode": -1}

        # Проверка, что путь не корневой env (на всякий случай, хотя get_safe_chat_path должен это гарантировать)
        # Импортируем настройки здесь, чтобы избежать потенциальных циклических зависимостей на уровне модуля
        from config import settings
        base_env_dir = os.path.abspath(settings.env_dir_path)
        if chat_dir_abs == base_env_dir:
             logger.error(f"Determined CWD is the root env directory '{chat_dir_abs}'. This should not happen for chat execution. Chat ID: {chat_id}")
             return {"status": "error", "message": "Internal security error: Cannot execute in root env directory.", "returncode": -1}

        logger.debug(f"Determined CWD for command execution: {chat_dir_abs}")
    except ImportError:
        logger.error("Failed to import config settings within execute_terminal_command_in_env for CWD check.")
        return {"status": "error", "message": "Internal configuration error during CWD check.", "returncode": -1}
    except Exception as path_err:
         logger.error(f"Error verifying CWD path '{chat_dir_abs}': {path_err}", exc_info=True)
         return {"status": "error", "message": f"Internal error verifying execution directory: {path_err}", "returncode": -1}
    # --- КОНЕЦ ИСПРАВЛЕНИЯ CWD ---

    # Запускаем команду в shell
    logger.info(f"{tool_name}: Executing command in shell: '{command}' in '{chat_dir_abs}'")
    try:
        # Используем полученный chat_dir_abs как cwd
        returncode, stdout, stderr = await _run_subprocess_shell(
            command,
            cwd=chat_dir_abs, # Убеждаемся, что используем исправленный chat_dir_abs
            timeout=settings.command_timeout_seconds
        )

        # Логика обработки результата остается без изменений
        status = "success" if returncode == 0 else "error"
        message = f"Command shell executed {'successfully' if returncode == 0 else 'with errors'}."
        if returncode == -99: # Таймаут
            status = "timeout" # Используем статус timeout
            message = stderr # Сообщение об ошибке таймаута
        elif returncode == -100: # Ошибка запуска
             message = stderr # Сообщение об ошибке
        elif returncode != 0: # Другая ошибка выполнения
            message += f" Exit code: {returncode}."

        logger.info(f"{tool_name}: Command '{command[:50]}...' executed. Exit code: {returncode}")
        return {
            "status": status,
            "returncode": returncode,
            "stdout": stdout,
            "stderr": stderr,
            "message": message,
            "command": command # Возвращаем команду для контекста
        }
    # Обработка ошибок остается
    except Exception as e:
        msg = f"Failed to execute command '{command}'. Error: {e}"
        logger.error(msg, exc_info=True)
        return {"status": "error", "message": msg, "command": command, "return_code": -1, "stdout": "", "stderr": ""}


# --- Редактирование файлов (AST и JSON) ---

async def edit_file_content(
    user_id: int, chat_id: int, filename: str, search_string: str, replace_string: str
) -> Dict[str, str]:
    """
    Редактирует файл в окружении чата, заменяя текст. Использует aiofiles.

    Args:
        user_id: ID пользователя.
        chat_id: ID текущего чата.
        filename: Относительный путь к файлу.
        search_string: Строка для поиска.
        replace_string: Строка для замены.

    Returns:
        dict: Словарь со статусом операции.
    """
    tool_name = "edit_file_content"
    logger.info(f"--- Tool Call: {tool_name}(user={user_id}, chat={chat_id}, file='{filename}', ... ) ---")

    if aiofiles is None: return {"status": "error", "message": "Internal error: aiofiles library missing."}

    # Проверяем путь (не создаем директорию чата заранее)
    is_safe, filepath = await get_safe_chat_path(chat_id, filename, user_id=user_id)
    if not is_safe or filepath is None:
        return {"status": "error", "message": "Access denied or invalid filename."}

    try:
        # Проверяем существование и тип файла
        if not await aiofiles.os.path.exists(filepath):
            return {"status": "error", "message": f"File '{filename}' not found."}
        if await aiofiles.os.path.isdir(filepath):
             return {"status": "error", "message": f"'{filename}' is a directory, cannot edit."}

        # Проверяем размер файла перед чтением
        stat_result = await aiofiles.os.stat(filepath)
        # ----- УДАЛЕНО: Проверка максимального размера чтения -----
        # if stat_result.st_size > settings.max_read_size_bytes:
        #      return {"status": "error", "message": f"File '{filename}' size exceeds read limit ({settings.max_read_size_bytes // 1024} KB)."}
        # ---------------------------------------------------------

        # Читаем файл
        async with aiofiles.open(filepath, mode="r", encoding='utf-8', errors='ignore') as f:
            content = await f.read()

        # Выполняем замену
        new_content = content.replace(search_string, replace_string)

        if new_content == content:
            logger.warning(f"{tool_name}: Search string '{search_string}' not found in file '{filename}'. No changes made.")
            return {"status": "warning", "message": f"Search string not found in '{filename}'. No changes made."}

        # Проверяем размер НОВОГО контента перед записью
        new_content_bytes = new_content.encode('utf-8')
        # ----- УДАЛЕНО: Проверка максимального размера записи -----
        # if len(new_content_bytes) > settings.max_write_size_bytes:
        #     return {"status": "error", "message": f"Edited content size ({len(new_content_bytes)} bytes) would exceed write limit ({settings.max_write_size_bytes // 1024} KB)."}
        # ---------------------------------------------------------

        # Записываем измененный файл
        async with aiofiles.open(filepath, mode="w", encoding='utf-8') as f:
            await f.write(new_content)

        logger.info(f"{tool_name}: Successfully edited file '{filename}'. Replaced '{search_string}' with '{replace_string}'.")
        return {"status": "success", "message": f"File '{filename}' edited successfully."}

    except Exception as e:
        msg = f"Error editing file '{filename}': {e}"
        logger.error(msg, exc_info=True)
        return {"status": "error", "message": msg}


async def replace_code_block_ast(
    user_id: int, chat_id: int, filename: str, block_type: str, block_name: str, new_code_block: str
) -> Dict[str, str]:
    """
    Заменяет блок кода (функцию или класс) в Python-файле окружения чата, используя AST.
    Выполняет файловые операции асинхронно с помощью aiofiles.

    Args:
        user_id: ID пользователя.
        chat_id: ID текущего чата.
        filename: Относительный путь к .py файлу.
        block_type: 'function' или 'class'.
        block_name: Имя заменяемого блока.
        new_code_block: Полный код нового блока.

    Returns:
        dict: Словарь со статусом операции.
    """
    tool_name = "replace_code_block_ast"
    logger.info(f"--- Tool Call: {tool_name}(user={user_id}, chat={chat_id}, file='{filename}', type='{block_type}', name='{block_name}') ---")

    # Проверка версии Python (ast.unparse доступен с 3.9) - остается синхронной
    import sys
    if sys.version_info < (3, 9):
        return {"status": "error", "message": "Error: This tool requires Python 3.9+ for ast.unparse()."}

    if aiofiles is None:
         return {"status": "error", "message": "Internal error: aiofiles library missing."}

    # Проверяем путь и убеждаемся, что директория чата существует
    is_safe, filepath = await get_safe_chat_path(chat_id, filename, user_id=user_id, ensure_chat_dir_exists=True)
    if not is_safe or filepath is None:
        return {"status": "error", "message": "Access denied, invalid filename, or failed to ensure base chat directory."}

    # Валидация имени файла и типа блока
    if not filename.lower().endswith(".py"): return {"status": "error", "message": "Error: Can only edit Python (.py) files."}
    if block_type not in ["function", "class"]: return {"status": "error", "message": f"Error: Invalid block_type '{block_type}'. Must be 'function' or 'class'."}

    try:
        # Асинхронно читаем исходный код
        if not await aiofiles.os.path.exists(filepath):
            return {"status": "not_found", "message": f"Error: File '{filename}' not found."}
        if await aiofiles.os.path.isdir(filepath):
            return {"status": "error", "message": f"Error: '{filename}' is a directory."}

        async with aiofiles.open(filepath, "r", encoding='utf-8') as f:
             source_code = await f.read()

        # Парсинг AST (синхронные операции)
        try:
            tree = ast.parse(source_code, filename=filename)
        except (SyntaxError, Exception) as parse_err:
             logger.error(f"{tool_name}: Error parsing original Python file '{filename}': {parse_err}", exc_info=True)
             return {"status": "error", "message": f"Error parsing Python code in '{filename}': {parse_err}"}

        try:
            new_code_tree = ast.parse(new_code_block)
            if not new_code_tree.body or len(new_code_tree.body) != 1:
                 return {"status": "error", "message": "Error: 'new_code_block' must contain exactly one function or class definition."}
            new_node = new_code_tree.body[0]

            # Проверка типа нового узла
            if block_type == "function" and not isinstance(new_node, ast.FunctionDef):
                 return {"status": "error", "message": f"Error: Expected 'function' definition, found {type(new_node)}."}
            if block_type == "class" and not isinstance(new_node, ast.ClassDef):
                 return {"status": "error", "message": f"Error: Expected 'class' definition, found {type(new_node)}."}

        except (SyntaxError, Exception) as new_parse_err:
            logger.error(f"{tool_name}: Error parsing new_code_block: {new_parse_err}", exc_info=True)
            return {"status": "error", "message": f"Error parsing new_code_block: {new_parse_err}"}

        # Применяем AST-трансформер (синхронно)
        # Убедимся, что ReplaceCodeTransformer импортирован корректно
        if 'ReplaceCodeTransformer' not in globals() or not callable(ReplaceCodeTransformer):
             # Это может произойти, если _ast_transformer.py не был создан/импортирован
             logger.critical(f"{tool_name}: ReplaceCodeTransformer class not available. Check import.")
             return {"status": "error", "message": "Internal error: Code transformer not available."}

        transformer = ReplaceCodeTransformer(block_type, block_name, new_node)
        new_tree = transformer.visit(tree)

        if not transformer.replaced:
            return {"status": "not_found", "message": f"Error: {block_type.capitalize()} '{block_name}' not found in file '{filename}'."}

        # Генерируем новый код (синхронно)
        new_source_code = ast.unparse(new_tree)

         # Проверка лимита на запись
        try:
            content_bytes = new_source_code.encode('utf-8')
            if len(content_bytes) > settings.max_write_size_bytes:
                 msg = f"Error: Resulting code size ({len(content_bytes)} bytes) exceeds limit ({settings.max_write_size_bytes // 1024} KB)."
                 logger.error(f"{tool_name}: {msg} for file '{filename}' after AST edit.")
                 return {"status": "error", "message": msg + " Edit aborted."}
        except Exception as e:
             logger.error(f"{tool_name}: Error encoding modified code for size check: {e}")
             return {"status": "error", "message": "Error checking modified code size."}

        # Асинхронно записываем новый код в файл
        async with aiofiles.open(filepath, "w", encoding='utf-8') as f:
            await f.write(new_source_code)

        msg = f"Successfully replaced {block_type} '{block_name}' in file '{filename}' using AST."
        logger.info(f"{tool_name}: {msg}")
        return {"status": "success", "message": msg}

    except Exception as e:
        msg = f"Error during AST replacement for file '{filename}': {e}"
        logger.error(msg, exc_info=True)
        return {"status": "error", "message": msg}


async def edit_json_file(
    user_id: int, chat_id: int, filename: str, json_path: str, new_value_json: str
) -> Dict[str, str]:
    """
    Редактирует JSON-файл в окружении чата по указанному пути.
    Выполняет файловые операции асинхронно.

    Args:
        user_id: ID пользователя.
        chat_id: ID текущего чата.
        filename: Относительный путь к .json файлу.
        json_path: Путь к элементу (dot-нотация, например 'a.b[0].c').
        new_value_json: Новое значение в виде JSON-строки.

    Returns:
        dict: Словарь со статусом операции.
    """
    tool_name = "edit_json_file"
    logger.info(f"--- Tool Call: {tool_name}(user={user_id}, chat={chat_id}, file='{filename}', path='{json_path}') ---")

    if aiofiles is None: return {"status": "error", "message": "Internal error: aiofiles library missing."}

    # Проверяем путь и убеждаемся, что директория чата существует
    is_safe, filepath = await get_safe_chat_path(chat_id, filename, user_id=user_id, ensure_chat_dir_exists=True)
    if not is_safe or filepath is None:
        return {"status": "error", "message": "Access denied, invalid filename, or failed to ensure base chat directory."}

    # Предупреждаем, если расширение не .json, но продолжаем
    if not filename.lower().endswith(".json"):
        logger.warning(f"{tool_name}: File '{filename}' does not have .json extension.")

    try:
        # Асинхронно читаем JSON
        if not await aiofiles.os.path.exists(filepath): return {"status": "not_found", "message": f"Error: File '{filename}' not found."}
        if await aiofiles.os.path.isdir(filepath): return {"status": "error", "message": f"Error: '{filename}' is a directory."}

        async with aiofiles.open(filepath, "r", encoding='utf-8') as f:
            try:
                content = await f.read()
                data = json.loads(content) # Парсинг JSON (синхронный)
            except json.JSONDecodeError as e:
                logger.error(f"{tool_name}: JSON Decode Error reading file '{filename}': {e}")
                return {"status": "error", "message": f"Error decoding JSON from file '{filename}': {e}"}
            except Exception as read_err: # Ловим и другие ошибки чтения
                 logger.error(f"Error reading file content '{filename}': {read_err}", exc_info=True)
                 return {"status": "error", "message": f"Error reading file: {read_err}"}


        # Парсинг нового значения (синхронный)
        try:
            new_value = json.loads(new_value_json)
        except json.JSONDecodeError:
            # Если не JSON, используем как строку (поведение как в v3)
            logger.warning(f"{tool_name}: Could not parse new_value_json '{new_value_json}' as JSON. Using as raw string.")
            new_value = new_value_json # Оставляем строкой

        # --- Логика парсинга json_path и установки значения (синхронная) ---
        # (Код парсинга и установки значения остается без изменений, как в v3)
        keys: List[Any] = []
        current_part = ""
        in_bracket = False
        in_quotes = False
        quote_char = ''
        path_iterator = iter(enumerate(json_path))
        try:
             for i, char in path_iterator:
                  if char in ('"', "'") and not in_bracket:
                       if not in_quotes: in_quotes = True; quote_char = char;
                       elif char == quote_char:
                            in_quotes = False; keys.append(current_part); current_part = ""
                            next_i = i + 1
                            if next_i < len(json_path) and json_path[next_i] == '.': next(path_iterator, None)
                       else: current_part += char
                       continue
                  if in_quotes: current_part += char; continue
                  if char == '.' and not in_bracket:
                       if not current_part and not keys: raise ValueError("JSON path cannot start with '.'")
                       if not current_part: raise ValueError(f"Invalid JSON path near index {i} (empty key)")
                       keys.append(current_part); current_part = ""
                  elif char == '[' and not in_bracket:
                       if current_part: keys.append(current_part); current_part = ""
                       in_bracket = True
                  elif char == ']' and in_bracket:
                       keys.append(int(current_part)); current_part = ""; in_bracket = False
                       next_i = i + 1
                       if next_i < len(json_path) and json_path[next_i] == '.': next(path_iterator, None)
                  elif in_bracket:
                       if not char.isdigit(): raise ValueError(f"Non-digit char '{char}' inside list index")
                       current_part += char
                  else: current_part += char
             if in_quotes: raise ValueError(f"Unmatched quote '{quote_char}' in JSON path")
             if in_bracket: raise ValueError("Unmatched '[' in JSON path")
             if current_part: keys.append(current_part)
             if not keys: raise ValueError("Empty or invalid JSON path")
        except (ValueError, IndexError) as path_err:
             logger.error(f"{tool_name}: Error parsing JSON path '{json_path}': {path_err}")
             return {"status": "error", "message": f"Error parsing JSON path '{json_path}': {path_err}"}

        temp_data: Any = data
        try:
             for key in keys[:-1]:
                  if isinstance(temp_data, list): temp_data = temp_data[int(key)]
                  elif isinstance(temp_data, dict): temp_data = temp_data[str(key)]
                  else: raise TypeError(f"Cannot access key '{key}' on element type {type(temp_data)}")
             last_key = keys[-1]
             if isinstance(temp_data, list): temp_data[int(last_key)] = new_value
             elif isinstance(temp_data, dict): temp_data[str(last_key)] = new_value
             elif len(keys) == 1: data = new_value; logger.warning(f"{tool_name}: Overwrote entire JSON file '{filename}'")
             else: raise TypeError(f"Cannot set value at '{last_key}'. Parent is not list/dict.")
        except (IndexError, KeyError, ValueError, TypeError) as set_err:
             logger.error(f"{tool_name}: Error setting value at path '{json_path}': {set_err}")
             return {"status": "error", "message": f"Error setting value at path '{json_path}': {set_err}"}
        # --- Конец логики парсинга и установки ---

        # Асинхронно записываем измененные данные обратно
        try:
            modified_json_str = json.dumps(data, indent=4, ensure_ascii=False)
            # Проверка лимита на запись
            content_bytes = modified_json_str.encode('utf-8')
            if len(content_bytes) > settings.max_write_size_bytes:
                 msg = f"Error: Resulting JSON size ({len(content_bytes)} bytes) exceeds limit ({settings.max_write_size_bytes // 1024} KB)."
                 logger.error(f"{tool_name}: {msg} for file '{filename}' after JSON edit.")
                 return {"status": "error", "message": msg + " Edit aborted."}

            async with aiofiles.open(filepath, "w", encoding='utf-8') as f:
                await f.write(modified_json_str)

            msg = f"JSON file '{filename}' edited successfully at path '{json_path}'."
            logger.info(f"{tool_name}: {msg}")
            return {"status": "success", "message": msg}
        except TypeError as e: # Ошибка сериализации измененных данных
             logger.error(f"{tool_name}: Error serializing modified JSON data for '{filename}': {e}", exc_info=True)
             return {"status": "error", "message": f"Error serializing modified JSON data: {e}"}
        except Exception as write_err: # Другие ошибки записи
             logger.error(f"{tool_name}: Error writing JSON file '{filename}': {write_err}", exc_info=True)
             return {"status": "error", "message": f"Error writing JSON file: {write_err}"}

    except Exception as e:
        # Ловим ошибки чтения файла или другие непредвиденные
        msg = f"Error processing JSON file '{filename}': {e}"
        logger.error(msg, exc_info=True)
        return {"status": "error", "message": msg}


async def send_file_from_env(user_id: int, chat_id: int, filename: str) -> Dict[str, str]:
    """
    Отправляет файл из окружения чата пользователю в текущий чат.

    Args:
        user_id (int): ID пользователя.
        chat_id (int): ID текущего чата для отправки файла.
        filename (str): Относительный путь к файлу в окружении.

    Returns:
        dict: Словарь со статусом операции.
    """
    tool_name = "send_file_from_env"
    logger.info(f"--- Tool Call: {tool_name}(user={user_id}, chat={chat_id}, file='{filename}') ---")

    if aiofiles is None:
        return {"status": "error", "message": "Internal error: aiofiles library missing."}

    # Проверяем путь БЕЗ создания директории чата
    is_safe, filepath = await get_safe_chat_path(chat_id, filename, user_id=user_id, ensure_chat_dir_exists=False)
    if not is_safe or filepath is None:
        return {"status": "error", "message": "Access denied or invalid filename."}

    try:
        # Проверяем существование и тип файла асинхронно
        if not await aiofiles.os.path.exists(filepath):
            return {"status": "not_found", "message": f"File '{filename}' not found in environment."}
        if await aiofiles.os.path.isdir(filepath):
             return {"status": "error", "message": f"'{filename}' is a directory, cannot send it as a file."}

        # Отправляем файл
        from bot_loader import bot # Импортируем бота здесь, чтобы избежать циклических зависимостей на уровне модуля
        if bot is None:
            return {"status": "error", "message": "Internal error: Bot instance is unavailable."}

        try:
            input_file = FSInputFile(filepath) # Создаем объект для отправки
            await bot.send_document(chat_id=chat_id, document=input_file)
            logger.info(f"{tool_name}: Successfully sent file '{filename}' to chat {chat_id}.")
            return {"status": "success", "message": f"File '{filename}' sent successfully."}
        except Exception as send_error:
             # Ловим ошибки отправки (файл слишком большой, бот заблокирован и т.д.)
             logger.error(f"{tool_name}: Failed to send file '{filename}' to chat {chat_id}: {send_error}", exc_info=True)
             # Попробуем извлечь более конкретное сообщение об ошибке TelegramAPIError
             from aiogram.exceptions import TelegramAPIError
             error_details = str(send_error)
             if isinstance(send_error, TelegramAPIError):
                  error_details = send_error.message # Более специфичное сообщение
             return {"status": "error", "message": f"Failed to send file: {error_details}"}

    except Exception as e:
        msg = f"Error preparing to send file '{filename}': {e}"
        logger.error(msg, exc_info=True)
        return {"status": "error", "message": msg}

========== Файл: tools\meta_tools.py ==========

# tools/communication_tools.py (или tools/meta_tools.py)

import logging
import asyncio
from typing import Dict, Optional

# --- Импорты ---
try:
    from bot_loader import bot, dp # Нужен бот для отправки админам и dp для модели
    from config import settings    # Нужны ID админов
    import database               # Нужна функция добавления в БД
    from utils.helpers import escape_markdown_v2
    from aiogram.enums import ParseMode
    from aiogram.exceptions import TelegramAPIError
except ImportError:
    settings = type('obj', (object,), {'admin_ids': set()})() # Заглушка для admin_ids
    database = None

logger = logging.getLogger(__name__)


# --- НОВАЯ ФУНКЦИЯ ---
async def Developer_Feedback(
    chat_id: Optional[int],       # Будет добавлено из контекста FC
    user_id: Optional[int],       # Будет добавлено из контекста FC
    Degree_of_importance: str, # Аргументы от модели (могут быть CamelCase)
    Reason: str,
    Problem: str
) -> Dict[str, str]:
    """
    Записывает обратную связь от модели в БД и отправляет уведомление администраторам.
    Эта функция является обработчиком для вызова 'Developer_Feedback' моделью.

    Args: (из Function Calling)
        chat_id (Optional[int]): ID чата, где произошла проблема.
        user_id (Optional[int]): ID пользователя, взаимодействие с которым вызвало фидбек.
        Degree_of_importance (str): Важность проблемы ('high', 'medium', 'low', etc.)
        Reason (str): Краткая причина/категория фидбека.
        Problem (str): Детальное описание проблемы/предложения.

    Returns:
        Dict[str, str]: Словарь со статусом операции.
    """
    tool_name = "Developer_Feedback" # Имя, которое знает модель
    internal_tool_name = "developer_feedback_tool" # Имя Python функции
    logger.info(f"--- Tool Call: {tool_name} (handled by {internal_tool_name}) ---")
    logger.info(f"    Args: chat_id={chat_id}, user_id={user_id}, importance='{Degree_of_importance}', reason='{Reason}', problem='{Problem[:100]}...'")

    # Валидация входных данных от модели
    if not Degree_of_importance or not isinstance(Degree_of_importance, str):
        return {"status": "error", "message": "Argument 'Degree_of_importance' is missing or invalid."}
    if not Reason or not isinstance(Reason, str):
        return {"status": "error", "message": "Argument 'Reason' is missing or invalid."}
    if not Problem or not isinstance(Problem, str):
        return {"status": "error", "message": "Argument 'Problem' is missing or invalid."}

    # Получаем имя модели из dp (опционально)
    model_name = None
    try:
        # Попытка получить имя текущей Pro модели (если она хранится)
        # Пример:
        current_index = dp.workflow_data.get("current_api_key_index", 0)
        pro_models = dp.workflow_data.get("pro_models_list", [])
        if pro_models and current_index < len(pro_models):
            model_instance = pro_models[current_index]
            model_name = getattr(model_instance, '_model_name', 'Unknown Pro Model')
    except Exception as e:
        logger.warning(f"Could not determine model name for feedback log: {e}")

    # 1. Запись в БД
    db_success = False
    feedback_id = None
    if database:
        try:
            feedback_id = await database.add_developer_feedback(
                degree_of_importance=Degree_of_importance,
                reason=Reason,
                problem_description=Problem,
                chat_id=chat_id,
                user_id=user_id,
                model_name=model_name
            )
            if feedback_id is not None:
                db_success = True
                logger.info(f"Feedback saved to DB with ID: {feedback_id}")
            else:
                logger.error("Failed to save feedback to DB (returned None ID).")
        except Exception as db_err:
            logger.error(f"Error saving feedback to DB: {db_err}", exc_info=True)
    else:
        logger.error("Cannot save feedback to DB: database module unavailable.")

    # 2. Отправка уведомления администраторам
    admin_notify_success = False
    if bot and settings and settings.admin_ids:
        # Формируем сообщение для админов
        escaped_reason = escape_markdown_v2(Reason)
        escaped_problem = escape_markdown_v2(Problem)
        escaped_importance = escape_markdown_v2(Degree_of_importance.upper())
        db_status = f"DB ID: `{feedback_id}`" if feedback_id else "DB Save Failed"

        admin_message = (
            f"⚠️ *Developer Feedback Received*\n\n"
            f"*Importance:* `{escaped_importance}`\n"
            f"*Reason:* `{escaped_reason}`\n"
            f"*Model:* `{escape_markdown_v2(model_name or 'N/A')}`\n"
            f"*Chat ID:* `{chat_id or 'N/A'}`\n"
            f"*User ID:* `{user_id or 'N/A'}`\n"
            f"*DB Status:* {db_status}\n\n"
            f"*Description:*\n```\n{escaped_problem}\n```"
        )

        # Ограничиваем длину сообщения
        if len(admin_message) > 4000: # Чуть меньше лимита
            admin_message = admin_message[:4000] + "\n... (message truncated)"
            logger.warning("Admin feedback notification message truncated.")

        sent_to_admins = 0
        for admin_id in settings.admin_ids:
            try:
                await bot.send_message(
                    chat_id=admin_id,
                    text=admin_message,
                    parse_mode=ParseMode.MARKDOWN_V2
                )
                sent_to_admins += 1
            except TelegramAPIError as send_err:
                logger.error(f"Failed to send feedback notification to admin {admin_id}: {send_err}")
            except Exception as e:
                logger.error(f"Unexpected error sending notification to admin {admin_id}: {e}", exc_info=True)

        if sent_to_admins > 0:
            admin_notify_success = True
            logger.info(f"Feedback notification sent to {sent_to_admins} admin(s).")
        else:
            logger.error("Failed to send feedback notification to any admin.")

    elif not bot:
        logger.error("Cannot send admin notification: Bot instance unavailable.")
    elif not settings or not settings.admin_ids:
        logger.warning("Cannot send admin notification: Admin IDs not configured.")

    # 3. Формируем результат для модели
    if db_success and admin_notify_success:
        return {"status": "success", "message": "Feedback logged and administrators notified."}
    elif db_success:
        return {"status": "warning", "message": "Feedback logged to DB, but failed to notify administrators."}
    elif admin_notify_success:
        return {"status": "warning", "message": "Feedback notification sent to administrators, but failed to log to DB."}
    else:
        return {"status": "error", "message": "Failed to log feedback to DB and failed to notify administrators."}

========== Файл: tools\user_data_tools.py ==========

# tools/user_data_tools.py

import logging
import asyncio
import json
from typing import Dict, Optional, Any, Union # Добавили Union

# --- Импортируем CRUD операции напрямую ---
try:
    import database
except ImportError:
    logging.critical("CRITICAL: Failed to import 'database' module in user_data_tools.")
    database = None # type: ignore

# --- Импортируем зависимости для аватара ---
try:
    from bot_loader import bot
    from config import settings # Нужен токен бота и API ключ Gemini
    import aiohttp
    from io import BytesIO
    # Импортируем функцию генерации описания
    from ai_interface.gemini_api import generate_image_description
except ImportError:
    logging.error("Failed to import dependencies (bot_loader, config, aiohttp, gemini_api) for avatar functionality.", exc_info=True)
    bot = None # type: ignore
    settings = None # type: ignore
    aiohttp = None # type: ignore
    BytesIO = None # type: ignore
    generate_image_description = None # type: ignore

logger = logging.getLogger(__name__)

# --- Инструменты ---

async def find_user_id(query: str) -> Dict[str, Any]:
    """
    Ищет user_id пользователя в базе данных по его имени (first_name)
    или username (без @). Использует database.find_user_id_by_profile.

    Args:
        query (str): Имя или username пользователя для поиска.

    Returns:
        dict: Словарь со статусом ('success' или 'not_found'/'error') и user_id (если найден).
    """
    tool_name = "find_user_id"
    logger.info(f"--- Tool Call: {tool_name}(query='{query}') ---")
    if not query or not isinstance(query, str):
        return {"status": "error", "message": "Query must be a non-empty string."}
    if database is None:
        return {"status": "error", "message": "Database module is unavailable."}

    try:
        found_id = await database.find_user_id_by_profile(query)
        if found_id:
            msg = f"User ID {found_id} found for query '{query}'."
            logger.info(msg)
            return {"status": "success", "user_id": found_id, "message": msg}
        else:
            msg = f"User with name or username similar to '{query}' not found in known profiles."
            logger.info(msg)
            return {"status": "not_found", "message": msg}
    except Exception as e:
        msg = f"Error searching for user ID with query '{query}': {e}"
        logger.error(msg, exc_info=True)
        return {"status": "error", "message": msg}


# --- ИСПРАВЛЕНО: Обработка user_id ---
async def reading_user_info(user_id: Union[int, float, str]) -> Dict[str, Any]:
    """
    Получает всю известную информацию (профиль + заметки) о пользователе по его ID.
    Использует database.get_user_data_combined.

    Args:
        user_id (Union[int, float, str]): ID пользователя Telegram (может прийти как float от LLM).

    Returns:
        dict: Словарь со статусом операции и данными пользователя ('user_data_json').
              Данные возвращаются как JSON-строка. При ошибке или отсутствии данных возвращает соответствующий статус.
    """
    tool_name = "reading_user_info"

    # --- Валидация и конвертация user_id ---
    try:
        user_id_int = int(float(user_id)) # Сначала в float для универсальности, потом в int
        if user_id_int <= 0:
             raise ValueError("User ID must be positive.")
    except (ValueError, TypeError):
         logger.error(f"{tool_name}: Invalid user_id type or value: type={type(user_id)}, value={user_id}")
         return {"status": "error", "message": f"Invalid user_id provided: {user_id}"}
    # --- Конец валидации ---

    logger.info(f"--- Tool Call: {tool_name}(user_id={user_id_int}) ---") # Логируем int ID

    # Старая, некорректная проверка удалена
    # if not isinstance(user_id, int) or user_id <= 0:
    #     return {"status": "error", "message": "Invalid user_id provided."}

    if database is None:
        return {"status": "error", "message": "Database module is unavailable."}

    try:
        # Используем user_id_int для запроса к БД
        user_data = await database.get_user_data_combined(user_id_int)

        if not user_data:
            msg = f"No information found for user {user_id_int}."
            logger.info(msg)
            return {"status": "not_found", "message": msg}
        else:
            try:
                data_json_str = json.dumps(user_data, ensure_ascii=False, indent=2, default=str)
                msg = f"User data for {user_id_int} retrieved successfully."
                logger.info(msg)
                return {"status": "success", "message": msg, "user_data_json": data_json_str}
            except Exception as json_err:
                 msg = f"Failed to serialize user data to JSON for user {user_id_int}: {json_err}"
                 logger.error(msg, exc_info=True)
                 return {"status": "warning", "message": f"{msg}. Returning raw data.", "data": user_data}

    except Exception as e:
        msg = f"Error retrieving combined user data for user_id={user_id_int}: {e}"
        logger.error(msg, exc_info=True)
        return {"status": "error", "message": msg}


# --- ИСПРАВЛЕНО: Обработка user_id ---
async def remember_user_info(
    user_id: Union[int, float, str], # Принимаем разные типы
    info_category: str,
    info_value: str,
    merge_lists: bool = True
) -> Dict[str, str]:
    """
    Сохраняет или обновляет заметку о пользователе. Использует database.upsert_user_note.
    Поддерживает объединение JSON списков/словарей.

    Args:
        user_id (Union[int, float, str]): ID пользователя.
        info_category (str): Категория заметки.
        info_value (str): Значение заметки (текст или JSON-строка).
        merge_lists (bool): Объединять ли списки/словари (по умолчанию True).

    Returns:
        dict: Словарь со статусом операции ('success' или 'error') и сообщением.
    """
    tool_name = "remember_user_info"

    # --- Валидация и конвертация user_id ---
    try:
        user_id_int = int(float(user_id))
        if user_id_int <= 0:
             raise ValueError("User ID must be positive.")
    except (ValueError, TypeError):
         logger.error(f"{tool_name}: Invalid user_id type or value: type={type(user_id)}, value={user_id}")
         return {"status": "error", "message": f"Invalid user_id provided: {user_id}"}
    # --- Конец валидации ---

    logger.info(f"--- Tool Call: {tool_name}(user_id={user_id_int}, category='{info_category}', value='{info_value[:50]}...', merge={merge_lists}) ---")

    # Старая, некорректная проверка удалена
    # if not isinstance(user_id, int) or user_id <= 0: return {"status": "error", "message": "Invalid user_id."}

    # Остальная валидация аргументов
    if not info_category or not isinstance(info_category, str): return {"status": "error", "message": "Invalid info_category."}
    if info_value is None or not isinstance(info_value, str): return {"status": "error", "message": "Invalid info_value (must be string)."}
    if not isinstance(merge_lists, bool):
        logger.warning(f"{tool_name}: Invalid merge_lists type ({type(merge_lists)}). Defaulting to True.")
        merge_lists = True

    if database is None: return {"status": "error", "message": "Database module is unavailable."}

    try:
        # Вызываем CRUD функцию с user_id_int
        success = await database.upsert_user_note(
            user_id=user_id_int,
            category=info_category,
            value=info_value,
            merge_lists=merge_lists
        )
        if success:
            msg = f"Note '{info_category}' for user {user_id_int} upserted successfully (merge={merge_lists})."
            logger.info(msg)
            return {"status": "success", "message": msg}
        else:
            # Функция upsert_user_note должна логировать ошибку БД
            return {"status": "error", "message": f"Failed to upsert note '{info_category}' for user {user_id_int}."}
    except Exception as e:
        msg = f"Unexpected error in {tool_name} handler: {e}"
        logger.error(msg, exc_info=True)
        return {"status": "error", "message": msg}


# --- ИСПРАВЛЕНО: Обработка user_id ---
async def forget_user_info(
    user_id: Union[int, float, str], # Принимаем разные типы
    info_category: str,
    key: Optional[str] = None,
    list_item: Optional[str] = None
) -> Dict[str, str]:
    """
    Удаляет заметку (или ее часть) о пользователе. Использует database.delete_user_note_nested или database.delete_user_note.

    Args:
        user_id (Union[int, float, str]): ID пользователя.
        info_category (str): Категория заметки.
        key (Optional[str]): Ключ для удаления из словаря.
        list_item (Optional[str]): Элемент для удаления из списка (передается как строка).

    Returns:
        dict: Словарь со статусом операции ('success', 'not_found' или 'error') и сообщением.
    """
    tool_name = "forget_user_info"

    # --- Валидация и конвертация user_id ---
    try:
        user_id_int = int(float(user_id))
        if user_id_int <= 0:
             raise ValueError("User ID must be positive.")
    except (ValueError, TypeError):
         logger.error(f"{tool_name}: Invalid user_id type or value: type={type(user_id)}, value={user_id}")
         return {"status": "error", "message": f"Invalid user_id provided: {user_id}"}
    # --- Конец валидации ---

    logger.info(f"--- Tool Call: {tool_name}(user_id={user_id_int}, category='{info_category}', key={key}, list_item={list_item}) ---")

    # Старая, некорректная проверка удалена
    # if not isinstance(user_id, int) or user_id <= 0: return {"status": "error", "message": "Invalid user_id."}

    if not info_category or not isinstance(info_category, str): return {"status": "error", "message": "Invalid info_category."}

    if database is None: return {"status": "error", "message": "Database module is unavailable."}

    parsed_list_item: Any = list_item

    try:
        if key is not None or list_item is not None:
            # Используем вложенное удаление с user_id_int
            success = await database.delete_user_note_nested(
                user_id=user_id_int,
                category=info_category,
                key=key,
                list_item=parsed_list_item
            )
            if success:
                op_desc = f"key '{key}'" if key is not None else f"item matching '{list_item}'"
                msg = f"{op_desc.capitalize()} deleted from note '{info_category}' for user {user_id_int}."
                logger.info(msg)
                return {"status": "success", "message": msg}
            else:
                op_desc = f"Key '{key}'" if key is not None else f"Item matching '{list_item}'"
                msg = f"{op_desc} or note category '{info_category}' not found for user {user_id_int}."
                logger.info(msg)
                return {"status": "not_found", "message": msg}
        else:
            # Удаляем всю категорию с user_id_int
            success = await database.delete_user_note(user_id_int, info_category)
            if success:
                msg = f"Note category '{info_category}' deleted for user {user_id_int}."
                logger.info(msg)
                return {"status": "success", "message": msg}
            else:
                msg = f"Note category '{info_category}' not found for user {user_id_int}."
                logger.info(msg)
                return {"status": "not_found", "message": msg}

    except Exception as e:
        msg = f"Unexpected error in {tool_name} handler: {e}"
        logger.error(msg, exc_info=True)
        return {"status": "error", "message": msg}


# --- ИСПРАВЛЕНО: Обработка user_id ---
async def get_avatar_description(user_id: Union[int, float, str], force_update: bool = False) -> Dict[str, Any]:
    """
    Получает или генерирует описание аватара пользователя, используя AI Vision.
    Использует database.get_user_profile и database.update_avatar_description.

    Args:
        user_id (Union[int, float, str]): ID пользователя.
        force_update (bool): Принудительно обновить описание.

    Returns:
        dict: Словарь со статусом и описанием (или сообщением об ошибке).
    """
    tool_name = "get_avatar_description"

    # --- Валидация и конвертация user_id ---
    try:
        user_id_int = int(float(user_id))
        if user_id_int <= 0:
             raise ValueError("User ID must be positive.")
    except (ValueError, TypeError):
         logger.error(f"{tool_name}: Invalid user_id type or value: type={type(user_id)}, value={user_id}")
         return {"status": "error", "message": f"Invalid user_id provided: {user_id}"}
    # --- Конец валидации ---

    logger.info(f"--- Tool Call: {tool_name}(user_id={user_id_int}, force_update={force_update}) ---")

    # Проверка зависимостей
    if database is None: return {"status": "error", "message": "Database module unavailable."}
    if bot is None: return {"status": "error", "message": "Bot instance unavailable."}
    if settings is None: return {"status": "error", "message": "Settings unavailable."}
    if aiohttp is None or BytesIO is None: return {"status": "error", "message": "Required libraries (aiohttp/io) missing."}
    if generate_image_description is None: return {"status": "error", "message": "Image description function unavailable."}

    # Старая, некорректная проверка удалена
    # if not isinstance(user_id, int) or user_id <= 0: return {"status": "error", "message": "Invalid user_id."}

    if not isinstance(force_update, bool):
         logger.warning(f"{tool_name}: Invalid force_update type ({type(force_update)}). Defaulting to False.")
         force_update = False

    try:
        # Используем user_id_int
        profile_data = await database.get_user_profile(user_id_int)

        # Проверяем кэш в БД, если не нужно принудительное обновление
        if not force_update and profile_data and profile_data.get("avatar_description"):
            desc = profile_data["avatar_description"]
            msg = f"Using cached avatar description for user {user_id_int}."
            logger.info(msg)
            return {"status": "success", "description": desc, "message": msg}

        # --- Получение File ID аватара ---
        avatar_file_id: Optional[str] = None
        # Используем user_id_int
        if profile_data and profile_data.get("avatar_file_id"):
             avatar_file_id = profile_data["avatar_file_id"]
             logger.debug(f"Found avatar file_id in profile cache for user {user_id_int}.")
        else:
             logger.info(f"Avatar file_id not in profile for user {user_id_int}, trying get_user_profile_photos API call.")
             try:
                 # Используем user_id_int
                 profile_photos = await bot.get_user_profile_photos(user_id_int, limit=1)
                 if profile_photos and profile_photos.photos:
                     avatar_file_id = profile_photos.photos[0][-1].file_id
                     logger.info(f"Retrieved avatar file_id '{avatar_file_id}' via API for user {user_id_int}.")
                     # Используем user_id_int
                     await database.update_avatar_description(user_id_int, avatar_file_id=avatar_file_id)
                 else:
                     msg = f"User {user_id_int} has no accessible profile photos via API."
                     logger.info(msg)
                     return {"status": "not_found", "message": msg}
             except Exception as get_photo_err:
                 msg = f"Failed to get user profile photos via API for user {user_id_int}: {get_photo_err}"
                 logger.error(msg, exc_info=False)
                 return {"status": "error", "message": f"Failed to get profile photos: {get_photo_err}"}

        if not avatar_file_id:
             return {"status": "error", "message": "Could not retrieve avatar file_id (not in DB or via API)."}

        # --- Загрузка и Описание Аватара ---
        logger.info(f"Generating new avatar description for user {user_id_int} (file_id: {avatar_file_id})...")
        image_bytes: Optional[bytes] = None
        try:
            file_info = await bot.get_file(avatar_file_id)
            if not file_info.file_path:
                 raise ValueError("Telegram API returned file info without file_path.")
            if not settings.bot_token: raise ValueError("Bot token is not configured in settings.")

            async with aiohttp.ClientSession() as session:
                file_url = bot.session.api.file_url(settings.bot_token, file_info.file_path)
                logger.debug(f"Downloading avatar from: {file_url}")
                async with session.get(file_url) as resp:
                    if resp.status != 200:
                        raise ConnectionError(f"Failed download avatar: HTTP {resp.status} from {file_url}")
                    image_bytes = await resp.read()
                    logger.debug(f"Avatar downloaded ({len(image_bytes)} bytes).")

        except Exception as download_err:
            msg = f"Error downloading avatar (file_id: {avatar_file_id}) user {user_id_int}: {download_err}"
            logger.error(msg, exc_info=True)
            return {"status": "error", "message": msg}

        if image_bytes:
            try:
                if not settings.google_api_key:
                     raise ValueError("Google API Key is not configured for Vision model.")

                prompt = "Опиши подробно, что изображено на этой аватарке пользователя Telegram. Сфокусируйся на визуальных деталях: объекты, люди (если есть), стиль, цвета, настроение. Будь объективен. Ответ дай в 1-3 предложениях."
                new_description = await generate_image_description(
                    api_key=settings.google_api_key,
                    image_bytes=image_bytes,
                    prompt=prompt
                )

                if new_description is None or "[Описание заблокировано:" in new_description:
                    msg = f"Image description generation failed or was blocked for user {user_id_int}."
                    logger.error(msg)
                    return {"status": "error", "message": new_description or msg }

                # Используем user_id_int
                update_success = await database.update_avatar_description(
                    user_id_int,
                    avatar_file_id=avatar_file_id,
                    avatar_description=new_description
                )
                if not update_success:
                     logger.error(f"Failed to save generated avatar description to DB for user {user_id_int}.")

                msg = f"New avatar description generated and {'saved' if update_success else 'failed to save'} for user {user_id_int}."
                logger.info(msg)
                return {"status": "success" if update_success else "warning", "description": new_description, "message": msg}

            except Exception as vision_err:
                 msg = f"Error generating image description for user {user_id_int}: {vision_err}"
                 logger.error(msg, exc_info=True)
                 return {"status": "error", "message": msg}
        else:
             return {"status": "error", "message": "Avatar download failed, cannot generate description."}

    except Exception as e:
        # Используем user_id_int в логе, если он был определен
        user_id_for_log = locals().get('user_id_int', user_id)
        msg = f"Unexpected error in {tool_name} handler for user_id={user_id_for_log}: {e}"
        logger.error(msg, exc_info=True)
        return {"status": "error", "message": msg}

========== Файл: tools\_ast_transformer.py ==========

# tools/_ast_transformer.py
import ast
import logging
from typing import Any

logger = logging.getLogger(__name__)

class ReplaceCodeTransformer(ast.NodeTransformer):
    """AST Transformer для замены узла (функции или класса)."""
    def __init__(self, block_type: str, block_name: str, new_code_node: ast.AST):
        self.block_type = block_type
        self.block_name = block_name
        self.new_code_node = new_code_node
        self.replaced = False # Флаг, была ли произведена замена

    def visit_FunctionDef(self, node: ast.FunctionDef) -> Any:
        """Посещает узел определения функции."""
        if self.block_type == "function" and node.name == self.block_name:
            if isinstance(self.new_code_node, ast.FunctionDef):
                logger.info(f"Replacing function '{self.block_name}'.")
                # Сохраняем декораторы старой функции, если у новой их нет
                if node.decorator_list and not self.new_code_node.decorator_list:
                    self.new_code_node.decorator_list = node.decorator_list
                self.replaced = True
                return self.new_code_node # Возвращаем новый узел
            else:
                logger.error(f"AST Type Mismatch: Expected FunctionDef for '{self.block_name}', got {type(self.new_code_node)}.")
                return node # Возвращаем старый узел при ошибке типа
        return self.generic_visit(node) # Продолжаем обход для вложенных узлов

    def visit_ClassDef(self, node: ast.ClassDef) -> Any:
        """Посещает узел определения класса."""
        if self.block_type == "class" and node.name == self.block_name:
            if isinstance(self.new_code_node, ast.ClassDef):
                logger.info(f"Replacing class '{self.block_name}'.")
                # Сохраняем декораторы старого класса, если у нового их нет
                if node.decorator_list and not self.new_code_node.decorator_list:
                    self.new_code_node.decorator_list = node.decorator_list
                self.replaced = True
                return self.new_code_node # Возвращаем новый узел
            else:
                logger.error(f"AST Type Mismatch: Expected ClassDef for '{self.block_name}', got {type(self.new_code_node)}.")
                return node # Возвращаем старый узел при ошибке типа
        return self.generic_visit(node) # Продолжаем обход для вложенных узлов 

========== Файл: tools\__init__.py ==========

# tools/__init__.py

import logging
import asyncio
import importlib # <<< Добавляем importlib
from typing import Dict, Callable, Coroutine, Any

available_functions: Dict[str, Callable[..., Coroutine[Any, Any, Any]]] = {}
logger = logging.getLogger(__name__)
logger.info("Initializing tools...")

# Список модулей с инструментами
tool_module_paths = [
    ".basic_tools",
    ".communication_tools",
    ".user_data_tools",
    ".environment_tools",
    ".deep_search_tool",
    ".meta_tools"
    # Добавляйте сюда другие модули с инструментами, если они появятся
]

internal_function_names = {
    "get_safe_chat_path",
    "ensure_chat_dir",
    # Добавьте другие внутренние/вспомогательные функции, если они есть
}
# <<< ИЗМЕНЕНО: Список имен функций, для которых пока нет _ast_transformer.py >>>
# (Если вы выбрали вариант (б) для Исправления 1)
disabled_tool_names = {
    # "replace_code_block_ast" # <<< ЗАКОММЕНТИРОВАНО, т.к. файл _ast_transformer.py создан
}

# Итерируемся по модулям и собираем функции
for module_path in tool_module_paths:
    try:
        module = importlib.import_module(module_path, package=__name__)
        found_in_module = 0
        logger.debug(f"Processing tool module: {module_path}")

        for func_name, func_obj in module.__dict__.items():
            # <<< ИЗМЕНЕНО: Условие регистрации >>>
            if (asyncio.iscoroutinefunction(func_obj) and
                    not func_name.startswith('_') and
                    func_name not in internal_function_names and # Не регистрируем внутренние
                    func_name not in disabled_tool_names): # Не регистрируем отключенные
                if func_name in available_functions:
                    logger.warning(f"Duplicate tool function name '{func_name}' found in {module_path}. Overwriting.")
                available_functions[func_name] = func_obj
                found_in_module += 1

        if found_in_module > 0:
            logger.info(f"Registered {found_in_module} tools from {module_path}.")
        else:
             logger.debug(f"No valid async tool functions found or registered in {module_path}.")

    except ImportError as e:
        logger.warning(f"Could not import tool module {module_path}: {e}.")
    except Exception as e:
         logger.error(f"Unexpected error processing module {module_path}: {e}", exc_info=True)

logger.info(f"Total initialized tools: {len(available_functions)}. Names: {list(available_functions.keys())}")

# Явно экспортируем словарь для использования в других частях приложения
__all__ = ["available_functions"]

========== Файл: utils\converters.py ==========

# utils/converters.py
import logging
import json
from typing import Dict, Any, List, Optional, Union

logger = logging.getLogger(__name__)

# --- Типы Google (только для аннотаций) ---
# Импортируем с проверкой, чтобы не падать, если пакет еще не установлен
try:
    # <<< ВОЗВРАЩАЕМ glm >>>
    from google.ai import generativelanguage as glm
    # <<< ДОБАВЛЯЕМ Импорт RepeatedComposite >>>
    from google.protobuf.internal.containers import RepeatedComposite
    Part = glm.Part
    Content = glm.Content
    FunctionResponse = glm.FunctionResponse
    FunctionCall = glm.FunctionCall
except ImportError:
    Part, Content, FunctionResponse, FunctionCall = Any, Any, Any, Any
    # <<< ДОБАВЛЯЕМ RepeatedComposite в fallback >>>
    RepeatedComposite = Any # Определяем как Any, если импорт не удался
    logging.getLogger(__name__).warning(
        "Could not import Google types (Part, Content, etc.) or RepeatedComposite. Using 'Any' for type hints."
    )



# --- Вспомогательные функции сериализации/десериализации (из v3) ---

def _serialize_parts(parts: Union[List[Dict[str, Any]], 'RepeatedComposite']) -> str:
    """Converts a list of part dicts or RepeatedComposite to a JSON string."""
    # <<< ДОБАВЛЕНО: Логгирование на входе в функцию >>>
    logger.debug(f"_serialize_parts received: type={type(parts)}, value={repr(parts)[:500]}") # Логгируем тип и начало значения
    if not isinstance(parts, (list, RepeatedComposite)): # This is where the error occurs
        logger.error(f"_serialize_parts expected a list or RepeatedComposite, got {type(parts)}. Returning empty list JSON.")
        return "[]"

    try:
        # <<< ИЗМЕНЕНИЕ: Используем parts_list >>>
        serializable_parts = [_convert_value_for_json(part) for part in parts]
        return json.dumps(serializable_parts, ensure_ascii=False)
    except TypeError as e:
        logger.error(f"Failed to serialize parts list to JSON: {e}", exc_info=True)
        # Возвращаем пустой список в случае ошибки сериализации
        return "[]"
    except Exception as e:
        logger.error(f"Unexpected error during parts serialization: {e}", exc_info=True)
        return "[]"


def _deserialize_parts(parts_json: Optional[str]) -> List[Dict[str, Any]]:
    """
    Десериализует JSON строку в список словарей.
    Возвращает пустой список при ошибке или если на входе None/пустая строка.
    """
    if not parts_json:
        return []
    try:
        data = json.loads(parts_json)
        if isinstance(data, list):
            # Дополнительно проверяем, что элементы списка - словари (опционально)
            if all(isinstance(item, dict) for item in data):
                return data
            else:
                logger.warning(f"_deserialize_parts: JSON list contains non-dict elements. Returning as is.")
                return data # Возвращаем как есть, но логируем
        else:
             logger.error(f"_deserialize_parts: JSON string did not decode into a list. Got type: {type(data)}")
             return [] # Возвращаем пустой список, если это не список
    except json.JSONDecodeError as e:
        logger.error(f"Failed to deserialize parts JSON: {e}. JSON: '{parts_json[:100]}...'")
        return [{"error": "deserialization_failed", "original_json": parts_json[:100] + "..."}]
    except Exception as e:
        logger.error(f"Unexpected error during parts deserialization: {e}", exc_info=True)
        return []



def _is_map_composite(obj: Any) -> bool:
    """Проверяет, похож ли объект на MapComposite (утиная типизация)."""
    return hasattr(obj, 'keys') and hasattr(obj, 'values') and hasattr(obj, 'items') and \
           not isinstance(obj, dict)

def _convert_value_for_json(value: Any) -> Any:
    """
    Рекурсивно конвертирует вложенные структуры (включая объекты Google)
    в типы, совместимые с JSON-сериализацией (dict, list, str, int, float, bool, None).
    """
    if isinstance(value, dict):
        # Конвертируем ключи в строки и рекурсивно обрабатываем значения
        return {str(k): _convert_value_for_json(v) for k, v in value.items()}
    elif isinstance(value, list):
        # Рекурсивно обрабатываем элементы списка
        return [_convert_value_for_json(item) for item in value]
    elif _is_map_composite(value):
         # Обрабатываем MapComposite-подобные объекты как словари
         logger.debug(f"Converting MapComposite-like object to dict: {type(value)}")
         return {str(k): _convert_value_for_json(v) for k, v in value.items()}
    # Обработка объектов с методом to_dict (например, объекты Google)
    elif hasattr(value, 'to_dict') and callable(value.to_dict):
        try:
            dict_repr = value.to_dict()
            # Рекурсивно обрабатываем результат to_dict
            return _convert_value_for_json(dict_repr)
        except Exception as e:
            logger.warning(f"Calling to_dict() failed for {type(value)}: {e}. Converting to string.")
            return str(value)
    # Базовые типы, совместимые с JSON
    elif isinstance(value, (str, int, float, bool, type(None))):
        return value
    # Для всех остальных неподдерживаемых типов
    else:
        logger.warning(f"Cannot directly serialize type {type(value)}. Converting to string.")
        return str(value)

def _convert_part_to_dict(part: Part) -> Optional[Dict[str, Any]]:
    """
    Преобразует объект google.ai.generativelanguage.Part в словарь Python.
    Корректно обрабатывает наличие text, function_call и function_response.
    Игнорирует FC/FR с невалидными (пустыми) именами.
    Возвращает словарь, если есть хотя бы одно валидное поле (text, fc, fr).
    """
    part_dict = {}
    has_valid_content = False

    try:
        # --- Текст ---
        # Сохраняем текст, даже если он пустой, если это ЕДИНСТВЕННОЕ содержимое.
        # Но если есть FC или FR, пустой текст можно проигнорировать.
        part_text = getattr(part, 'text', None)
        if isinstance(part_text, str): # Проверяем, что атрибут text есть и это строка
             part_dict['text'] = part_text # Сохраняем текст (может быть пустым)
             if part_text: # Считаем валидным контентом только непустой текст
                 has_valid_content = True

        # --- FunctionCall ---
        fc = getattr(part, 'function_call', None)
        if fc is not None:
            fc_name = getattr(fc, 'name', None)
            if isinstance(fc_name, str) and fc_name.strip():
                # --- Код обработки fc_args (остается как был) ---
                fc_args_converted = {"error": "conversion failed"}
                fc_args_raw = getattr(fc, 'args', None)
                if fc_args_raw is not None:
                    try:
                        fc_args_converted = _convert_value_for_json(fc_args_raw)
                        if not isinstance(fc_args_converted, dict):
                            logger.error(f"Conversion of function_call args did not result in a dict for '{fc_name}'. Args type: {type(fc_args_converted)}")
                            fc_args_converted = {"error": "failed to parse args structure"}
                    except Exception as e:
                        logger.error(f"Could not convert function_call args to dict for '{fc_name}': {e}. Raw Args: {fc_args_raw}")
                        fc_args_converted = {"error": f"failed to parse args: {e}"}
                else:
                    fc_args_converted = {}
                # --- Конец кода обработки fc_args ---
                part_dict['function_call'] = {'name': fc_name, 'args': fc_args_converted}
                has_valid_content = True
            else:
                logger.debug(f"Ignoring invalid function_call name: '{fc_name}' during conversion.")

        # --- FunctionResponse ---
        fr = getattr(part, 'function_response', None)
        if fr is not None:
            fr_name = getattr(fr, 'name', None)
            if isinstance(fr_name, str) and fr_name.strip():
                # --- Код обработки fr_response (остается как был) ---
                fr_response_converted = {"error": "conversion failed"}
                fr_response_raw = getattr(fr, 'response', None)
                if fr_response_raw is not None:
                    try:
                        fr_response_converted = _convert_value_for_json(fr_response_raw)
                        if not isinstance(fr_response_converted, dict):
                            logger.error(f"Conversion of function_response 'response' did not result in a dict for '{fr_name}'. Type: {type(fr_response_converted)}")
                            fr_response_converted = {"error": "failed to parse response structure"}
                    except Exception as e:
                        logger.error(f"Could not convert function_response 'response' for '{fr_name}': {e}. Raw Response: {fr_response_raw}")
                        fr_response_converted = {"error": f"failed to parse response: {e}"}
                else:
                    fr_response_converted = {}
                # --- Конец кода обработки fr_response ---
                part_dict['function_response'] = {'name': fr_name, 'response': fr_response_converted}
                has_valid_content = True
            else:
                 logger.debug(f"Ignoring invalid function_response name: '{fr_name}' during conversion.")


        # <<< УТОЧНЕННАЯ ЛОГИКА ВОЗВРАТА >>>
        # Если есть валидный FC или FR, или НЕПУСТОЙ текст, возвращаем словарь.
        # Если есть ТОЛЬКО ПУСТОЙ текст, то НЕ возвращаем словарь (None),
        # чтобы не создавать пустые записи в истории без FC/FR.
        if has_valid_content:
             # Если есть FC/FR, удаляем поле 'text', если оно пустое
             if ('function_call' in part_dict or 'function_response' in part_dict) and 'text' in part_dict and not part_dict['text']:
                  del part_dict['text']
             return part_dict
        elif 'text' in part_dict and not part_dict['text']: # Если был только пустой текст
             logger.debug("Part contained only empty text after processing. Returning None.")
             return None
        else: # Не было ни текста, ни валидного FC/FR
             return None

    except Exception as e:
        logger.error(f"Error converting Part to dict: {e}. Part: {part}", exc_info=True)
        return None

def gemini_history_to_dict_list(history: Optional[List[Content]]) -> List[Dict[str, Any]]:
    """
    Преобразует историю Gemini (список объектов Content) в список словарей Python.

    Args:
        history: Список объектов google.ai.generativelanguage.Content или None.

    Returns:
        Список словарей, где каждый словарь представляет запись истории
        с ключами 'role' и 'parts' (список словарей).
    """
    dict_list: List[Dict[str, Any]] = []
    if not history:
        return dict_list

    for entry in history:
        if not isinstance(entry, Content):
            logger.warning(f"Skipping non-Content item in history: {type(entry)}")
            continue

        role = getattr(entry, 'role', None)
        if not role:
            logger.warning("History entry missing role, skipping.")
            continue

        parts_list_of_dicts: List[Dict[str, Any]] = []
        if hasattr(entry, 'parts') and isinstance(entry.parts, (list, tuple)):
            for p in entry.parts:
                # Конвертируем каждую часть и добавляем, если результат не None
                converted_part = _convert_part_to_dict(p)
                if converted_part is not None:
                    parts_list_of_dicts.append(converted_part)
                else:
                    # Логируем, что часть была пропущена (возможно, ошибка конвертации)
                    logger.debug(f"Part conversion returned None for role '{role}', part type: {type(p)}. Skipping part.")

        # <<< ИЗМЕНЕНИЕ: УДАЛЯЕМ проверку 'if parts_list_of_dicts:' >>>
        # Добавляем запись, если есть роль, даже если parts_list_of_dicts пуст
        # Это сохранит структуру диалога, даже если содержимое ответа модели было проблемным
        # if parts_list_of_dicts: # <-- Удаляем эту строку
        #     dict_list.append({"role": role, "parts": parts_list_of_dicts})
        # elif role: # <-- Удаляем эту строку
        #      logger.debug(f"History entry for role '{role}' resulted in empty parts list after conversion. Skipping entry.") # <-- Удаляем эту строку

        # <<< ИЗМЕНЕНИЕ: Добавляем всегда, если есть роль >>>
        dict_list.append({"role": role, "parts": parts_list_of_dicts})
        if not parts_list_of_dicts:
            logger.debug(f"History entry for role '{role}' resulted in empty parts list after conversion, but entry structure is saved.")

    return dict_list

# <<< НАЧАЛО НОВОЙ ФУНКЦИИ >>>
def reconstruct_content_object(role: str, parts_list_of_dicts: List[Dict[str, Any]]) -> Optional[Content]:
    """
    Воссоздает объект google.ai.generativelanguage.Content из роли и списка словарей,
    представляющих его части (включая text, function_call, function_response).

    Args:
        role: Роль ('user' или 'model').
        parts_list_of_dicts: Список словарей, десериализованный из parts_json.

    Returns:
        Объект google.ai.generativelanguage.Content или None, если возникла ошибка.
    """
    try:
        reconstructed_parts: List[Part] = []
        for part_dict in parts_list_of_dicts:
            if not isinstance(part_dict, dict):
                logger.warning(f"Skipping non-dict item in parts_list_of_dicts: {part_dict}")
                continue

            # Создаем объект Part
            new_part = glm.Part()
            part_has_content = False

            # Восстанавливаем текст
            if 'text' in part_dict:
                text_content = part_dict['text']
                if isinstance(text_content, str):
                    new_part.text = text_content
                    part_has_content = True
                else:
                    logger.warning(f"Reconstruct: Invalid type for text content: type={type(text_content)}, value='{str(text_content)[:50]}...'. Skipping part.")

            # Восстанавливаем FunctionCall
            if 'function_call' in part_dict and isinstance(part_dict['function_call'], dict):
                fc_data = part_dict['function_call']
                fc_name = fc_data.get('name')
                fc_args = fc_data.get('args', {}) # Args должны быть словарем
                if isinstance(fc_name, str) and fc_name.strip() and isinstance(fc_args, dict):
                    try:
                         # Пытаемся создать FunctionCall. Аргументы передаем как есть (словарь).
                         # <<< ИЗМЕНЕНИЕ: Используем glm.FunctionCall >>>
                         new_part.function_call = glm.FunctionCall(name=fc_name, args=fc_args)
                         part_has_content = True
                    except Exception as fc_err:
                         logger.error(f"Failed to reconstruct FunctionCall for '{fc_name}': {fc_err}. Data: {fc_data}", exc_info=True)
                else:
                     logger.warning(f"Skipping invalid function_call data during reconstruction: Name='{fc_name}', Args Type='{type(fc_args)}'")


            # Восстанавливаем FunctionResponse
            if 'function_response' in part_dict and isinstance(part_dict['function_response'], dict):
                fr_data = part_dict['function_response']
                fr_name = fr_data.get('name')
                # Response может быть любым JSON-совместимым типом, но ожидается словарь
                fr_response = fr_data.get('response', {})
                if isinstance(fr_name, str) and fr_name.strip():
                     try:
                         # Пытаемся создать FunctionResponse. Response передаем как есть.
                         # <<< ИЗМЕНЕНИЕ: Используем glm.FunctionResponse >>>
                         new_part.function_response = glm.FunctionResponse(name=fr_name, response=fr_response)
                         part_has_content = True
                     except Exception as fr_err:
                         logger.error(f"Failed to reconstruct FunctionResponse for '{fr_name}': {fr_err}. Data: {fr_data}", exc_info=True)
                else:
                    logger.warning(f"Skipping invalid function_response data during reconstruction: Name='{fr_name}'")


            # Добавляем созданную часть в список, если она не пустая
            if part_has_content:
                reconstructed_parts.append(new_part)
            else:
                logger.warning(f"Skipping part reconstruction as it resulted in empty content: {part_dict}")


        # Если после обработки всех частей список не пуст, создаем Content
        if reconstructed_parts:
            # <<< ИЗМЕНЕНИЕ: Используем glm.Content >>>
            return glm.Content(role=role, parts=reconstructed_parts)
        else:
            logger.warning(f"Reconstruction resulted in no valid parts for role '{role}'. Original data: {parts_list_of_dicts}")
            return None

    except Exception as e:
        logger.error(f"Failed to reconstruct Content object for role '{role}': {e}", exc_info=True)
        return None
# <<< КОНЕЦ НОВОЙ ФУНКЦИИ >>>

========== Файл: utils\helpers.py ==========

# utils/helpers.py
import re
import logging
from typing import Optional, Set

# Импортируем настройки для доступа к ADMIN_IDS
try:
    from config import settings
except ImportError:
    # Заглушка на случай проблем с импортом config
    class MockSettings:
        admin_ids: Set[int] = set()
    settings = MockSettings()
    logging.warning("Could not import settings from config.py in helpers. Using mock settings.")

logger = logging.getLogger(__name__)

def is_admin(user_id: Optional[int]) -> bool:
    """
    Проверяет, является ли пользователь администратором бота.

    Args:
        user_id (Optional[int]): ID пользователя Telegram.

    Returns:
        bool: True, если пользователь является администратором, иначе False.
    """
    if user_id is None:
        return False
    # Проверяем наличие ID в множестве администраторов из настроек
    is_admin_flag = user_id in settings.admin_ids
    if is_admin_flag:
        logger.debug(f"Admin check: User {user_id} is an admin.")
    # else:
    #     logger.debug(f"Admin check: User {user_id} is NOT an admin.")
    return is_admin_flag


def escape_markdown_v2(text: Optional[str]) -> str:
    """
    Экранирует специальные символы для разметки Telegram MarkdownV2.

    Args:
        text (Optional[str]): Входной текст.

    Returns:
        str: Текст с экранированными символами или пустая строка, если на входе None.
    """
    if text is None:
        return ""
    if not isinstance(text, str):
        try:
            text = str(text)
            logger.warning(f"escape_markdown_v2 received non-string type: {type(text)}. Converted to string.")
        except Exception:
             logger.error(f"escape_markdown_v2 failed to convert non-string input: {type(text)}.")
             return ""

    # Символы для экранирования в MarkdownV2
    # _ * [ ] ( ) ~ ` > # + - = | { } . !
    escape_chars = r'_*[]()~`>#+-=|{}.!'
    # Создаем регулярное выражение для поиска этих символов
    # Экранируем сам символ '\' перед ним
    regex = re.compile(f'([{re.escape(escape_chars)}])')
    # Заменяем найденные символы на экранированные (добавляем '\' перед символом)
    return regex.sub(r'\\\1', text)


def remove_markdown(text: Optional[str]) -> str:
    """
    Удаляет основные символы разметки Markdown из текста.

    Args:
        text (Optional[str]): Входной текст.

    Returns:
        str: Текст без Markdown разметки или пустая строка, если на входе None.
    """
    if text is None:
        return ""
    if not isinstance(text, str):
        try:
            text = str(text)
            logger.warning(f"remove_markdown received non-string type: {type(text)}. Converted to string.")
        except Exception:
             logger.error(f"remove_markdown failed to convert non-string input: {type(text)}.")
             return ""

    # Удаляем символы форматирования: *, _, ~, `, ```, [, ], (, )
    # Осторожно с [, ], (, ), так как они могут быть частью обычного текста.
    # Простое удаление может быть недостаточным для сложных случаев (например, вложенность).

    # Удаляем парные символы (**, __, ~~, ```, `)
    text = re.sub(r'\*\*(.*?)\*\*', r'\1', text, flags=re.DOTALL)
    text = re.sub(r'__(.*?)__', r'\1', text, flags=re.DOTALL)
    text = re.sub(r'~~(.*?)~~', r'\1', text, flags=re.DOTALL)
    text = re.sub(r'```(.*?)```', r'\1', text, flags=re.DOTALL)
    text = re.sub(r'`(.*?)`', r'\1', text, flags=re.DOTALL)

    # Удаляем одиночные символы (*, _) - могут быть в обычных словах, удаляем аккуратно
    # Этот шаг может быть излишне агрессивным, возможно, лучше оставить
    # text = re.sub(r'(?<!\\)[*_]', '', text) # Удаляем * и _, если перед ними нет \

    # Удаляем разметку ссылок [текст](url) -> текст
    text = re.sub(r'\[(.*?)\]\((.*?)\)', r'\1', text)

    return text

# Можно добавить другие вспомогательные функции по мере необходимости
